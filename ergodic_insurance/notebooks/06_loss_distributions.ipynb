{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Distribution Analysis\n",
    "\n",
    "Interactive exploration of manufacturing loss distributions including attritional, large, and catastrophic losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent.parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from ergodic_insurance.src.loss_distributions import (\n",
    "    ManufacturingLossGenerator,\n",
    "    AttritionalLossGenerator,\n",
    "    LargeLossGenerator,\n",
    "    CatastrophicLossGenerator,\n",
    "    LossEvent\n",
    ")\n",
    "from ergodic_insurance.src.visualization import (\n",
    "    WSJ_COLORS,\n",
    "    wsj_style,\n",
    "    format_currency\n",
    ")\n",
    "\n",
    "# Set default plotly theme\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"Loss Distribution Analysis Notebook\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Interactive Loss Parameter Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widgets for loss parameters\n",
    "attritional_freq = widgets.FloatSlider(\n",
    "    value=5.0, min=1.0, max=20.0, step=0.5,\n",
    "    description='Frequency:', continuous_update=False\n",
    ")\n",
    "attritional_severity = widgets.IntSlider(\n",
    "    value=50000, min=10000, max=200000, step=10000,\n",
    "    description='Severity:', continuous_update=False\n",
    ")\n",
    "attritional_cv = widgets.FloatSlider(\n",
    "    value=0.8, min=0.2, max=2.0, step=0.1,\n",
    "    description='CV:', continuous_update=False\n",
    ")\n",
    "\n",
    "large_freq = widgets.FloatSlider(\n",
    "    value=0.5, min=0.1, max=2.0, step=0.1,\n",
    "    description='Frequency:', continuous_update=False\n",
    ")\n",
    "large_severity = widgets.IntSlider(\n",
    "    value=2000000, min=500000, max=10000000, step=500000,\n",
    "    description='Severity:', continuous_update=False\n",
    ")\n",
    "large_cv = widgets.FloatSlider(\n",
    "    value=1.2, min=0.5, max=3.0, step=0.1,\n",
    "    description='CV:', continuous_update=False\n",
    ")\n",
    "\n",
    "cat_freq = widgets.FloatSlider(\n",
    "    value=0.02, min=0.001, max=0.1, step=0.001,\n",
    "    description='Frequency:', continuous_update=False\n",
    ")\n",
    "cat_xm = widgets.IntSlider(\n",
    "    value=10000000, min=5000000, max=50000000, step=5000000,\n",
    "    description='Min Loss:', continuous_update=False\n",
    ")\n",
    "cat_alpha = widgets.FloatSlider(\n",
    "    value=2.5, min=1.5, max=4.0, step=0.1,\n",
    "    description='Alpha:', continuous_update=False\n",
    ")\n",
    "\n",
    "n_simulations = widgets.IntSlider(\n",
    "    value=10000, min=1000, max=100000, step=1000,\n",
    "    description='Simulations:', continuous_update=False\n",
    ")\n",
    "\n",
    "def update_loss_distribution(att_freq, att_sev, att_cv, \n",
    "                           large_freq, large_sev, large_cv,\n",
    "                           cat_freq, cat_xm, cat_alpha, n_sims):\n",
    "    \"\"\"Update loss distribution visualization.\"\"\"\n",
    "    \n",
    "    # Create generator with parameters\n",
    "    generator = ManufacturingLossGenerator(\n",
    "        attritional_params={\n",
    "            'base_frequency': att_freq,\n",
    "            'severity_mean': att_sev,\n",
    "            'severity_cv': att_cv\n",
    "        },\n",
    "        large_params={\n",
    "            'base_frequency': large_freq,\n",
    "            'severity_mean': large_sev,\n",
    "            'severity_cv': large_cv\n",
    "        },\n",
    "        catastrophic_params={\n",
    "            'base_frequency': cat_freq,\n",
    "            'severity_xm': cat_xm,\n",
    "            'severity_alpha': cat_alpha\n",
    "        },\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Generate losses\n",
    "    all_losses = []\n",
    "    loss_types = []\n",
    "    \n",
    "    for _ in range(n_sims):\n",
    "        events, _ = generator.generate_losses(duration=1.0, revenue=10_000_000)\n",
    "        for event in events:\n",
    "            all_losses.append(event.amount)\n",
    "            loss_types.append(event.loss_type)\n",
    "    \n",
    "    if not all_losses:\n",
    "        print(\"No losses generated. Try adjusting parameters.\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'amount': all_losses,\n",
    "        'type': loss_types\n",
    "    })\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Loss Distribution by Type',\n",
    "            'Empirical CDF',\n",
    "            'Loss Frequency',\n",
    "            'Summary Statistics'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'histogram'}, {'type': 'scatter'}],\n",
    "            [{'type': 'bar'}, {'type': 'table'}]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Histogram by type\n",
    "    for loss_type in df['type'].unique():\n",
    "        type_data = df[df['type'] == loss_type]['amount']\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=type_data,\n",
    "                name=loss_type,\n",
    "                opacity=0.7,\n",
    "                nbinsx=30\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Empirical CDF\n",
    "    sorted_losses = np.sort(all_losses)\n",
    "    cdf = np.arange(1, len(sorted_losses) + 1) / len(sorted_losses)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=sorted_losses,\n",
    "            y=cdf,\n",
    "            mode='lines',\n",
    "            name='ECDF',\n",
    "            line=dict(color=WSJ_COLORS['blue'])\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Loss frequency by type\n",
    "    freq_data = df.groupby('type').size().reset_index(name='count')\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=freq_data['type'],\n",
    "            y=freq_data['count'],\n",
    "            marker_color=[WSJ_COLORS['blue'], WSJ_COLORS['orange'], WSJ_COLORS['red']]\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Summary statistics table\n",
    "    stats = df.groupby('type')['amount'].agg([\n",
    "        'count', 'mean', 'std', 'min', 'max'\n",
    "    ]).round(0)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Table(\n",
    "            header=dict(\n",
    "                values=['Type', 'Count', 'Mean', 'Std', 'Min', 'Max'],\n",
    "                fill_color=WSJ_COLORS['light_gray'],\n",
    "                align='left'\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[\n",
    "                    stats.index,\n",
    "                    stats['count'],\n",
    "                    ['${:,.0f}'.format(x) for x in stats['mean']],\n",
    "                    ['${:,.0f}'.format(x) for x in stats['std']],\n",
    "                    ['${:,.0f}'.format(x) for x in stats['min']],\n",
    "                    ['${:,.0f}'.format(x) for x in stats['max']]\n",
    "                ],\n",
    "                align='left'\n",
    "            )\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        title_text=f\"Loss Distribution Analysis ({n_sims:,} simulations)\",\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Loss Amount ($)\", row=1, col=1, tickformat='$,.0f')\n",
    "    fig.update_xaxes(title_text=\"Loss Amount ($)\", row=1, col=2, tickformat='$,.0f', type='log')\n",
    "    fig.update_xaxes(title_text=\"Loss Type\", row=2, col=1)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Cumulative Probability\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Count\", row=2, col=1)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nTotal losses generated: {len(all_losses):,}\")\n",
    "    print(f\"Average annual loss: ${np.mean(all_losses):,.0f}\")\n",
    "    print(f\"95th percentile: ${np.percentile(all_losses, 95):,.0f}\")\n",
    "    print(f\"99th percentile: ${np.percentile(all_losses, 99):,.0f}\")\n",
    "    print(f\"Maximum loss: ${np.max(all_losses):,.0f}\")\n",
    "\n",
    "# Create interactive interface\n",
    "print(\"Adjust parameters to explore loss distributions:\")\n",
    "print()\n",
    "\n",
    "attritional_box = widgets.VBox([\n",
    "    widgets.HTML(\"<b>Attritional Losses</b>\"),\n",
    "    attritional_freq,\n",
    "    attritional_severity,\n",
    "    attritional_cv\n",
    "])\n",
    "\n",
    "large_box = widgets.VBox([\n",
    "    widgets.HTML(\"<b>Large Losses</b>\"),\n",
    "    large_freq,\n",
    "    large_severity,\n",
    "    large_cv\n",
    "])\n",
    "\n",
    "cat_box = widgets.VBox([\n",
    "    widgets.HTML(\"<b>Catastrophic Losses</b>\"),\n",
    "    cat_freq,\n",
    "    cat_xm,\n",
    "    cat_alpha\n",
    "])\n",
    "\n",
    "params_box = widgets.HBox([attritional_box, large_box, cat_box])\n",
    "controls = widgets.VBox([params_box, n_simulations])\n",
    "\n",
    "output = widgets.interactive_output(\n",
    "    update_loss_distribution,\n",
    "    {\n",
    "        'att_freq': attritional_freq,\n",
    "        'att_sev': attritional_severity,\n",
    "        'att_cv': attritional_cv,\n",
    "        'large_freq': large_freq,\n",
    "        'large_sev': large_severity,\n",
    "        'large_cv': large_cv,\n",
    "        'cat_freq': cat_freq,\n",
    "        'cat_xm': cat_xm,\n",
    "        'cat_alpha': cat_alpha,\n",
    "        'n_sims': n_simulations\n",
    "    }\n",
    ")\n",
    "\n",
    "display(controls, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Loss Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_temporal_losses(years=10, seed=42):\n",
    "    \"\"\"Simulate losses over multiple years.\"\"\"\n",
    "    \n",
    "    generator = ManufacturingLossGenerator(\n",
    "        attritional_params={\n",
    "            'base_frequency': 5.0,\n",
    "            'severity_mean': 50_000,\n",
    "            'severity_cv': 0.8\n",
    "        },\n",
    "        large_params={\n",
    "            'base_frequency': 0.5,\n",
    "            'severity_mean': 2_000_000,\n",
    "            'severity_cv': 1.2\n",
    "        },\n",
    "        catastrophic_params={\n",
    "            'base_frequency': 0.02,\n",
    "            'severity_xm': 10_000_000,\n",
    "            'severity_alpha': 2.5\n",
    "        },\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    yearly_data = []\n",
    "    \n",
    "    for year in range(years):\n",
    "        events, stats = generator.generate_losses(duration=1.0, revenue=10_000_000)\n",
    "        \n",
    "        yearly_data.append({\n",
    "            'year': year + 1,\n",
    "            'total_loss': stats['total_amount'],\n",
    "            'num_events': len(events),\n",
    "            'attritional': sum(e.amount for e in events if e.loss_type == 'attritional'),\n",
    "            'large': sum(e.amount for e in events if e.loss_type == 'large'),\n",
    "            'catastrophic': sum(e.amount for e in events if e.loss_type == 'catastrophic')\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(yearly_data)\n",
    "\n",
    "# Simulate temporal losses\n",
    "temporal_df = simulate_temporal_losses(years=20)\n",
    "\n",
    "# Create temporal visualization\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    subplot_titles=(\n",
    "        'Annual Total Losses',\n",
    "        'Loss Composition by Type',\n",
    "        'Cumulative Losses'\n",
    "    ),\n",
    "    row_heights=[0.35, 0.35, 0.3]\n",
    ")\n",
    "\n",
    "# Annual total losses\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=temporal_df['year'],\n",
    "        y=temporal_df['total_loss'],\n",
    "        name='Total Loss',\n",
    "        marker_color=WSJ_COLORS['blue']\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add mean line\n",
    "mean_loss = temporal_df['total_loss'].mean()\n",
    "fig.add_hline(\n",
    "    y=mean_loss,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=WSJ_COLORS['red'],\n",
    "    annotation_text=f\"Mean: ${mean_loss:,.0f}\",\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Stacked bar chart by type\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=temporal_df['year'],\n",
    "        y=temporal_df['attritional'],\n",
    "        name='Attritional',\n",
    "        marker_color=WSJ_COLORS['light_blue']\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=temporal_df['year'],\n",
    "        y=temporal_df['large'],\n",
    "        name='Large',\n",
    "        marker_color=WSJ_COLORS['orange']\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=temporal_df['year'],\n",
    "        y=temporal_df['catastrophic'],\n",
    "        name='Catastrophic',\n",
    "        marker_color=WSJ_COLORS['red']\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Cumulative losses\n",
    "temporal_df['cumulative'] = temporal_df['total_loss'].cumsum()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=temporal_df['year'],\n",
    "        y=temporal_df['cumulative'],\n",
    "        mode='lines+markers',\n",
    "        name='Cumulative',\n",
    "        line=dict(color=WSJ_COLORS['blue'], width=2)\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=900,\n",
    "    showlegend=True,\n",
    "    title_text=\"Temporal Loss Pattern Analysis (20 Years)\",\n",
    "    template='plotly_white',\n",
    "    barmode='stack'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Year\")\n",
    "fig.update_yaxes(title_text=\"Loss Amount ($)\", tickformat='$,.0f')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nTemporal Loss Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Mean annual loss: ${temporal_df['total_loss'].mean():,.0f}\")\n",
    "print(f\"Std deviation: ${temporal_df['total_loss'].std():,.0f}\")\n",
    "print(f\"Coefficient of variation: {temporal_df['total_loss'].std()/temporal_df['total_loss'].mean():.2f}\")\n",
    "print(f\"Min annual loss: ${temporal_df['total_loss'].min():,.0f}\")\n",
    "print(f\"Max annual loss: ${temporal_df['total_loss'].max():,.0f}\")\n",
    "print(f\"Years with catastrophic losses: {(temporal_df['catastrophic'] > 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extreme Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extreme_value_analysis(n_simulations=10000):\n",
    "    \"\"\"Analyze extreme values and tail behavior.\"\"\"\n",
    "    \n",
    "    generator = ManufacturingLossGenerator(\n",
    "        attritional_params={\n",
    "            'base_frequency': 5.0,\n",
    "            'severity_mean': 50_000,\n",
    "            'severity_cv': 0.8\n",
    "        },\n",
    "        large_params={\n",
    "            'base_frequency': 0.5,\n",
    "            'severity_mean': 2_000_000,\n",
    "            'severity_cv': 1.2\n",
    "        },\n",
    "        catastrophic_params={\n",
    "            'base_frequency': 0.02,\n",
    "            'severity_xm': 10_000_000,\n",
    "            'severity_alpha': 2.5\n",
    "        },\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Simulate annual maximum losses\n",
    "    annual_maxima = []\n",
    "    annual_totals = []\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        events, stats = generator.generate_losses(duration=1.0, revenue=10_000_000)\n",
    "        if events:\n",
    "            annual_maxima.append(max(e.amount for e in events))\n",
    "        else:\n",
    "            annual_maxima.append(0)\n",
    "        annual_totals.append(stats['total_amount'])\n",
    "    \n",
    "    # Sort for percentile analysis\n",
    "    sorted_maxima = np.sort(annual_maxima)\n",
    "    sorted_totals = np.sort(annual_totals)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Distribution of Annual Maximum Losses',\n",
    "            'Exceedance Probability',\n",
    "            'Return Period Analysis',\n",
    "            'Tail Distribution (Log-Log)'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Distribution of annual maxima\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=annual_maxima,\n",
    "            nbinsx=50,\n",
    "            name='Annual Max',\n",
    "            marker_color=WSJ_COLORS['blue']\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Exceedance probability\n",
    "    exceedance_prob = 1 - np.arange(len(sorted_totals)) / len(sorted_totals)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=sorted_totals,\n",
    "            y=exceedance_prob,\n",
    "            mode='lines',\n",
    "            name='Annual Total',\n",
    "            line=dict(color=WSJ_COLORS['blue'])\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Return period analysis\n",
    "    return_periods = [2, 5, 10, 20, 50, 100, 200, 500]\n",
    "    return_levels_max = []\n",
    "    return_levels_total = []\n",
    "    \n",
    "    for rp in return_periods:\n",
    "        percentile = 100 * (1 - 1/rp)\n",
    "        return_levels_max.append(np.percentile(annual_maxima, percentile))\n",
    "        return_levels_total.append(np.percentile(annual_totals, percentile))\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=return_periods,\n",
    "            y=return_levels_max,\n",
    "            mode='lines+markers',\n",
    "            name='Max Loss',\n",
    "            line=dict(color=WSJ_COLORS['red'])\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=return_periods,\n",
    "            y=return_levels_total,\n",
    "            mode='lines+markers',\n",
    "            name='Total Loss',\n",
    "            line=dict(color=WSJ_COLORS['blue'])\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Tail distribution (log-log plot)\n",
    "    # Only plot non-zero values for log scale\n",
    "    non_zero_maxima = [x for x in sorted_maxima if x > 0]\n",
    "    if non_zero_maxima:\n",
    "        tail_prob = 1 - np.arange(len(non_zero_maxima)) / len(non_zero_maxima)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=non_zero_maxima,\n",
    "                y=tail_prob,\n",
    "                mode='markers',\n",
    "                name='Empirical',\n",
    "                marker=dict(size=3, color=WSJ_COLORS['blue'])\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        title_text=f\"Extreme Value Analysis ({n_simulations:,} simulations)\",\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Loss Amount ($)\", row=1, col=1, tickformat='$,.0f')\n",
    "    fig.update_xaxes(title_text=\"Loss Amount ($)\", row=1, col=2, tickformat='$,.0f', type='log')\n",
    "    fig.update_xaxes(title_text=\"Return Period (years)\", row=2, col=1, type='log')\n",
    "    fig.update_xaxes(title_text=\"Loss Amount ($)\", row=2, col=2, type='log', tickformat='$,.0f')\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Exceedance Probability\", row=1, col=2, type='log')\n",
    "    fig.update_yaxes(title_text=\"Return Level ($)\", row=2, col=1, tickformat='$,.0f')\n",
    "    fig.update_yaxes(title_text=\"Exceedance Probability\", row=2, col=2, type='log')\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Print return period table\n",
    "    print(\"\\nReturn Period Analysis:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Return Period':<15} {'Max Loss':<20} {'Total Loss':<20}\")\n",
    "    print(\"-\"*70)\n",
    "    for i, rp in enumerate(return_periods):\n",
    "        print(f\"{rp:>10} year {'${:,.0f}'.format(return_levels_max[i]):<20} {'${:,.0f}'.format(return_levels_total[i]):<20}\")\n",
    "\n",
    "# Run extreme value analysis\n",
    "extreme_value_analysis(n_simulations=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_analysis(n_years=100):\n",
    "    \"\"\"Analyze correlations between different loss types.\"\"\"\n",
    "    \n",
    "    generator = ManufacturingLossGenerator(\n",
    "        attritional_params={\n",
    "            'base_frequency': 5.0,\n",
    "            'severity_mean': 50_000,\n",
    "            'severity_cv': 0.8\n",
    "        },\n",
    "        large_params={\n",
    "            'base_frequency': 0.5,\n",
    "            'severity_mean': 2_000_000,\n",
    "            'severity_cv': 1.2\n",
    "        },\n",
    "        catastrophic_params={\n",
    "            'base_frequency': 0.02,\n",
    "            'severity_xm': 10_000_000,\n",
    "            'severity_alpha': 2.5\n",
    "        },\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Simulate multiple years\n",
    "    data = {\n",
    "        'year': [],\n",
    "        'attritional_count': [],\n",
    "        'attritional_total': [],\n",
    "        'large_count': [],\n",
    "        'large_total': [],\n",
    "        'catastrophic_count': [],\n",
    "        'catastrophic_total': [],\n",
    "        'total_loss': []\n",
    "    }\n",
    "    \n",
    "    for year in range(n_years):\n",
    "        events, stats = generator.generate_losses(duration=1.0, revenue=10_000_000)\n",
    "        \n",
    "        att_events = [e for e in events if e.loss_type == 'attritional']\n",
    "        large_events = [e for e in events if e.loss_type == 'large']\n",
    "        cat_events = [e for e in events if e.loss_type == 'catastrophic']\n",
    "        \n",
    "        data['year'].append(year + 1)\n",
    "        data['attritional_count'].append(len(att_events))\n",
    "        data['attritional_total'].append(sum(e.amount for e in att_events))\n",
    "        data['large_count'].append(len(large_events))\n",
    "        data['large_total'].append(sum(e.amount for e in large_events))\n",
    "        data['catastrophic_count'].append(len(cat_events))\n",
    "        data['catastrophic_total'].append(sum(e.amount for e in cat_events))\n",
    "        data['total_loss'].append(stats['total_amount'])\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_cols = ['attritional_total', 'large_total', 'catastrophic_total', 'total_loss']\n",
    "    corr_matrix = df[corr_cols].corr()\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Correlation Heatmap',\n",
    "            'Scatter: Attritional vs Large',\n",
    "            'Loss Components Over Time',\n",
    "            'Distribution of Total Losses'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'heatmap'}, {'type': 'scatter'}],\n",
    "            [{'type': 'scatter'}, {'type': 'histogram'}]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=corr_matrix.values,\n",
    "            x=['Attritional', 'Large', 'Catastrophic', 'Total'],\n",
    "            y=['Attritional', 'Large', 'Catastrophic', 'Total'],\n",
    "            colorscale='RdBu',\n",
    "            zmid=0,\n",
    "            text=corr_matrix.values.round(2),\n",
    "            texttemplate='%{text}',\n",
    "            textfont={\"size\": 10}\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Scatter plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['attritional_total'],\n",
    "            y=df['large_total'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=8,\n",
    "                color=df['total_loss'],\n",
    "                colorscale='Viridis',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"Total Loss\")\n",
    "            ),\n",
    "            name='Years'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Time series of components\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['year'],\n",
    "            y=df['attritional_total'],\n",
    "            mode='lines',\n",
    "            name='Attritional',\n",
    "            line=dict(color=WSJ_COLORS['light_blue'])\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['year'],\n",
    "            y=df['large_total'],\n",
    "            mode='lines',\n",
    "            name='Large',\n",
    "            line=dict(color=WSJ_COLORS['orange'])\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Distribution of total losses\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=df['total_loss'],\n",
    "            nbinsx=30,\n",
    "            name='Total Loss',\n",
    "            marker_color=WSJ_COLORS['blue']\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        title_text=f\"Loss Correlation Analysis ({n_years} years)\",\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Attritional Loss ($)\", row=1, col=2, tickformat='$,.0f')\n",
    "    fig.update_xaxes(title_text=\"Year\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Total Loss ($)\", row=2, col=2, tickformat='$,.0f')\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Large Loss ($)\", row=1, col=2, tickformat='$,.0f')\n",
    "    fig.update_yaxes(title_text=\"Loss Amount ($)\", row=2, col=1, tickformat='$,.0f')\n",
    "    fig.update_yaxes(title_text=\"Frequency\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Print correlation summary\n",
    "    print(\"\\nCorrelation Analysis Summary:\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"\\nCorrelation Matrix:\")\n",
    "    print(corr_matrix.round(3))\n",
    "    print(\"\\nKey Insights:\")\n",
    "    print(f\"- Attritional-Large correlation: {corr_matrix.loc['attritional_total', 'large_total']:.3f}\")\n",
    "    print(f\"- Years with catastrophic losses: {(df['catastrophic_total'] > 0).sum()} ({100*(df['catastrophic_total'] > 0).sum()/n_years:.1f}%)\")\n",
    "    print(f\"- Average contribution to total loss:\")\n",
    "    print(f\"  - Attritional: {100*df['attritional_total'].sum()/df['total_loss'].sum():.1f}%\")\n",
    "    print(f\"  - Large: {100*df['large_total'].sum()/df['total_loss'].sum():.1f}%\")\n",
    "    print(f\"  - Catastrophic: {100*df['catastrophic_total'].sum()/df['total_loss'].sum():.1f}%\")\n",
    "\n",
    "# Run correlation analysis\n",
    "correlation_analysis(n_years=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides comprehensive tools for analyzing manufacturing loss distributions:\n",
    "\n",
    "1. **Interactive Parameter Exploration**: Real-time visualization of how parameters affect loss distributions\n",
    "2. **Temporal Analysis**: Understanding loss patterns over time\n",
    "3. **Extreme Value Analysis**: Return period calculations and tail behavior\n",
    "4. **Correlation Analysis**: Relationships between different loss types\n",
    "\n",
    "Key findings:\n",
    "- Loss distributions are heavily right-skewed with catastrophic events driving tail risk\n",
    "- Different loss types show low correlation, suggesting diversification benefits\n",
    "- Return period analysis is crucial for insurance limit selection\n",
    "- Temporal patterns help identify clustering and volatility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
