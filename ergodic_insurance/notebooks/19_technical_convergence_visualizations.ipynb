{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Convergence and Validation Visualizations\n",
    "\n",
    "This notebook demonstrates the technical appendix visualizations implemented for Issue #65:\n",
    "- Figure A1: Enhanced Convergence Diagnostics\n",
    "- Figure B1: Loss Distribution Validation\n",
    "- Figure C3: Monte Carlo Convergence Analysis\n",
    "\n",
    "These visualizations are designed for technical audiences and provide detailed statistical diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Configure matplotlib for inline display\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "# Import visualization functions\n",
    "from ergodic_insurance.src.visualization.technical_plots import (\n",
    "    plot_enhanced_convergence_diagnostics,\n",
    "    plot_trace_plots,\n",
    "    plot_loss_distribution_validation,\n",
    "    plot_monte_carlo_convergence,\n",
    "    plot_convergence_diagnostics\n",
    ")\n",
    "\n",
    "# Import supporting modules\n",
    "from ergodic_insurance.src.convergence import ConvergenceDiagnostics\n",
    "from ergodic_insurance.src.loss_distributions import LognormalLoss\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Technical visualization modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Figure A1: Convergence Diagnostics\n",
    "\n",
    "The convergence diagnostics visualization provides comprehensive analysis of MCMC chain convergence, including:\n",
    "- Trace plots with burn-in indicators\n",
    "- R-hat (Gelman-Rubin) statistics\n",
    "- Effective Sample Size (ESS)\n",
    "- Autocorrelation functions\n",
    "- Monte Carlo Standard Errors (MCSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic MCMC chains for demonstration\n",
    "def generate_mcmc_chains(n_chains=4, n_iterations=2000, n_params=3, burn_in=500):\n",
    "    \"\"\"Generate synthetic MCMC chains with burn-in period.\"\"\"\n",
    "    chains = np.zeros((n_chains, n_iterations, n_params))\n",
    "    \n",
    "    # Parameter true values and names\n",
    "    true_values = [10.0, 0.5, 2.0]\n",
    "    param_names = [\"Premium Rate\", \"Deductible\", \"Risk Factor\"]\n",
    "    \n",
    "    for chain in range(n_chains):\n",
    "        for param in range(n_params):\n",
    "            # Burn-in period with higher variance and bias\n",
    "            chains[chain, :burn_in, param] = np.random.normal(\n",
    "                true_values[param] * 0.8,  # Biased starting point\n",
    "                true_values[param] * 0.3,  # Higher variance\n",
    "                burn_in\n",
    "            )\n",
    "            \n",
    "            # Post burn-in converged samples\n",
    "            chains[chain, burn_in:, param] = np.random.normal(\n",
    "                true_values[param],\n",
    "                true_values[param] * 0.05,  # Lower variance after convergence\n",
    "                n_iterations - burn_in\n",
    "            )\n",
    "            \n",
    "            # Add some autocorrelation\n",
    "            for t in range(1, n_iterations):\n",
    "                chains[chain, t, param] = 0.3 * chains[chain, t-1, param] + 0.7 * chains[chain, t, param]\n",
    "    \n",
    "    return chains, param_names\n",
    "\n",
    "# Generate chains\n",
    "chains, param_names = generate_mcmc_chains()\n",
    "print(f\"Generated MCMC chains: shape = {chains.shape}\")\n",
    "print(f\"Parameters: {param_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trace plots\n",
    "fig_trace = plot_trace_plots(\n",
    "    chains,\n",
    "    parameter_names=param_names,\n",
    "    burn_in=500,\n",
    "    title=\"MCMC Trace Plots with Burn-in Period\",\n",
    "    figsize=(14, 8)\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTrace plots show:\")\n",
    "print(\"- Multiple chains exploring parameter space\")\n",
    "print(\"- Burn-in period (first 500 iterations) shaded\")\n",
    "print(\"- Convergence to stable distribution after burn-in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced convergence diagnostics\n",
    "fig_diagnostics = plot_enhanced_convergence_diagnostics(\n",
    "    chains,\n",
    "    parameter_names=param_names,\n",
    "    burn_in=500,\n",
    "    title=\"Figure A1: Enhanced Convergence Diagnostics\",\n",
    "    figsize=(14, 10)\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDiagnostics interpretation:\")\n",
    "print(\"- R-hat < 1.1 indicates good convergence\")\n",
    "print(\"- ESS > 1000 suggests adequate effective samples\")\n",
    "print(\"- Declining autocorrelation shows good mixing\")\n",
    "print(\"- Low MCSE indicates stable estimates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display convergence statistics\n",
    "diag = ConvergenceDiagnostics()\n",
    "\n",
    "# Calculate statistics after burn-in\n",
    "post_burnin_chains = chains[:, 500:, :]\n",
    "\n",
    "# R-hat for each parameter\n",
    "print(\"R-hat Statistics (Gelman-Rubin):\")\n",
    "for i, param in enumerate(param_names):\n",
    "    r_hat = diag.calculate_r_hat(post_burnin_chains[:, :, i:i+1])\n",
    "    print(f\"  {param}: {r_hat:.4f} {'✓' if r_hat < 1.1 else '✗'}\")\n",
    "\n",
    "# ESS for each parameter\n",
    "print(\"\\nEffective Sample Size:\")\n",
    "for i, param in enumerate(param_names):\n",
    "    pooled = post_burnin_chains[:, :, i].flatten()\n",
    "    ess = diag.calculate_ess(pooled)\n",
    "    print(f\"  {param}: {ess:.0f} samples {'✓' if ess > 1000 else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Figure B1: Loss Distribution Validation\n",
    "\n",
    "The loss distribution validation plots provide:\n",
    "- Q-Q plots comparing empirical vs theoretical distributions\n",
    "- CDF comparisons with goodness-of-fit metrics\n",
    "- Kolmogorov-Smirnov test statistics\n",
    "- MSE and maximum deviation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic loss data\n",
    "def generate_loss_data():\n",
    "    \"\"\"Generate realistic loss data for validation.\"\"\"\n",
    "    # Attritional losses (high frequency, low severity)\n",
    "    attritional_gen = LognormalLoss(mean=50_000, cv=0.5, seed=42)\n",
    "    attritional_losses = attritional_gen.generate_severity(2000)\n",
    "    \n",
    "    # Large losses (low frequency, high severity)\n",
    "    large_gen = LognormalLoss(mean=1_000_000, cv=1.5, seed=43)\n",
    "    large_losses = large_gen.generate_severity(200)\n",
    "    \n",
    "    # Add some outliers for realism\n",
    "    attritional_losses[::100] *= 3  # 1% outliers\n",
    "    large_losses[::50] *= 5  # 2% extreme events\n",
    "    \n",
    "    return attritional_losses, large_losses\n",
    "\n",
    "attritional_losses, large_losses = generate_loss_data()\n",
    "\n",
    "print(\"Loss Data Summary:\")\n",
    "print(f\"\\nAttritional Losses:\")\n",
    "print(f\"  Count: {len(attritional_losses)}\")\n",
    "print(f\"  Mean: ${np.mean(attritional_losses):,.0f}\")\n",
    "print(f\"  Median: ${np.median(attritional_losses):,.0f}\")\n",
    "print(f\"  95th percentile: ${np.percentile(attritional_losses, 95):,.0f}\")\n",
    "\n",
    "print(f\"\\nLarge Losses:\")\n",
    "print(f\"  Count: {len(large_losses)}\")\n",
    "print(f\"  Mean: ${np.mean(large_losses):,.0f}\")\n",
    "print(f\"  Median: ${np.median(large_losses):,.0f}\")\n",
    "print(f\"  95th percentile: ${np.percentile(large_losses, 95):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss distribution validation plots\n",
    "fig_validation = plot_loss_distribution_validation(\n",
    "    attritional_losses,\n",
    "    large_losses,\n",
    "    title=\"Figure B1: Loss Distribution Validation\",\n",
    "    figsize=(14, 12)\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nValidation plots interpretation:\")\n",
    "print(\"- Q-Q plots: Points close to diagonal line indicate good fit\")\n",
    "print(\"- K-S test: p-value > 0.05 suggests distributions match\")\n",
    "print(\"- CDF comparison: Visual alignment between empirical and theoretical\")\n",
    "print(\"- MSE: Lower values indicate better fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform additional distribution tests\n",
    "from scipy.stats import anderson, shapiro\n",
    "\n",
    "# Log-transform for normality tests\n",
    "log_attritional = np.log(attritional_losses)\n",
    "log_large = np.log(large_losses)\n",
    "\n",
    "print(\"Distribution Tests (on log-transformed data):\")\n",
    "print(\"\\nShapiro-Wilk Test (Normality):\")\n",
    "\n",
    "# Shapiro test (use subset for large samples)\n",
    "stat_att, p_att = shapiro(log_attritional[:1000])\n",
    "stat_large, p_large = shapiro(log_large)\n",
    "\n",
    "print(f\"  Attritional: statistic={stat_att:.4f}, p-value={p_att:.4f}\")\n",
    "print(f\"  Large: statistic={stat_large:.4f}, p-value={p_large:.4f}\")\n",
    "\n",
    "print(\"\\nAnderson-Darling Test:\")\n",
    "result_att = anderson(log_attritional)\n",
    "result_large = anderson(log_large)\n",
    "\n",
    "print(f\"  Attritional: statistic={result_att.statistic:.4f}\")\n",
    "print(f\"    Critical values at significance levels: {result_att.critical_values}\")\n",
    "print(f\"  Large: statistic={result_large.statistic:.4f}\")\n",
    "print(f\"    Critical values at significance levels: {result_large.critical_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Figure C3: Monte Carlo Convergence Analysis\n",
    "\n",
    "The Monte Carlo convergence analysis shows:\n",
    "- Evolution of key metrics over iterations\n",
    "- Running mean and confidence intervals\n",
    "- Convergence status indicators\n",
    "- Threshold comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Monte Carlo convergence for insurance metrics\n",
    "def simulate_monte_carlo_metrics(n_iterations=10000):\n",
    "    \"\"\"Simulate convergence of insurance metrics.\"\"\"\n",
    "    metrics_history = {}\n",
    "    \n",
    "    # ROE convergence (target: 12%)\n",
    "    true_roe = 0.12\n",
    "    roe_noise = 0.05\n",
    "    roe_values = []\n",
    "    \n",
    "    # Ruin probability convergence (target: 0.8%)\n",
    "    true_ruin = 0.008\n",
    "    ruin_noise = 0.005\n",
    "    ruin_values = []\n",
    "    \n",
    "    # Sharpe ratio convergence (target: 1.5)\n",
    "    true_sharpe = 1.5\n",
    "    sharpe_noise = 0.3\n",
    "    sharpe_values = []\n",
    "    \n",
    "    # Premium adequacy convergence (target: 1.25)\n",
    "    true_adequacy = 1.25\n",
    "    adequacy_noise = 0.15\n",
    "    adequacy_values = []\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # Decreasing variance as iterations increase (convergence)\n",
    "        variance_factor = 1.0 / np.sqrt(i + 1)\n",
    "        \n",
    "        # Add some realistic jumps and patterns\n",
    "        if i % 1000 == 0 and i > 0:  # Occasional jumps\n",
    "            jump_factor = 1.5\n",
    "        else:\n",
    "            jump_factor = 1.0\n",
    "        \n",
    "        # Generate values with decreasing noise\n",
    "        roe_values.append(true_roe + np.random.normal(0, roe_noise * variance_factor * jump_factor))\n",
    "        ruin_values.append(max(0, true_ruin + np.random.normal(0, ruin_noise * variance_factor * jump_factor)))\n",
    "        sharpe_values.append(true_sharpe + np.random.normal(0, sharpe_noise * variance_factor * jump_factor))\n",
    "        adequacy_values.append(true_adequacy + np.random.normal(0, adequacy_noise * variance_factor * jump_factor))\n",
    "    \n",
    "    metrics_history = {\n",
    "        \"ROE (%)\": [v * 100 for v in roe_values],\n",
    "        \"Ruin Probability (%)\": [v * 100 for v in ruin_values],\n",
    "        \"Sharpe Ratio\": sharpe_values,\n",
    "        \"Premium Adequacy\": adequacy_values\n",
    "    }\n",
    "    \n",
    "    return metrics_history\n",
    "\n",
    "# Generate convergence data\n",
    "metrics_history = simulate_monte_carlo_metrics()\n",
    "\n",
    "print(\"Monte Carlo Simulation Metrics:\")\n",
    "for metric, values in metrics_history.items():\n",
    "    final_mean = np.mean(values[-1000:])\n",
    "    final_std = np.std(values[-1000:])\n",
    "    print(f\"  {metric}: {final_mean:.3f} ± {final_std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Monte Carlo convergence plots\n",
    "convergence_thresholds = {\n",
    "    \"ROE (%)\": 12.0,\n",
    "    \"Ruin Probability (%)\": 1.0,\n",
    "    \"Sharpe Ratio\": 1.5,\n",
    "    \"Premium Adequacy\": 1.25\n",
    "}\n",
    "\n",
    "fig_mc = plot_monte_carlo_convergence(\n",
    "    metrics_history,\n",
    "    convergence_thresholds=convergence_thresholds,\n",
    "    title=\"Figure C3: Monte Carlo Convergence Analysis\",\n",
    "    figsize=(16, 12),\n",
    "    log_scale=True\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConvergence analysis interpretation:\")\n",
    "print(\"- Log-scale x-axis shows early vs late convergence behavior\")\n",
    "print(\"- Running mean stabilizes as iterations increase\")\n",
    "print(\"- Confidence bands narrow with more samples\")\n",
    "print(\"- Green status indicates successful convergence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze convergence rates\n",
    "def analyze_convergence_rate(values, window_sizes=[100, 500, 1000, 5000]):\n",
    "    \"\"\"Analyze convergence at different window sizes.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for window in window_sizes:\n",
    "        if len(values) >= window * 2:\n",
    "            early_mean = np.mean(values[:window])\n",
    "            late_mean = np.mean(values[-window:])\n",
    "            relative_change = abs(late_mean - early_mean) / abs(early_mean) * 100\n",
    "            \n",
    "            results.append({\n",
    "                'Window': window,\n",
    "                'Early Mean': early_mean,\n",
    "                'Late Mean': late_mean,\n",
    "                'Relative Change (%)': relative_change,\n",
    "                'Converged': relative_change < 1.0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Convergence Rate Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric_name, values in metrics_history.items():\n",
    "    print(f\"\\n{metric_name}:\")\n",
    "    df = analyze_convergence_rate(values)\n",
    "    print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combined Technical Dashboard\n",
    "\n",
    "Create a comprehensive technical appendix figure combining all diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive technical dashboard\n",
    "fig = plt.figure(figsize=(18, 20))\n",
    "\n",
    "# Layout: 3 rows for the three main figure types\n",
    "gs = fig.add_gridspec(3, 1, height_ratios=[1, 1, 1], hspace=0.25)\n",
    "\n",
    "# Row 1: Convergence diagnostics summary\n",
    "gs1 = gs[0].subgridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Trace plot for first parameter\n",
    "ax1 = fig.add_subplot(gs1[0, :])\n",
    "for chain_idx in range(chains.shape[0]):\n",
    "    ax1.plot(chains[chain_idx, :, 0], alpha=0.7, linewidth=0.8)\n",
    "ax1.axvline(x=500, color='red', linestyle='--', alpha=0.5)\n",
    "ax1.set_title(f\"Trace Plot: {param_names[0]}\")\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.set_ylabel(\"Value\")\n",
    "\n",
    "# R-hat values\n",
    "ax2 = fig.add_subplot(gs1[1, 0])\n",
    "r_hats = [diag.calculate_r_hat(chains[:, 500:, i:i+1]) for i in range(3)]\n",
    "bars = ax2.bar(param_names, r_hats)\n",
    "ax2.axhline(y=1.1, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.set_title(\"R-hat Statistics\")\n",
    "ax2.set_ylabel(\"R-hat\")\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# ESS values\n",
    "ax3 = fig.add_subplot(gs1[1, 1])\n",
    "ess_values = [diag.calculate_ess(chains[:, 500:, i].flatten()) for i in range(3)]\n",
    "bars = ax3.bar(param_names, ess_values)\n",
    "ax3.axhline(y=1000, color='red', linestyle='--', alpha=0.5)\n",
    "ax3.set_title(\"Effective Sample Size\")\n",
    "ax3.set_ylabel(\"ESS\")\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Autocorrelation for first parameter\n",
    "ax4 = fig.add_subplot(gs1[1, 2])\n",
    "chain_data = chains[0, 500:, 0]\n",
    "acf_values = [np.corrcoef(chain_data[:-lag], chain_data[lag:])[0, 1] if lag > 0 else 1.0 \n",
    "              for lag in range(20)]\n",
    "ax4.bar(range(20), acf_values, alpha=0.7)\n",
    "ax4.set_title(f\"ACF: {param_names[0]}\")\n",
    "ax4.set_xlabel(\"Lag\")\n",
    "ax4.set_ylabel(\"Autocorrelation\")\n",
    "\n",
    "# Row 2: Loss distribution validation\n",
    "gs2 = gs[1].subgridspec(1, 2, wspace=0.3)\n",
    "\n",
    "# Q-Q plot for attritional losses\n",
    "ax5 = fig.add_subplot(gs2[0])\n",
    "stats.probplot(attritional_losses, dist=\"lognorm\", plot=ax5)\n",
    "ax5.set_title(\"Q-Q Plot: Attritional Losses\")\n",
    "\n",
    "# Q-Q plot for large losses\n",
    "ax6 = fig.add_subplot(gs2[1])\n",
    "stats.probplot(large_losses, dist=\"lognorm\", plot=ax6)\n",
    "ax6.set_title(\"Q-Q Plot: Large Losses\")\n",
    "\n",
    "# Row 3: Monte Carlo convergence\n",
    "gs3 = gs[2].subgridspec(1, 2, wspace=0.3)\n",
    "\n",
    "# ROE convergence\n",
    "ax7 = fig.add_subplot(gs3[0])\n",
    "iterations = np.arange(1, len(metrics_history[\"ROE (%)\"]) + 1)\n",
    "running_mean = [np.mean(metrics_history[\"ROE (%)\"][:i]) for i in range(1, len(metrics_history[\"ROE (%)\"]) + 1)]\n",
    "ax7.plot(iterations[::10], metrics_history[\"ROE (%)\"][::10], alpha=0.3, label=\"Raw\")\n",
    "ax7.plot(iterations[::10], running_mean[::10], linewidth=2, label=\"Running Mean\")\n",
    "ax7.axhline(y=12.0, color='red', linestyle='--', alpha=0.5, label=\"Target\")\n",
    "ax7.set_xscale('log')\n",
    "ax7.set_title(\"ROE Convergence\")\n",
    "ax7.set_xlabel(\"Iterations (log scale)\")\n",
    "ax7.set_ylabel(\"ROE (%)\")\n",
    "ax7.legend()\n",
    "\n",
    "# Ruin probability convergence\n",
    "ax8 = fig.add_subplot(gs3[1])\n",
    "running_mean_ruin = [np.mean(metrics_history[\"Ruin Probability (%)\"][:i]) \n",
    "                     for i in range(1, len(metrics_history[\"Ruin Probability (%)\"]) + 1)]\n",
    "ax8.plot(iterations[::10], metrics_history[\"Ruin Probability (%)\"][::10], alpha=0.3, label=\"Raw\")\n",
    "ax8.plot(iterations[::10], running_mean_ruin[::10], linewidth=2, label=\"Running Mean\")\n",
    "ax8.axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label=\"Threshold\")\n",
    "ax8.set_xscale('log')\n",
    "ax8.set_title(\"Ruin Probability Convergence\")\n",
    "ax8.set_xlabel(\"Iterations (log scale)\")\n",
    "ax8.set_ylabel(\"Ruin Probability (%)\")\n",
    "ax8.legend()\n",
    "\n",
    "plt.suptitle(\"Technical Appendix: Convergence and Validation Dashboard\", fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTechnical dashboard created successfully!\")\n",
    "print(\"This comprehensive view provides all key diagnostics for:\")\n",
    "print(\"- MCMC convergence assessment\")\n",
    "print(\"- Loss distribution validation\")\n",
    "print(\"- Monte Carlo convergence tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export and Save Figures\n",
    "\n",
    "Export the technical figures for inclusion in reports and presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save figures in multiple formats\n",
    "def save_technical_figures():\n",
    "    \"\"\"Save all technical figures in high quality.\"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"../../results/technical_figures\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Generating and saving technical figures...\")\n",
    "    \n",
    "    # Figure A1: Enhanced Convergence Diagnostics\n",
    "    fig_a1 = plot_enhanced_convergence_diagnostics(\n",
    "        chains,\n",
    "        parameter_names=param_names,\n",
    "        burn_in=500,\n",
    "        figsize=(10, 8)\n",
    "    )\n",
    "    fig_a1.savefig(f\"{output_dir}/figure_A1_convergence_diagnostics.pdf\", dpi=300, bbox_inches='tight')\n",
    "    fig_a1.savefig(f\"{output_dir}/figure_A1_convergence_diagnostics.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_a1)\n",
    "    print(\"  ✓ Figure A1 saved\")\n",
    "    \n",
    "    # Figure B1: Loss Distribution Validation\n",
    "    fig_b1 = plot_loss_distribution_validation(\n",
    "        attritional_losses,\n",
    "        large_losses,\n",
    "        figsize=(10, 8)\n",
    "    )\n",
    "    fig_b1.savefig(f\"{output_dir}/figure_B1_loss_validation.pdf\", dpi=300, bbox_inches='tight')\n",
    "    fig_b1.savefig(f\"{output_dir}/figure_B1_loss_validation.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_b1)\n",
    "    print(\"  ✓ Figure B1 saved\")\n",
    "    \n",
    "    # Figure C3: Monte Carlo Convergence\n",
    "    fig_c3 = plot_monte_carlo_convergence(\n",
    "        metrics_history,\n",
    "        convergence_thresholds=convergence_thresholds,\n",
    "        figsize=(10, 8),\n",
    "        log_scale=True\n",
    "    )\n",
    "    fig_c3.savefig(f\"{output_dir}/figure_C3_mc_convergence.pdf\", dpi=300, bbox_inches='tight')\n",
    "    fig_c3.savefig(f\"{output_dir}/figure_C3_mc_convergence.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_c3)\n",
    "    print(\"  ✓ Figure C3 saved\")\n",
    "    \n",
    "    print(f\"\\nAll figures saved to: {os.path.abspath(output_dir)}\")\n",
    "    print(\"Formats: PDF (for publication) and PNG (for presentations)\")\n",
    "\n",
    "# Uncomment to save figures\n",
    "# save_technical_figures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the implementation of technical convergence and validation visualizations:\n",
    "\n",
    "### Key Features Implemented:\n",
    "\n",
    "1. **Figure A1: Enhanced Convergence Diagnostics**\n",
    "   - Multi-panel layout with trace plots, R-hat evolution, ESS, ACF, and MCSE\n",
    "   - Burn-in period visualization and marking\n",
    "   - Comprehensive convergence assessment tools\n",
    "\n",
    "2. **Figure B1: Loss Distribution Validation**\n",
    "   - Q-Q plots for attritional and large losses\n",
    "   - CDF comparisons with empirical vs theoretical\n",
    "   - K-S test statistics and goodness-of-fit metrics\n",
    "   - Automatic distribution fitting and validation\n",
    "\n",
    "3. **Figure C3: Monte Carlo Convergence Analysis**\n",
    "   - Running mean and variance tracking\n",
    "   - Confidence interval visualization\n",
    "   - Log-scale iteration axis for detailed convergence view\n",
    "   - Convergence status indicators with relative change metrics\n",
    "\n",
    "### Technical Standards Met:\n",
    "- All plots follow professional technical standards\n",
    "- Statistical tests are correctly implemented\n",
    "- Convergence criteria are clearly visualized\n",
    "- Plots are suitable for technical appendix (10×8 inches)\n",
    "- Mathematical formulas and metrics are accurately calculated\n",
    "\n",
    "### Usage:\n",
    "These visualizations are designed for:\n",
    "- Technical documentation and appendices\n",
    "- Model validation reports\n",
    "- Academic publications\n",
    "- Regulatory submissions\n",
    "- Internal technical reviews\n",
    "\n",
    "The implementation provides actuaries and data scientists with professional-grade diagnostic tools for validating Monte Carlo simulations and statistical models in insurance applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
