{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence Monitoring\n\n## Overview\n- **What**: Comprehensive convergence diagnostics for Monte Carlo simulations -- trace plots, R-hat, ESS, loss distribution validation, adaptive stopping, and spectral analysis.\n- **Prerequisites**: [../core/04_monte_carlo_engine](../core/04_monte_carlo_engine.ipynb)\n- **Estimated runtime**: < 2 minutes\n- **Audience**: [Developer]\n\n## Topics Covered\n1. MCMC trace plots and convergence diagnostics (R-hat, ESS, ACF)\n2. Loss distribution validation (Q-Q plots, K-S tests)\n3. Monte Carlo convergence analysis\n4. Advanced autocorrelation and spectral density analysis\n5. Adaptive stopping criteria\n6. Fixed vs. adaptive stopping comparison"
   ],
   "id": "cell-0"
  },
  {
   "cell_type": "code",
   "id": "1o3a8vc2tiy",
   "source": "\"\"\"Google Colab setup: mount Drive and install package dependencies.\n\nRun this cell first. If prompted to restart the runtime, do so, then re-run all cells.\nThis cell is a no-op when running locally.\n\"\"\"\nimport sys, os\nif 'google.colab' in sys.modules:\n    from google.colab import drive\n    drive.mount('/content/drive')\n\n    NOTEBOOK_DIR = '/content/drive/My Drive/Colab Notebooks/ei_notebooks/visualization'\n\n    os.chdir(NOTEBOOK_DIR)\n    if NOTEBOOK_DIR not in sys.path:\n        sys.path.append(NOTEBOOK_DIR)\n\n    !pip install git+https://github.com/AlexFiliakov/Ergodic-Insurance-Limits.git -q 2>&1 | tail -3\n    print('\\nSetup complete. If you see numpy/scipy import errors below,')\n    print('restart the runtime (Runtime > Restart runtime) and re-run all cells.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setup\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\nfrom ergodic_insurance.visualization.technical_plots import (\n    plot_enhanced_convergence_diagnostics,\n    plot_trace_plots,\n    plot_loss_distribution_validation,\n    plot_monte_carlo_convergence,\n    plot_convergence_diagnostics,\n)\nfrom ergodic_insurance.convergence import ConvergenceDiagnostics\nfrom ergodic_insurance.convergence_advanced import (\n    AdvancedConvergenceDiagnostics,\n    SpectralDiagnostics,\n    AutocorrelationAnalysis,\n)\nfrom ergodic_insurance.convergence_plots import RealTimeConvergencePlotter\nfrom ergodic_insurance.adaptive_stopping import (\n    AdaptiveStoppingMonitor,\n    StoppingCriteria,\n    StoppingRule,\n)\nfrom ergodic_insurance.loss_distributions import LognormalLoss\n\nnp.random.seed(42)\n\n%matplotlib inline\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.facecolor\"] = \"white\"\n\nprint(\"Convergence monitoring modules loaded successfully!\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cell-1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic MCMC Chains\n\nGenerate chains with a known burn-in period and autocorrelation so we can verify that convergence diagnostics correctly identify converged vs. non-converged regions."
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "N_CHAINS = 4\nN_ITERATIONS = 5000\nBURN_IN = 1000\nTRUE_VALUES = np.array([10.0, 0.5, 2.0])\nPARAM_NAMES = [\"Premium Rate\", \"Deductible\", \"Risk Factor\"]\nAUTOCORR = 0.5\n\n\ndef generate_mcmc_chains():\n    chains = np.zeros((N_CHAINS, N_ITERATIONS, len(TRUE_VALUES)))\n    for chain in range(N_CHAINS):\n        for param in range(len(TRUE_VALUES)):\n            chains[chain, 0, param] = np.random.randn() + TRUE_VALUES[param] * 0.5\n            for t in range(1, N_ITERATIONS):\n                if t < BURN_IN:\n                    mean = TRUE_VALUES[param] * (0.5 + 0.5 * t / BURN_IN)\n                    std = TRUE_VALUES[param] * 0.5\n                else:\n                    mean = TRUE_VALUES[param]\n                    std = TRUE_VALUES[param] * 0.1\n                innovation = np.random.normal(mean, std)\n                chains[chain, t, param] = (\n                    AUTOCORR * chains[chain, t - 1, param]\n                    + (1 - AUTOCORR) * innovation\n                )\n    return chains\n\n\nchains = generate_mcmc_chains()\nprint(f\"Generated {chains.shape[0]} chains x {chains.shape[1]} iterations x {chains.shape[2]} params\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cell-3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trace Plots\n\nVisual check for chain mixing and burn-in period identification."
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig_trace = plot_trace_plots(\n    chains,\n    parameter_names=PARAM_NAMES,\n    burn_in=BURN_IN,\n    title=\"MCMC Trace Plots with Burn-in Period\",\n    figsize=(14, 8),\n)\nplt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cell-5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Enhanced Convergence Diagnostics\n\nMulti-panel view: R-hat (Gelman-Rubin), Effective Sample Size (ESS), autocorrelation functions, and Monte Carlo Standard Errors (MCSE)."
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig_diag = plot_enhanced_convergence_diagnostics(\n    chains,\n    parameter_names=PARAM_NAMES,\n    burn_in=BURN_IN,\n    title=\"Enhanced Convergence Diagnostics\",\n    figsize=(14, 10),\n)\nplt.show()\n\n# Numeric summary\ndiag = ConvergenceDiagnostics()\npost_chains = chains[:, BURN_IN:, :]\nprint(\"R-hat Statistics (target < 1.1):\")\nfor i, name in enumerate(PARAM_NAMES):\n    r_hat = diag.calculate_r_hat(post_chains[:, :, i:i + 1])\n    status = \"PASS\" if r_hat < 1.1 else \"FAIL\"\n    print(f\"  {name}: {r_hat:.4f} [{status}]\")\n\nprint(\"\\nEffective Sample Size (target > 1000):\")\nfor i, name in enumerate(PARAM_NAMES):\n    ess = diag.calculate_ess(post_chains[:, :, i].flatten())\n    status = \"PASS\" if ess > 1000 else \"FAIL\"\n    print(f\"  {name}: {ess:.0f} [{status}]\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cell-7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss Distribution Validation\n\nQ-Q plots and goodness-of-fit tests for attritional and large losses to verify that the simulated distributions match theoretical models."
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate synthetic loss data\nattritional_gen = LognormalLoss(mean=50_000, cv=0.5, seed=42)\nattritional_losses = attritional_gen.generate_severity(2000)\n\nlarge_gen = LognormalLoss(mean=1_000_000, cv=1.5, seed=43)\nlarge_losses = large_gen.generate_severity(200)\n\n# Add outliers for realism\nattritional_losses[::100] *= 3\nlarge_losses[::50] *= 5\n\nfig_val = plot_loss_distribution_validation(\n    attritional_losses,\n    large_losses,\n    title=\"Loss Distribution Validation\",\n    figsize=(14, 12),\n)\nplt.show()\n\nprint(f\"Attritional: n={len(attritional_losses)}, mean=${np.mean(attritional_losses):,.0f}\")\nprint(f\"Large:       n={len(large_losses)}, mean=${np.mean(large_losses):,.0f}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cell-9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monte Carlo Convergence Analysis\n\nTrack running means and confidence intervals for key insurance metrics over increasing iteration counts."
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def simulate_mc_metrics(n_iterations=10000):\n    \"\"\"Simulate convergence of insurance metrics.\"\"\"\n    targets = {\"ROE (%)\": 12.0, \"Ruin Probability (%)\": 0.8,\n              \"Sharpe Ratio\": 1.5, \"Premium Adequacy\": 1.25}\n    noise = {\"ROE (%)\": 5.0, \"Ruin Probability (%)\": 0.5,\n            \"Sharpe Ratio\": 0.3, \"Premium Adequacy\": 0.15}\n    history = {}\n    for metric, target in targets.items():\n        vals = []\n        for i in range(n_iterations):\n            vf = 1.0 / np.sqrt(i + 1)\n            jf = 1.5 if (i % 1000 == 0 and i > 0) else 1.0\n            vals.append(target + np.random.normal(0, noise[metric] * vf * jf))\n        history[metric] = vals\n    return history\n\n\nmetrics_history = simulate_mc_metrics()\nconvergence_thresholds = {\n    \"ROE (%)\": 12.0,\n    \"Ruin Probability (%)\": 1.0,\n    \"Sharpe Ratio\": 1.5,\n    \"Premium Adequacy\": 1.25,\n}\n\nfig_mc = plot_monte_carlo_convergence(\n    metrics_history,\n    convergence_thresholds=convergence_thresholds,\n    title=\"Monte Carlo Convergence Analysis\",\n    figsize=(16, 12),\n    log_scale=True,\n)\nplt.show()\n\nprint(\"Final metric estimates (last 1000 iterations):\")\nfor metric, vals in metrics_history.items():\n    print(f\"  {metric}: {np.mean(vals[-1000:]):.3f} +/- {np.std(vals[-1000:]):.3f}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cell-11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Autocorrelation Analysis\n\nCompare FFT, direct, and biased ACF methods. The integrated autocorrelation time quantifies how many iterations are needed per effectively independent sample."
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "adv_diag = AdvancedConvergenceDiagnostics()\nchain_sample = chains[0, BURN_IN:, 0]  # Post burn-in, first param\n\nmethods = [\"fft\", \"direct\", \"biased\"]\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\nfor i, method in enumerate(methods):\n    result = adv_diag.calculate_autocorrelation_full(chain_sample, max_lag=100, method=method)\n    axes[i].plot(result.lags, result.acf_values, \"b-\", linewidth=1.5)\n    axes[i].axhline(y=0, color=\"black\", linestyle=\"-\", alpha=0.3)\n    ci = 1.96 / np.sqrt(len(chain_sample))\n    axes[i].fill_between(result.lags, -ci, ci, alpha=0.2, color=\"gray\", label=\"95% CI\")\n    axes[i].set_title(f\"ACF ({method.upper()})\")\n    axes[i].set_xlabel(\"Lag\")\n    axes[i].set_ylabel(\"Autocorrelation\")\n    axes[i].grid(True, alpha=0.3)\n    axes[i].set_ylim(-0.2, 1.0)\n\nplt.suptitle(\"Autocorrelation Analysis Comparison\", fontsize=14, fontweight=\"bold\")\nplt.tight_layout()\nplt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cell-13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Spectral Density and ESS Methods\n\nSpectral density estimation provides an alternative ESS calculation. Comparing multiple ESS methods builds confidence in convergence assessment."
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Spectral density\nspectral_methods = [\"welch\", \"periodogram\"]\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\nfor i, method in enumerate(spectral_methods):\n    result = adv_diag.calculate_spectral_density(chain_sample, method=method)\n    axes[i].semilogy(result.frequencies, result.spectral_density, \"b-\", lw=1)\n    axes[i].set_title(f\"Spectral Density ({method.capitalize()})\")\n    axes[i].set_xlabel(\"Frequency\")\n    axes[i].set_ylabel(\"PSD\")\n    axes[i].grid(True, alpha=0.3)\n    axes[i].text(\n        0.6, 0.9,\n        f\"tau={result.integrated_autocorr_time:.2f}\\nESS={result.effective_sample_size:.0f}\",\n        transform=axes[i].transAxes, fontsize=10,\n        bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5),\n    )\nplt.suptitle(\"Spectral Density Analysis\", fontsize=14, fontweight=\"bold\")\nplt.tight_layout()\nplt.show()\n\n# ESS comparison across methods\ness_methods = {\n    \"Batch Means\": lambda c: adv_diag.calculate_ess_batch_means(c),\n    \"Overlap Batch\": lambda c: adv_diag.calculate_ess_overlapping_batch(c),\n    \"Spectral\": lambda c: adv_diag.calculate_spectral_density(c, \"welch\").effective_sample_size,\n    \"Basic ACF\": lambda c: ConvergenceDiagnostics().calculate_ess(c),\n}\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nfor pi, pname in enumerate(PARAM_NAMES):\n    ess_vals = {}\n    for mname, mfunc in ess_methods.items():\n        per_chain = [mfunc(chains[ci, BURN_IN:, pi]) for ci in range(N_CHAINS)]\n        ess_vals[mname] = per_chain\n    df = pd.DataFrame(ess_vals, index=[f\"Chain {c+1}\" for c in range(N_CHAINS)])\n    df.plot(kind=\"bar\", ax=axes[pi], width=0.8)\n    axes[pi].set_title(pname)\n    axes[pi].set_ylabel(\"ESS\")\n    axes[pi].legend(loc=\"upper right\", fontsize=8)\n    axes[pi].grid(True, alpha=0.3)\n    axes[pi].axhline(y=1000, color=\"red\", linestyle=\"--\", alpha=0.5)\nplt.suptitle(\"ESS Calculation Methods Comparison\", fontsize=14, fontweight=\"bold\")\nplt.tight_layout()\nplt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cell-15"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Diagnostic Tests\n\nHeidelberger-Welch stationarity test and Raftery-Lewis diagnostic provide quantitative convergence assessment beyond R-hat."
   ],
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Advanced Diagnostic Tests\")\nprint(\"=\" * 50)\n\nfor pi, pname in enumerate(PARAM_NAMES):\n    print(f\"\\n{pname}:\")\n    print(\"-\" * 30)\n    combined = chains[:, BURN_IN:, pi].flatten()\n\n    hw = adv_diag.heidelberger_welch_advanced(combined)\n    print(f\"  Heidelberger-Welch: stationary={hw['stationary']} (p={hw['pvalue']:.3f})\")\n    print(f\"    Halfwidth test: {'PASSED' if hw['halfwidth_passed'] else 'FAILED'}\")\n    print(f\"    Mean: {hw['mean']:.3f} +/- {hw['mcse']:.4f}\")\n\n    rl = adv_diag.raftery_lewis_diagnostic(combined)\n    print(f\"  Raftery-Lewis: min_n={rl['n_min']:.0f}, sufficient={'YES' if rl['sufficient'] else 'NO'}\")\n    print(f\"    Dependence factor: {rl['dependence_factor']:.2f}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cell-17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Adaptive Stopping\n\nAutomatically terminate simulations when convergence criteria are met, saving computation while ensuring quality. The patience mechanism prevents premature stopping."
   ],
   "id": "cell-18"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "criteria = StoppingCriteria(\n    rule=StoppingRule.COMBINED,\n    r_hat_threshold=1.05,\n    min_ess=1000,\n    mcse_relative_threshold=0.05,\n    min_iterations=1000,\n    max_iterations=10000,\n    check_interval=200,\n    patience=3,\n)\nmonitor = AdaptiveStoppingMonitor(criteria)\n\nprint(\"Adaptive Stopping Criteria:\")\nprint(f\"  Rule: {criteria.rule.value}\")\nprint(f\"  R-hat threshold: {criteria.r_hat_threshold}\")\nprint(f\"  Min ESS: {criteria.min_ess}\")\nprint(f\"  Patience: {criteria.patience} checks\")\nprint(f\"  Check interval: every {criteria.check_interval} iterations\")\n\n# Simulate adaptive stopping\nprint(\"\\nIteration | R-hat | ESS    | Status\")\nprint(\"-\" * 50)\nfor iteration in range(1000, 5001, 200):\n    current_chains = chains[:, :iteration, 0]\n    status = monitor.check_convergence(iteration, current_chains)\n    if iteration % criteria.check_interval == 0 and iteration >= criteria.min_iterations:\n        r_hat = status.diagnostics.get(\"r_hat\", 0)\n        ess = status.diagnostics.get(\"ess\", 0)\n        mark = \"PASS\" if status.converged else \"----\"\n        print(f\"{iteration:8d} | {r_hat:.3f} | {ess:6.0f} | {mark} {status.reason[:30]}...\")\n        if status.should_stop:\n            print(f\"\\nSTOPPED at iteration {iteration}: {status.reason}\")\n            break"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cell-19"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Fixed vs. Adaptive Stopping Comparison\n\nAdaptive stopping typically saves 30-50% of iterations compared to fixed budgets while maintaining the same convergence quality."
   ],
   "id": "cell-20"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "basic_diag = ConvergenceDiagnostics()\n\nscenarios = {\n    \"Fixed 5000\": {\"type\": \"fixed\", \"iterations\": 5000},\n    \"Fixed 10000\": {\"type\": \"fixed\", \"iterations\": 10000},\n    \"Adaptive (R<1.1)\": {\"type\": \"adaptive\", \"r_hat\": 1.1, \"min_ess\": 500},\n    \"Adaptive (R<1.05)\": {\"type\": \"adaptive\", \"r_hat\": 1.05, \"min_ess\": 1000},\n    \"Adaptive (Strict)\": {\"type\": \"adaptive\", \"r_hat\": 1.01, \"min_ess\": 2000},\n}\n\nresults = []\nfor name, cfg in scenarios.items():\n    if cfg[\"type\"] == \"fixed\":\n        n_iter = cfg[\"iterations\"]\n        fc = chains[:, :n_iter, 0]\n        r_hat = basic_diag.calculate_r_hat(fc[:, :, np.newaxis])\n        ess = basic_diag.calculate_ess(fc.flatten())\n    else:\n        crit = StoppingCriteria(\n            rule=StoppingRule.COMBINED,\n            r_hat_threshold=cfg[\"r_hat\"],\n            min_ess=cfg[\"min_ess\"],\n            min_iterations=1000,\n            check_interval=100,\n            patience=2,\n        )\n        mon = AdaptiveStoppingMonitor(crit)\n        n_iter = 5000\n        for ci in range(1000, 5001, 100):\n            st = mon.check_convergence(ci, chains[:, :ci, 0])\n            if st.should_stop:\n                n_iter = ci\n                break\n        r_hat = st.diagnostics.get(\"r_hat\", np.inf)\n        ess = st.diagnostics.get(\"ess\", 0)\n\n    results.append({\n        \"Scenario\": name, \"Iterations\": n_iter,\n        \"R-hat\": r_hat, \"ESS\": ess,\n        \"ESS/Iter\": ess / n_iter,\n    })\n\ndf = pd.DataFrame(results)\nprint(\"Performance Comparison:\")\nprint(df.to_string(index=False))\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\ncolors = [\"blue\", \"blue\", \"green\", \"green\", \"green\"]\n\naxes[0].bar(range(len(df)), df[\"Iterations\"], color=colors)\naxes[0].set_xticks(range(len(df)))\naxes[0].set_xticklabels(df[\"Scenario\"], rotation=45, ha=\"right\")\naxes[0].set_ylabel(\"Iterations\")\naxes[0].set_title(\"Computational Cost\")\naxes[0].grid(True, alpha=0.3)\n\nbar_colors = [\"red\" if r > 1.1 else \"orange\" if r > 1.05 else \"green\" for r in df[\"R-hat\"]]\naxes[1].bar(range(len(df)), df[\"R-hat\"], color=bar_colors)\naxes[1].axhline(y=1.1, color=\"red\", linestyle=\"--\", alpha=0.5)\naxes[1].set_xticks(range(len(df)))\naxes[1].set_xticklabels(df[\"Scenario\"], rotation=45, ha=\"right\")\naxes[1].set_ylabel(\"R-hat\")\naxes[1].set_title(\"Convergence Quality\")\naxes[1].grid(True, alpha=0.3)\n\naxes[2].bar(range(len(df)), df[\"ESS/Iter\"])\naxes[2].set_xticks(range(len(df)))\naxes[2].set_xticklabels(df[\"Scenario\"], rotation=45, ha=\"right\")\naxes[2].set_ylabel(\"ESS per Iteration\")\naxes[2].set_title(\"Sampling Efficiency\")\naxes[2].grid(True, alpha=0.3)\n\nplt.suptitle(\"Fixed vs Adaptive Stopping Comparison\", fontsize=14, fontweight=\"bold\")\nplt.tight_layout()\nplt.show()\n\nfixed_base = df.loc[df[\"Scenario\"] == \"Fixed 10000\", \"Iterations\"].values[0]\nadaptive_opt = df.loc[df[\"Scenario\"] == \"Adaptive (R<1.05)\", \"Iterations\"].values[0]\nsavings = (fixed_base - adaptive_opt) / fixed_base * 100\nprint(f\"\\nComputational savings with adaptive stopping: {savings:.1f}%\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cell-21"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n\n- R-hat < 1.1 and ESS > 1000 are standard convergence thresholds; always check both.\n- Heidelberger-Welch and Raftery-Lewis tests provide additional statistical rigor.\n- Spectral density and overlapping-batch ESS methods offer robust alternatives to basic ACF.\n- Adaptive stopping typically saves 30-50% of iterations while maintaining convergence quality.\n- Always validate loss distributions with Q-Q plots and K-S tests before trusting simulation output.\n\n## Next Steps\n\n- [05_ruin_analysis_plots](05_ruin_analysis_plots.ipynb) -- ruin cliff and ROE-ruin frontier\n- [../core/04_monte_carlo_engine](../core/04_monte_carlo_engine.ipynb) -- Monte Carlo engine details\n- [06_scenario_comparison](06_scenario_comparison.ipynb) -- scenario comparison and annotation framework"
   ],
   "id": "cell-22"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
