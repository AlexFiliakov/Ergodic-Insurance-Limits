{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af904fa9",
   "metadata": {},
   "source": [
    "# Process Tail Simulation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd9fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "\n",
    "results_dir = r\"D:\\Ergodicity Simulations\\2025-10-10 Run - L Tail and Lim - production 1\"\n",
    "\n",
    "# sample_file = \"Cap (25M) - Ded (100K) - LR (0.6) - Pol_Lim (25M) - X_Th_%le (0.0005) - X_Shape (1.0) - X_Scale (1.0) - 250K Sims - 25 Yrs.pkl\"\n",
    "\n",
    "# file_path = os.path.join(results_dir, sample_file)\n",
    "# with open(file_path, \"rb\") as f:\n",
    "#     loaded_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f964ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_data.ruin_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52fc95de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_data.growth_rates.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f6e9c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4196ebfa39e4261a88c01d593dc60a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing pickle files:   0%|          | 0/156 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 156 pickle files into all_configurations.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "from ergodic_insurance.monte_carlo import SimulationResults\n",
    "import numpy as np\n",
    "from time import perf_counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def _parse_number(text):\n",
    "    text = text.strip().replace(\",\", \"\")\n",
    "    m = re.fullmatch(r'([+-]?\\d+(?:\\.\\d+)?)([KMB])?$', text, re.I)\n",
    "    if not m:\n",
    "        # fallback: plain int/float or leave as-is\n",
    "        try:\n",
    "            return int(text)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return float(text)\n",
    "            except ValueError:\n",
    "                return text\n",
    "    num = float(m.group(1))\n",
    "    mult = {\"K\": 1_000, \"M\": 1_000_000, \"B\": 1_000_000_000}.get((m.group(2) or \"\").upper(), 1)\n",
    "    val = num * mult\n",
    "    return int(val) if val.is_integer() else val\n",
    "\n",
    "\n",
    "def parse_config_key(key: str) -> dict:\n",
    "    parts = re.split(r\"\\s*-\\s*\", key.strip())\n",
    "    out = {}\n",
    "    for part in parts:\n",
    "        if not part:\n",
    "            continue\n",
    "\n",
    "        # e.g. \"Cap (100M)\"\n",
    "        m = re.match(r\"^([A-Za-z_%]+)\\s*\\(\\s*([^)]+)\\s*\\)$\", part)\n",
    "        if m:\n",
    "            out[m.group(1)] = _parse_number(m.group(2))\n",
    "            continue\n",
    "\n",
    "        # e.g. \"0K Sims\" or \"50 Yrs\"\n",
    "        m = re.match(r\"^([+-]?\\d+(?:\\.\\d+)?)\\s*([KMB])?\\s*([A-Za-z_]+)$\", part)\n",
    "        if m:\n",
    "            value = _parse_number((m.group(1) or \"\") + (m.group(2) or \"\"))\n",
    "            out[m.group(3)] = value\n",
    "            continue\n",
    "\n",
    "        # flags like \"NOINS\"\n",
    "        if part.upper() == \"NOINS\":\n",
    "            out[\"NOINS\"] = True\n",
    "\n",
    "    return out\n",
    "\n",
    "results_dir = Path(results_dir)\n",
    "\n",
    "sample_files = \"*.pkl\"\n",
    "\n",
    "pkl_paths = sorted(results_dir.glob(sample_files))\n",
    "\n",
    "qs = np.arange(0.01, 1.00, 0.01) # Growth Rate Quantiles\n",
    "\n",
    "all_configurations = {}\n",
    "if not pkl_paths:\n",
    "    print(f\"No pickle files found in {results_dir}.\")\n",
    "else:\n",
    "    try:\n",
    "        iterator = tqdm(pkl_paths, desc=\"Processing pickle files\", unit=\"file\")\n",
    "    except Exception:\n",
    "        iterator = pkl_paths  # fallback without progress bar\n",
    "\n",
    "    start_time = perf_counter()\n",
    "    for idx, path in enumerate(iterator, 1):\n",
    "        if idx > 1:\n",
    "            elapsed = perf_counter() - start_time\n",
    "            avg = elapsed / (idx - 1)\n",
    "            remaining = avg * (len(pkl_paths) - (idx - 1))\n",
    "            if hasattr(iterator, \"set_postfix\"):\n",
    "                iterator.set_postfix(avg_s=f\"{avg:.2f}\", eta_s=f\"{remaining:.1f}\")\n",
    "        try:\n",
    "            with open(path, \"rb\") as f:\n",
    "                one_config = pickle.load(f)\n",
    "                growth_rate = one_config.growth_rates.mean()\n",
    "                growth_rate_ci = {str(q): val for q, val in zip(qs, np.quantile(one_config.growth_rates, qs))}\n",
    "                ror = one_config.ruin_probability\n",
    "                all_configurations[path.stem] = {\n",
    "                    \"growth_rate\": growth_rate,\n",
    "                    \"growth_rate_ci\": growth_rate_ci,\n",
    "                    \"risk_of_ruin\": ror\n",
    "                    # \"annual_losses\": one_config.annual_losses\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {path.name}: {e}\")\n",
    "    print(f\"Loaded {len(all_configurations)} pickle files into all_configurations.\")\n",
    "\n",
    "parsed_params_by_key = {k: parse_config_key(k) | all_configurations[k] for k in all_configurations.keys()}\n",
    "# parsed_params_by_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "debbc56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 156 configurations to cache\\parsed_params_by_key.pkl\n"
     ]
    }
   ],
   "source": [
    "outfile = r\"cache\\parsed_params_by_key.pkl\"\n",
    "out_path = Path(outfile)\n",
    "if out_path.parent and not out_path.parent.exists():\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(out_path, \"wb\") as f:\n",
    "    pickle.dump(parsed_params_by_key, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(f\"Wrote {len(parsed_params_by_key)} configurations to {outfile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10cc0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# infile = r\"cache\\parsed_params_by_key.pkl\"\n",
    "\n",
    "# with open(infile, 'rb') as f:\n",
    "#     parsed_params_by_key = pickle.load(f)\n",
    "# print(f\"Loaded {len(parsed_params_by_key)} configurations to `parsed_params_by_key`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b32ffa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10000000,\n",
       " 25000000,\n",
       " 50000000,\n",
       " 75000000,\n",
       " 100000000,\n",
       " 150000000,\n",
       " 250000000,\n",
       " 350000000]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the first failing comprehension with this safe version:\n",
    "all_lims = sorted({sc['Pol_Lim'] for sc in parsed_params_by_key.values() if 'Pol_Lim' in sc})\n",
    "all_lims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "801ad10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cap',\n",
       " 'Ded',\n",
       " 'LR',\n",
       " 'NOINS',\n",
       " 'Pol_Lim',\n",
       " 'Sims',\n",
       " 'X_Scale',\n",
       " 'X_Shape',\n",
       " 'X_Th_%le',\n",
       " 'Yrs',\n",
       " 'growth_rate',\n",
       " 'growth_rate_ci',\n",
       " 'risk_of_ruin'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the first failing comprehension with this safe version:\n",
    "all_keys = set().union(*(sc.keys() for sc in parsed_params_by_key.values()))\n",
    "all_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d84d256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sims: ['250000']\n",
      "X_Shape: ['0.5', '0.6', '0.7', '0.8', '0.9', '1']\n",
      "NOINS: ['True']\n",
      "growth_rate_ci: {<class 'dict'>}\n",
      "Yrs: ['50']\n",
      "Pol_Lim: ['10000000', '100000000', '150000000', '25000000', '250000000', '350000000', '50000000', '75000000']\n",
      "Cap: ['10000000', '100000000']\n",
      "X_Scale: ['1']\n",
      "Ded: ['250000']\n",
      "LR: ['0.6']\n",
      "growth_rate: ['-0.0005405508405064681', '-0.0010501237914220907', '-0.0011503066155126853', '-0.0015497239686340413', '-0.001964669596315576', '-0.0022836063566061895', '-0.002368480437508162', '-0.004032633253378054', '-0.005712410670016531', '-0.006557100539840105', '-0.00701411182935926', '-4.8677622562972605e-05', '0.00032908903618440104', '0.0005871077487088378', '0.001794991811772762', '0.0029541920482606967', '0.002998493611137167', '0.0031748961749049455', '0.0038805189019364434', '0.004285413567395652', '0.004565945173277437', '0.005103607190866101', '0.005265883551881169', '0.005574834284942899', '0.005690898828112593', '0.0060150010691063654', '0.006038679684580893', '0.006066100231205562', '0.0063009558161395', '0.006470933423173243', '0.006545093184721408', '0.0068682429404183405', '0.006870070331744368', '0.007111961215156844', '0.007169370741425282', '0.007178908706707316', '0.0072816337043695965', '0.007421072070170654', '0.0075545547286175714', '0.007923742311930616', '0.007982812235351223', '0.008038757856016281', '0.008070624823195094', '0.008100122660891744', '0.008197225168440236', '0.008426115433505561', '0.008482435583006433', '0.008540096757120643', '0.008734569206214236', '0.008747906028981041', '0.008749974938656273', '0.008823764120430413', '0.009070392167181803', '0.009333051577209586', '0.009419764686304333', '0.009464260686239916', '0.009786668940738073', '0.0098142981975965', '0.00990825990382757', '0.009910047455921958', '0.009951523304371782', '0.010167203202468233', '0.010177744233035585', '0.010194464385070424', '0.010240759745479546', '0.01035429764743188', '0.010420319330001822', '0.010481154582000083', '0.0106654754530403', '0.010691240368717034', '0.010776026339533857', '0.010880882708569538', '0.010920952109772734', '0.011002458130878861', '0.01109634119829415', '0.011202384992788698', '0.011260384846443249', '0.011269415415556316', '0.011463864878444321', '0.011479505654827794', '0.011487596487342938', '0.011585989206079492', '0.011652091891615687', '0.011689974914016988', '0.011734375738854476', '0.011798095909295588', '0.011949780040315203', '0.011981832751219586', '0.012081760223863064', '0.012093597857065964', '0.01213127628473765', '0.012296489340795422', '0.012407169662375586', '0.012443961608116871', '0.012445015361333191', '0.012453006371229676', '0.012533123534486068', '0.012558051084453181', '0.01258248040041465', '0.012779619240067609', '0.012866511951254184', '0.012933561324180122', '0.012948233201452077', '0.01308355199530872', '0.01308396258856837', '0.013145927266183194', '0.013158222765179743', '0.013162066232721682', '0.013206713554950832', '0.013274601650851727', '0.01328287070113467', '0.013387442233906593', '0.01342753663262883', '0.013483874791050534', '0.013484388790224249', '0.013625204368289618', '0.013722733006004947', '0.013855021110326892', '0.013886573271742272', '0.013932861710412775', '0.013959110897922664', '0.013974148242044496', '0.013989093863369162', '0.01419263071958928', '0.014264168740571593', '0.014306561968826213', '0.014333914501995611', '0.01435142970529869', '0.014456832393134304', '0.014496872702190269', '0.014568195090598195', '0.014667619859602856', '0.014736611522157777', '0.01478553816446467', '0.014919434505823897', '0.01499467273017356', '0.015040149085514156', '0.015064162620483433', '0.015083063354040846', '0.01518084127359801', '0.015235941376278518', '0.015251454453021842', '0.015290152106673489', '0.015374793281110003', '0.015380892228380311', '0.015381240927609383', '0.015412039982778616', '0.0154215676537533', '0.015494669456599731', '0.015539934575576612', '0.015552356047261478', '0.015662346570020892', '0.015786038013447076', '0.015894701070858958', '0.01598335347852716', '0.01725143193241202']\n",
      "risk_of_ruin: {<class 'dict'>}\n",
      "X_Th_%le: ['0.0001', '0.0005']\n"
     ]
    }
   ],
   "source": [
    "for key in all_keys:\n",
    "    all_key_vals = sorted({str(sc[key]) for sc in parsed_params_by_key.values() if key in sc and type(sc[key]) not in (list, dict, set)})\n",
    "    if all_key_vals != []:\n",
    "        print(f\"{key}: {all_key_vals}\")\n",
    "    all_key_vals = {type(sc[key]) for sc in parsed_params_by_key.values() if key in sc and type(sc[key]) in (list, dict, set)}\n",
    "    if all_key_vals != set():\n",
    "        print(f\"{key}: {all_key_vals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d670c4b6",
   "metadata": {},
   "source": [
    "I have the following set of data as a list of dictionaries for 1029 configurations that I'd like to explore visually in Python:\n",
    "\n",
    "```\n",
    "'risk_of_ruin': {<class 'dict'>} # Risk of Ruin snapshots at 5-year intervales (5, 10, 15, 20, 25)\n",
    "'Ded': ['100000'] # Deductible\n",
    "'X_Scale': ['0.5', '1', '1.5', '2'] # Scale parameter for the Generalized Pareto Distribution (GPD) tail\n",
    "'X_Th_%le': ['0.0001', '0.0005', '0.001', 'None'] # Threshold percentile for the Generalized Pareto Distribution (GPD) tail\n",
    "'growth_rate': <class 'float'> # Mean Growth Rate at the end of the simulation\n",
    "'growth_rate_ci': {<class 'dict'>} # Growth Rate quantiles from 0.01 to 0.99 in increments of 0.01 at the end of the simulation\n",
    "'Pol_Lim': ['100000000', '200000000', '50000000', '500000000']\n",
    "'X_Shape': ['0', '1', '1.5', '2', '2.5'] # Shape parameter for the Generalized Pareto Distribution (GPD) tail\n",
    "'LR': ['0.3', '0.4', '0.5', '0.6', '0.7'] # Loss Ratio (Claims / Premiums), lower implies a higher premium charge for the same expected losses\n",
    "'Yrs': ['25'] # Simulations were run for 25 years only\n",
    "'Sims': ['100000'] # Each configuration was run for 100,000 simulations\n",
    "# There are also configurations without insurance for which there is no 'Pol_Lim', no 'Ded', and no 'LR' parameters. These scenarios are marked with `'NOINS': True`\n",
    "```\n",
    "\n",
    "For the first set of plots, I'd like to create an Efficiency Frontier plot with the following parameters:\n",
    "x-axix: 'risk_of_ruin'\n",
    "y-axis: 'growth_rate'\n",
    "Display this curve for each tail configuration in the following setup:\n",
    "row: 'X_Th_%le'\n",
    "column: 'X_Shape'\n",
    "Plot different graphs for each collection of 'X_Scale', which are transformations on the loss distribution with '1' representing a close match, '0.5' representing 0.5 loss density compared to default tail, '2' representing twice the density of the default tail, and so on.\n",
    "Color represents percentiles, using the pallette \"cividis\"\n",
    "Encode different limits as shapes for the median/mean/quantile, so for example, a triangle in different colors represents the same limit (50M)\n",
    "Shapes are as follows:\n",
    "'NOINS': plus sign, \"P\" shape code\n",
    "'50000000': triangle, \"v\" shape code\n",
    "'100000000': square, \"s\" shape code\n",
    "'200000000': pentagon, \"p\" shape code\n",
    "'500000000': hexagon, \"H\" shape code\n",
    "\n",
    "There should be 4 plots (one for each 'X_Scale') with DPI set to 300px that get saved to individual PNG files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08c0d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e65f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_only_vals = [val for val in parsed_params_by_key.values() if val.get('NOINS', False) is False]\n",
    "len(ins_only_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ac8ba41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in ins_only_vals if c['X_Shape'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cf7160c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.6, 0.7, 0.8, 0.9, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shapes = sorted(set(c['X_Shape'] for c in ins_only_vals))\n",
    "x_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3927df24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in ins_only_vals if c['X_Shape'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfdfd6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = sorted(set(c['LR'] for c in ins_only_vals))\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e1f423",
   "metadata": {},
   "source": [
    "## Plot Facets of Growth vs Limit (Row = Shape; Col = Initial Cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d381e3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexf\\AppData\\Local\\Temp\\ipykernel_56756\\181985325.py:315: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n",
      "  color_elements.append(mpatches.Patch(color=cmap(pct),\n",
      "C:\\Users\\alexf\\AppData\\Local\\Temp\\ipykernel_56756\\181985325.py:319: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n",
      "  color_elements.append(mpatches.Patch(color=\"#d3360e\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: cache/growth_v_limit_lr_0p6_thresh_0.0001_scale_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexf\\AppData\\Local\\Temp\\ipykernel_56756\\181985325.py:315: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n",
      "  color_elements.append(mpatches.Patch(color=cmap(pct),\n",
      "C:\\Users\\alexf\\AppData\\Local\\Temp\\ipykernel_56756\\181985325.py:319: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n",
      "  color_elements.append(mpatches.Patch(color=\"#d3360e\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: cache/growth_v_limit_lr_0p6_thresh_0.0005_scale_1.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Assuming your data is stored in a list called 'configurations'\n",
    "# configurations = [{'risk_of_ruin': {...}, 'growth_rate': ..., 'X_Scale': ..., ...}, ...]\n",
    "\n",
    "\n",
    "def create_efficiency_frontier_plots(configurations):\n",
    "    \"\"\"\n",
    "    Create efficiency frontier plots for actuarial simulation results.\n",
    "    \n",
    "    FIXED VERSION: Includes comprehensive error handling for pcolormesh issues.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    configurations : list of dict\n",
    "        List of configuration dictionaries with simulation results\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    Saves PNG files for each X_Scale with efficiency frontier plots.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get unique values for separate charts\n",
    "    x_scales = sorted(set(c['X_Scale'] for c in configurations))\n",
    "    lr = sorted(set(c['LR'] for c in configurations))\n",
    "    caps = sorted(set(c['Cap'] for c in configurations))\n",
    "    x_thresholds = sorted({(c['X_Th_%le'] if isinstance(c['X_Th_%le'], (float, np.floating)) else 0.0) for c in configurations})\n",
    "    x_thresholds = [s for s in x_thresholds if s != 0] # Filter out 0\n",
    "\n",
    "    # Define percentiles for overlay\n",
    "    highlight_percentiles = [0.01, 0.05, 0.1, 0.25, 0.50]\n",
    "    legend_percentiles = [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99]\n",
    "    all_percentiles = np.arange(0.01, 1.00, 0.01).tolist()\n",
    "\n",
    "    for loss_ratio in lr:\n",
    "        for threshold in x_thresholds:\n",
    "            # Create a plot for each Loss Ratio and Threshold\n",
    "            for scale in x_scales:\n",
    "                scale_configs = [c for c in configurations \n",
    "                                if c['X_Scale'] == scale and \n",
    "                                    c['LR'] == loss_ratio and \n",
    "                                    c['X_Th_%le'] == threshold]\n",
    "                \n",
    "                # Get unique values for faceting\n",
    "                x_shapes = sorted(set(float(c['X_Shape']) for c in scale_configs))\n",
    "                x_shapes = [s for s in x_shapes if s != 0] # Filter out 0\n",
    "                # x_shapes = [0.25, 0.5, 1.0, 1.5]\n",
    "\n",
    "                all_gr_min, all_gr_max = [], []\n",
    "                for val in ins_only_vals:\n",
    "                    val_min, val_max = min(val['growth_rate_ci'].values()), max(val['growth_rate_ci'].values())\n",
    "                    all_gr_min.append(val_min)\n",
    "                    all_gr_max.append(val_max)\n",
    "\n",
    "                y_min, y_max = min(all_gr_min), max(all_gr_max)\n",
    "\n",
    "                # Create figure with subplots\n",
    "                n_rows = len(x_shapes)\n",
    "                n_cols = len(caps)\n",
    "\n",
    "                fig, axes = plt.subplots(n_rows, n_cols,\n",
    "                                        figsize=(5*n_cols, 4*n_rows),\n",
    "                                        dpi=300,\n",
    "                                        squeeze=False)\n",
    "\n",
    "                # Set overall title\n",
    "                thresh_label = f'{threshold*100:,.2f}%' if threshold != 'None' else 'No Tail'\n",
    "                # Not displaying Scale for now since it's always 1.0\n",
    "                scale_label = f\"{float(scale):.1f}\" if scale != '1' else \"Baseline\"\n",
    "                lr_pct = f\"{loss_ratio*100:.0f}%\"\n",
    "                fig.suptitle(f'Time-Average Growth vs Insurance Limit\\n(Loss Ratio: {lr_pct}; Threshold {thresh_label})',\n",
    "                            fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "                # Create colormap for percentiles\n",
    "                cmap = plt.cm.viridis\n",
    "\n",
    "                # Plot each facet\n",
    "                for i, shape_param in enumerate(x_shapes):\n",
    "                    for j, cap in enumerate(caps):\n",
    "                        ax = axes[i, j]\n",
    "\n",
    "                        # Debug: Check what values we're comparing\n",
    "                        if cap == 0 or shape_param == 0:\n",
    "                            print(f\"\\n=== Debug for cap={cap}, shape_param={shape_param} ===\")\n",
    "                            print(f\"shape_param type: {type(shape_param)}, value: {repr(shape_param)}\")\n",
    "                            print(f\"cap type: {type(cap)}, value: {repr(cap)}\")\n",
    "                            # Sample a few configs to see their actual values\n",
    "                            for c in scale_configs[:3]:\n",
    "                                print(f\"  X_Shape: {repr(c['X_Shape'])} (type: {type(c['X_Shape'])})\")\n",
    "                                print(f\"  X_Th_%le: {repr(c['X_Th_%le'])} (type: {type(c['X_Th_%le'])})\")\n",
    "                                print(f\"  float(c['X_Shape']) == shape_param: {float(c['X_Shape']) == shape_param}\")\n",
    "                                print(f\"  Threshold match: {c['X_Th_%le'] == threshold or (c['X_Th_%le'] is None and threshold == 0)}\")\n",
    "                                print()\n",
    "\n",
    "                        # Filter for this facet\n",
    "                        facet_configs = [c for c in scale_configs\n",
    "                                        if c['Cap'] == cap and float(c['X_Shape']) == shape_param]\n",
    "\n",
    "                        if (cap == 0 or shape_param == 0):\n",
    "                            print(len(facet_configs))\n",
    "\n",
    "                        # Intermediate pass - Create smooth gradient using pcolormesh\n",
    "                        # Organize data by percentile\n",
    "                        percentile_data = {pct: [] for pct in all_percentiles}\n",
    "\n",
    "                        for config in facet_configs:\n",
    "                            # Calculate log of policy limit for x-axis\n",
    "                            if config.get('NOINS', False):\n",
    "                                continue  # Skip NOINS\n",
    "                            else:\n",
    "                                pol_lim = config.get('Pol_Lim', [''])[0] if isinstance(\n",
    "                                    config.get('Pol_Lim'), list) else config.get('Pol_Lim', '')\n",
    "                                x_value = np.log10(float(pol_lim))\n",
    "                            \n",
    "                            # Collect percentile values\n",
    "                            if 'growth_rate_ci' in config and config['growth_rate_ci']:\n",
    "                                for pct in all_percentiles:\n",
    "                                    pct_key = f\"{pct:.2f}\" if f\"{pct:.2f}\" in config['growth_rate_ci'] else pct\n",
    "                                    if pct_key in config['growth_rate_ci']:\n",
    "                                        growth = config['growth_rate_ci'][pct_key]\n",
    "                                        percentile_data[pct].append((x_value, growth, float(pol_lim)))\n",
    "\n",
    "                        # Get unique x values (policy limits) and sort\n",
    "                        unique_x_values = sorted(set(p[0] for pct_list in percentile_data.values() for p in pct_list))\n",
    "\n",
    "                        if len(unique_x_values) > 1:\n",
    "                            # Create interpolation grid with many points for smooth gradient\n",
    "                            x_interp = np.linspace(min(unique_x_values), max(unique_x_values), 200)\n",
    "                            \n",
    "                            # For each percentile, interpolate growth rates across policy limits\n",
    "                            from scipy.interpolate import interp1d\n",
    "                            \n",
    "                            y_grid = []\n",
    "                            valid_percentiles = []\n",
    "                            \n",
    "                            for pct in sorted(all_percentiles):\n",
    "                                if len(percentile_data[pct]) > 1:\n",
    "                                    # Sort by x value\n",
    "                                    sorted_data = sorted(percentile_data[pct], key=lambda p: p[0])\n",
    "                                    x_data = np.array([p[0] for p in sorted_data])\n",
    "                                    y_data = np.array([p[1] for p in sorted_data])\n",
    "                                    \n",
    "                                    # CRITICAL FIX: Remove non-finite values and use bounded extrapolation\n",
    "                                    valid_mask = np.isfinite(x_data) & np.isfinite(y_data)\n",
    "                                    if np.sum(valid_mask) >= 2:  # Need at least 2 points\n",
    "                                        x_clean = x_data[valid_mask]\n",
    "                                        y_clean = y_data[valid_mask]\n",
    "                                        \n",
    "                                        try:\n",
    "                                            # Use bounded fill values instead of 'extrapolate' to prevent inf\n",
    "                                            f = interp1d(x_clean, y_clean, kind='linear', \n",
    "                                                        bounds_error=False,\n",
    "                                                        fill_value=(y_clean[0], y_clean[-1]))\n",
    "                                            y_interp = f(x_interp)\n",
    "                                            \n",
    "                                            # Validate interpolation output\n",
    "                                            if np.all(np.isfinite(y_interp)):\n",
    "                                                y_grid.append(y_interp)\n",
    "                                                valid_percentiles.append(pct)\n",
    "                                            else:\n",
    "                                                print(f\"Warning: Non-finite interpolation at pct={pct}\")\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"Interpolation failed at pct={pct}: {e}\")\n",
    "                            \n",
    "                            if len(y_grid) > 1:\n",
    "                                # Convert to 2D array: rows = percentiles, columns = x positions\n",
    "                                y_grid = np.asarray(y_grid, dtype=np.float64)\n",
    "                                \n",
    "                                # CRITICAL FIX: Check for MaskedArray and validate data\n",
    "                                if isinstance(y_grid, np.ma.MaskedArray):\n",
    "                                    print(f\"Warning: y_grid is MaskedArray, converting...\")\n",
    "                                    y_grid = y_grid.filled(np.nan)\n",
    "                                \n",
    "                                # Final validation: ensure all finite values\n",
    "                                if not np.all(np.isfinite(y_grid)):\n",
    "                                    print(f\"Warning: Non-finite values in y_grid, cleaning...\")\n",
    "                                    # Replace inf with max/min finite\n",
    "                                    finite_mask = np.isfinite(y_grid)\n",
    "                                    if np.any(finite_mask):\n",
    "                                        max_finite = np.max(y_grid[finite_mask])\n",
    "                                        min_finite = np.min(y_grid[finite_mask])\n",
    "                                        y_grid = np.where(np.isposinf(y_grid), max_finite, y_grid)\n",
    "                                        y_grid = np.where(np.isneginf(y_grid), min_finite, y_grid)\n",
    "                                        # Fill NaN with column means\n",
    "                                        for col_idx in range(y_grid.shape[1]):\n",
    "                                            col = y_grid[:, col_idx]\n",
    "                                            if np.any(np.isnan(col)):\n",
    "                                                col_mean = np.nanmean(col)\n",
    "                                                y_grid[np.isnan(col), col_idx] = col_mean\n",
    "                                \n",
    "                                # Only proceed if we have valid data\n",
    "                                if np.all(np.isfinite(y_grid)):\n",
    "                                    # Create meshgrid for pcolormesh\n",
    "                                    X, Y = np.meshgrid(x_interp, valid_percentiles)\n",
    "                                    \n",
    "                                    # Ensure meshgrids are regular arrays\n",
    "                                    X = np.asarray(X, dtype=np.float64)\n",
    "                                    Y = np.asarray(Y, dtype=np.float64)\n",
    "                                    \n",
    "                                    # Use pcolormesh with the colormap\n",
    "                                    mesh = ax.pcolormesh(X, y_grid, Y, \n",
    "                                                        cmap=cmap, \n",
    "                                                        shading='gouraud',  # Smooth interpolation\n",
    "                                                        vmin=0, vmax=1,\n",
    "                                                        zorder=5)\n",
    "                                else:\n",
    "                                    print(f\"Skipping pcolormesh - data still contains non-finite values\")\n",
    "\n",
    "                        # Second pass: Overlay specific percentiles with shapes\n",
    "                        for config in facet_configs:\n",
    "                            # Get risk of ruin at year 25\n",
    "                            # ror_25 = config['risk_of_ruin'].get(25, config['risk_of_ruin'].get('25'))\n",
    "\n",
    "                            # Calculate log of policy limit for x-axis\n",
    "                            if config.get('NOINS', False):\n",
    "                                x_value = 0  # or np.nan if you want to exclude NOINS from plot\n",
    "                            else:\n",
    "                                pol_lim = config.get('Pol_Lim', [''])[0] if isinstance(\n",
    "                                    config.get('Pol_Lim'), list) else config.get('Pol_Lim', '')\n",
    "                                x_value = np.log10(float(pol_lim))\n",
    "\n",
    "                            # Plot mean in #cc0000\n",
    "                            if 'growth_rate' in config:\n",
    "                                growth_mean = config['growth_rate']\n",
    "                                ax.scatter(x_value, growth_mean,\n",
    "                                            marker='o',\n",
    "                                            c='#cc0000',\n",
    "                                            alpha=1.0,\n",
    "                                            edgecolors='#cc0000',\n",
    "                                            linewidths=1.5,\n",
    "                                            zorder=10)\n",
    "\n",
    "\n",
    "                        ### Draw lines connecting means across limits #######\n",
    "                        # Collect (x, growth_rate, raw_limit) tuples to connect mean growth rates\n",
    "                        mean_points = []\n",
    "                        \n",
    "                        for config in facet_configs:\n",
    "                            # Skip NOINS for connecting line (only plot actual policy limits)\n",
    "                            if config.get('NOINS', False):\n",
    "                                continue\n",
    "                            pol_lim = config.get('Pol_Lim', [''])[0] if isinstance(\n",
    "                                config.get('Pol_Lim'), list) else config.get('Pol_Lim', '')\n",
    "                            try:\n",
    "                                x_value = np.log10(float(pol_lim))\n",
    "                            except (TypeError, ValueError):\n",
    "                                continue\n",
    "                            if 'growth_rate' in config and config['growth_rate'] is not None:\n",
    "                                mean_points.append((x_value, float(config['growth_rate']), float(pol_lim)))\n",
    "                        \n",
    "                        if len(mean_points) > 1:\n",
    "                            # Sort by actual (non-log) policy limit to ensure correct ordering\n",
    "                            sorted_points = sorted(mean_points, key=lambda p: p[2])\n",
    "                            x_coords = [p[0] for p in sorted_points]\n",
    "                            y_coords = [p[1] for p in sorted_points]\n",
    "                            ax.plot(x_coords, y_coords,\n",
    "                                    color='#cc0000',\n",
    "                                    linewidth=2,\n",
    "                                    alpha=1.0,\n",
    "                                    zorder=9)\n",
    "\n",
    "                        # Formatting\n",
    "                        ax.set_xlabel('Policy Limit (log scale)', fontsize=10)\n",
    "                        ax.set_ylabel('Growth Rate', fontsize=10)\n",
    "                        ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "\n",
    "                        # Set title for each subplot\n",
    "                        cap_label = f\"${cap/1_000_000:.0f}M\"\n",
    "                        ax.set_title(f'Initial Cap: {cap_label} ; Shape: {shape_param}', fontsize=9)\n",
    "\n",
    "                        # Set axis limits\n",
    "                        # ax.set_xlim(x_min, x_max)\n",
    "                        ax.set_xlim(np.log10(25000000* 0.9),\n",
    "                                    np.log10(500000000 * 1.1))\n",
    "                        if (cap == 25_000_000):\n",
    "                            ax.set_ylim(-0.15, 0.03)\n",
    "                            # ax.set_ylim(y_min, y_max)\n",
    "                        elif (cap == 50_000_000):\n",
    "                            ax.set_ylim(-0.15, 0.03)\n",
    "                            # ax.set_ylim(y_min, y_max)\n",
    "                        else:\n",
    "                            ax.set_ylim(y_min, y_max)\n",
    "\n",
    "                        # Set x-ticks to show actual policy limit values\n",
    "                        ax.set_xticks([np.log10(25e6),\n",
    "                                        np.log10(50e6),\n",
    "                                        np.log10(75e6),\n",
    "                                        np.log10(100e6), \n",
    "                                        np.log10(150e6),\n",
    "                                        np.log10(250e6),\n",
    "                                        np.log10(350e6),\n",
    "                                        np.log10(500e6)])\n",
    "                        ax.set_xticklabels(['25M',\n",
    "                                            '50M',\n",
    "                                            '75M', \n",
    "                                            '100M', \n",
    "                                            '150M',\n",
    "                                            '250M', \n",
    "                                            '350M',\n",
    "                                            '500M'])\n",
    "\n",
    "                # Color legend (percentiles + mean)\n",
    "                color_elements = []\n",
    "                for pct in legend_percentiles:\n",
    "                    color_elements.append(mpatches.Patch(color=cmap(pct),\n",
    "                                                        label=f'{int(pct*100)}th %ile',\n",
    "                                                        edgecolor='black',\n",
    "                                                        linewidth=0.5))\n",
    "                color_elements.append(mpatches.Patch(color=\"#d3360e\",\n",
    "                                                    label='Mean',\n",
    "                                                    edgecolor='#d3360e',\n",
    "                                                    linewidth=0.5))\n",
    "\n",
    "                fig.legend(handles=color_elements, loc='upper center',\n",
    "                            bbox_to_anchor=(0.5, 0.0), title='Percentile',\n",
    "                            frameon=False, fontsize=9, ncol=len(color_elements))\n",
    "\n",
    "                plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "\n",
    "                # Save figure\n",
    "                filename = f'cache/growth_v_limit_lr_{str(loss_ratio).replace(\".\", \"p\")}_thresh_{threshold}_scale_{str(scale).replace(\".\", \"p\")}.png'\n",
    "                plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "                print(f'Saved: {filename}')\n",
    "                plt.close()\n",
    "\n",
    "\n",
    "create_efficiency_frontier_plots(ins_only_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b969ae",
   "metadata": {},
   "source": [
    "## Plot Individual Graphs of Growth vs Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad99255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as mpatches\n",
    "# import numpy as np\n",
    "\n",
    "# from matplotlib.lines import Line2D\n",
    "# from scipy.interpolate import interp1d\n",
    "\n",
    "# # Assuming your data is sto#cc0000 in a list called 'configurations'\n",
    "# # configurations = [{'risk_of_ruin': {...}, 'growth_rate': ..., 'X_Scale': ..., ...}, ...]\n",
    "\n",
    "\n",
    "# def create_efficiency_frontier_plots_base_only(configurations):\n",
    "#     \"\"\"\n",
    "#     Create efficiency frontier plots for actuarial simulation results.\n",
    "    \n",
    "#     FIXED VERSION: Includes comprehensive error handling for pcolormesh issues.\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     configurations : list of dict\n",
    "#         List of configuration dictionaries with simulation results\n",
    "\n",
    "#     Output:\n",
    "#     -------\n",
    "#     Saves PNG files for each X_Scale with efficiency frontier plots.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Get unique values for separate charts\n",
    "#     x_scales = sorted(set(c['X_Scale'] for c in configurations))\n",
    "#     lr = sorted(set(c['LR'] for c in configurations))\n",
    "#     caps = sorted(set(c['Cap'] for c in configurations))\n",
    "\n",
    "#     # Define percentiles for overlay\n",
    "#     highlight_percentiles = [0.50, 0.75, 0.90, 0.95, 0.99]\n",
    "#     legend_percentiles = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]\n",
    "#     all_percentiles = np.arange(0.01, 1.00, 0.01).tolist()\n",
    "\n",
    "#     for cap in caps:\n",
    "#         # Create a plot for each X_Scale\n",
    "#         for scale in x_scales:\n",
    "#             for loss_ratio in lr:\n",
    "#                 if scale != 1.0 or loss_ratio != 0.6:\n",
    "#                     continue\n",
    "\n",
    "#                 config_subset = [c for c in configurations if c['Cap'] == cap and c['X_Scale'] == scale and c['LR'] == loss_ratio]\n",
    "#                 # Get unique values for faceting\n",
    "#                 x_shapes = sorted(set(float(c['X_Shape']) for c in config_subset))\n",
    "#                 x_shapes = [s for s in x_shapes if s != 0] # Filter out 0\n",
    "#                 base_shape = 1.0\n",
    "#                 x_shapes = [base_shape]\n",
    "#                 x_thresholds = sorted({(c['X_Th_%le'] if isinstance(c['X_Th_%le'], (float, np.floating)) else 0.0) for c in config_subset})\n",
    "#                 x_thresholds = [s for s in x_thresholds if s != 0] # Filter out 0\n",
    "#                 base_threshold = 0.001\n",
    "#                 x_thresholds = [base_threshold]\n",
    "\n",
    "#                 # Filter configurations for this scale\n",
    "#                 scale_configs = config_subset\n",
    "\n",
    "#                 # Create figure with subplots\n",
    "#                 n_rows = len(x_thresholds)\n",
    "#                 n_cols = len(x_shapes)\n",
    "\n",
    "#                 fig, axes = plt.subplots(n_rows, n_cols,\n",
    "#                                         figsize=(5*3, 4*2),\n",
    "#                                         dpi=300,\n",
    "#                                         squeeze=False)\n",
    "\n",
    "#                 # Set overall title\n",
    "#                 scale_label = f\"{float(scale):.1f}x\" if scale != '1' else \"Baseline\"\n",
    "#                 lr_pct = f\"{loss_ratio*100:.0f}%\"\n",
    "#                 threshold_pct = f\"{base_threshold*100:.2f}%\"\n",
    "#                 fig.suptitle(f'Efficiency Frontier (Init Cap: {cap/1_000_000:.0f}M; Scale: {scale_label}; Loss Ratio: {lr_pct}; Tail Threshold: {threshold_pct}; Shape: {base_shape})',\n",
    "#                             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "#                 # Create colormap for percentiles\n",
    "#                 cmap = plt.cm.viridis\n",
    "\n",
    "#                 # Plot each facet\n",
    "#                 for i, threshold in enumerate(x_thresholds):\n",
    "#                     for j, shape_param in enumerate(x_shapes):\n",
    "#                         ax = axes[i, j]\n",
    "\n",
    "#                         # Debug: Check what values we're comparing\n",
    "#                         if threshold == 0 or shape_param == 0:\n",
    "#                             print(\n",
    "#                                 f\"\\n=== Debug for threshold={threshold}, shape_param={shape_param} ===\")\n",
    "#                             print(\n",
    "#                                 f\"shape_param type: {type(shape_param)}, value: {repr(shape_param)}\")\n",
    "#                             print(\n",
    "#                                 f\"threshold type: {type(threshold)}, value: {repr(threshold)}\")\n",
    "\n",
    "#                             # Sample a few configs to see their actual values\n",
    "#                             for c in scale_configs[:3]:\n",
    "#                                 print(\n",
    "#                                     f\"  X_Shape: {repr(c['X_Shape'])} (type: {type(c['X_Shape'])})\")\n",
    "#                                 print(\n",
    "#                                     f\"  X_Th_%le: {repr(c['X_Th_%le'])} (type: {type(c['X_Th_%le'])})\")\n",
    "#                                 print(\n",
    "#                                     f\"  float(c['X_Shape']) == shape_param: {float(c['X_Shape']) == shape_param}\")\n",
    "#                                 print(\n",
    "#                                     f\"  Threshold match: {c['X_Th_%le'] == threshold or (c['X_Th_%le'] is None and threshold == 0)}\")\n",
    "#                                 print()\n",
    "\n",
    "#                         # Filter for this facet\n",
    "#                         facet_configs = [c for c in scale_configs\n",
    "#                                         if (c['X_Th_%le'] == threshold or (c['X_Th_%le'] == 'None' and threshold == 0))\n",
    "#                                         and float(c['X_Shape']) == shape_param]\n",
    "\n",
    "#                         if (threshold == 0 or shape_param == 0):\n",
    "#                             print(len(facet_configs))\n",
    "\n",
    "#                         # Intermediate pass - Create smooth gradient using pcolormesh\n",
    "#                         # Organize data by percentile\n",
    "#                         percentile_data = {pct: [] for pct in all_percentiles}\n",
    "\n",
    "#                         for config in facet_configs:\n",
    "#                             # Calculate log of policy limit for x-axis\n",
    "#                             if config.get('NOINS', False):\n",
    "#                                 continue  # Skip NOINS\n",
    "#                             else:\n",
    "#                                 pol_lim = config.get('Pol_Lim', [''])[0] if isinstance(\n",
    "#                                     config.get('Pol_Lim'), list) else config.get('Pol_Lim', '')\n",
    "#                                 x_value = np.log10(float(pol_lim))\n",
    "                            \n",
    "#                             # Collect percentile values\n",
    "#                             if 'growth_rate_ci' in config and config['growth_rate_ci']:\n",
    "#                                 for pct in all_percentiles:\n",
    "#                                     pct_key = f\"{pct:.2f}\" if f\"{pct:.2f}\" in config['growth_rate_ci'] else pct\n",
    "#                                     if pct_key in config['growth_rate_ci']:\n",
    "#                                         growth = config['growth_rate_ci'][pct_key]\n",
    "#                                         percentile_data[pct].append((x_value, growth, float(pol_lim)))\n",
    "\n",
    "#                         # Get unique x values (policy limits) and sort\n",
    "#                         unique_x_values = sorted(set(p[0] for pct_list in percentile_data.values() for p in pct_list))\n",
    "\n",
    "#                         if len(unique_x_values) > 1:\n",
    "#                             # Create interpolation grid with many points for smooth gradient\n",
    "#                             x_interp = np.linspace(min(unique_x_values), max(unique_x_values), 200)\n",
    "                            \n",
    "#                             # For each percentile, interpolate growth rates across policy limits\n",
    "#                             from scipy.interpolate import interp1d\n",
    "                            \n",
    "#                             y_grid = []\n",
    "#                             valid_percentiles = []\n",
    "                            \n",
    "#                             for pct in sorted(all_percentiles):\n",
    "#                                 if len(percentile_data[pct]) > 1:\n",
    "#                                     # Sort by x value\n",
    "#                                     sorted_data = sorted(percentile_data[pct], key=lambda p: p[0])\n",
    "#                                     x_data = np.array([p[0] for p in sorted_data])\n",
    "#                                     y_data = np.array([p[1] for p in sorted_data])\n",
    "                                    \n",
    "#                                     # CRITICAL FIX: Remove non-finite values and use bounded extrapolation\n",
    "#                                     valid_mask = np.isfinite(x_data) & np.isfinite(y_data)\n",
    "#                                     if np.sum(valid_mask) >= 2:  # Need at least 2 points\n",
    "#                                         x_clean = x_data[valid_mask]\n",
    "#                                         y_clean = y_data[valid_mask]\n",
    "                                        \n",
    "#                                         try:\n",
    "#                                             # Use bounded fill values instead of 'extrapolate' to prevent inf\n",
    "#                                             f = interp1d(x_clean, y_clean, kind='linear', \n",
    "#                                                         bounds_error=False,\n",
    "#                                                         fill_value=(y_clean[0], y_clean[-1]))\n",
    "#                                             y_interp = f(x_interp)\n",
    "                                            \n",
    "#                                             # Validate interpolation output\n",
    "#                                             if np.all(np.isfinite(y_interp)):\n",
    "#                                                 y_grid.append(y_interp)\n",
    "#                                                 valid_percentiles.append(pct)\n",
    "#                                             else:\n",
    "#                                                 print(f\"Warning: Non-finite interpolation at pct={pct}\")\n",
    "#                                         except Exception as e:\n",
    "#                                             print(f\"Interpolation failed at pct={pct}: {e}\")\n",
    "                            \n",
    "#                             if len(y_grid) > 1:\n",
    "#                                 # Convert to 2D array: rows = percentiles, columns = x positions\n",
    "#                                 y_grid = np.asarray(y_grid, dtype=np.float64)\n",
    "                                \n",
    "#                                 # CRITICAL FIX: Check for MaskedArray and validate data\n",
    "#                                 if isinstance(y_grid, np.ma.MaskedArray):\n",
    "#                                     print(f\"Warning: y_grid is MaskedArray, converting...\")\n",
    "#                                     y_grid = y_grid.filled(np.nan)\n",
    "                                \n",
    "#                                 # Final validation: ensure all finite values\n",
    "#                                 if not np.all(np.isfinite(y_grid)):\n",
    "#                                     print(f\"Warning: Non-finite values in y_grid, cleaning...\")\n",
    "#                                     # Replace inf with max/min finite\n",
    "#                                     finite_mask = np.isfinite(y_grid)\n",
    "#                                     if np.any(finite_mask):\n",
    "#                                         max_finite = np.max(y_grid[finite_mask])\n",
    "#                                         min_finite = np.min(y_grid[finite_mask])\n",
    "#                                         y_grid = np.where(np.isposinf(y_grid), max_finite, y_grid)\n",
    "#                                         y_grid = np.where(np.isneginf(y_grid), min_finite, y_grid)\n",
    "#                                         # Fill NaN with column means\n",
    "#                                         for col_idx in range(y_grid.shape[1]):\n",
    "#                                             col = y_grid[:, col_idx]\n",
    "#                                             if np.any(np.isnan(col)):\n",
    "#                                                 col_mean = np.nanmean(col)\n",
    "#                                                 y_grid[np.isnan(col), col_idx] = col_mean\n",
    "                                \n",
    "#                                 # Only proceed if we have valid data\n",
    "#                                 if np.all(np.isfinite(y_grid)):\n",
    "#                                     # Create meshgrid for pcolormesh\n",
    "#                                     X, Y = np.meshgrid(x_interp, valid_percentiles)\n",
    "                                    \n",
    "#                                     # Ensure meshgrids are regular arrays\n",
    "#                                     X = np.asarray(X, dtype=np.float64)\n",
    "#                                     Y = np.asarray(Y, dtype=np.float64)\n",
    "                                    \n",
    "#                                     # Use pcolormesh with the colormap\n",
    "#                                     mesh = ax.pcolormesh(X, y_grid, Y, \n",
    "#                                                         cmap=cmap, \n",
    "#                                                         shading='gouraud',  # Smooth interpolation\n",
    "#                                                         vmin=0, vmax=1,\n",
    "#                                                         zorder=5)\n",
    "#                                 else:\n",
    "#                                     print(f\"Skipping pcolormesh - data still contains non-finite values\")\n",
    "\n",
    "#                         # Second pass: Overlay specific percentiles with shapes\n",
    "#                         for config in facet_configs:\n",
    "#                             # Get risk of ruin at year 25\n",
    "#                             # ror_25 = config['risk_of_ruin'].get(25, config['risk_of_ruin'].get('25'))\n",
    "\n",
    "#                             # Calculate log of policy limit for x-axis\n",
    "#                             if config.get('NOINS', False):\n",
    "#                                 x_value = 0  # or np.nan if you want to exclude NOINS from plot\n",
    "#                             else:\n",
    "#                                 pol_lim = config.get('Pol_Lim', [''])[0] if isinstance(\n",
    "#                                     config.get('Pol_Lim'), list) else config.get('Pol_Lim', '')\n",
    "#                                 x_value = np.log10(float(pol_lim))\n",
    "\n",
    "#                             # Plot mean in #cc0000\n",
    "#                             if 'growth_rate' in config:\n",
    "#                                 growth_mean = config['growth_rate']\n",
    "#                                 ax.scatter(x_value, growth_mean,\n",
    "#                                             marker='o',\n",
    "#                                             c='#cc0000',\n",
    "#                                             alpha=1.0,\n",
    "#                                             edgecolors='#cc0000',\n",
    "#                                             linewidths=1.5,\n",
    "#                                             zorder=10)\n",
    "\n",
    "\n",
    "#                         ### Draw lines connecting means across limits #######\n",
    "#                         # Collect (x, growth_rate, raw_limit) tuples to connect mean growth rates\n",
    "#                         mean_points = []\n",
    "                        \n",
    "#                         for config in facet_configs:\n",
    "#                             # Skip NOINS for connecting line (only plot actual policy limits)\n",
    "#                             if config.get('NOINS', False):\n",
    "#                                 continue\n",
    "#                             pol_lim = config.get('Pol_Lim', [''])[0] if isinstance(\n",
    "#                                 config.get('Pol_Lim'), list) else config.get('Pol_Lim', '')\n",
    "#                             try:\n",
    "#                                 x_value = np.log10(float(pol_lim))\n",
    "#                             except (TypeError, ValueError):\n",
    "#                                 continue\n",
    "#                             if 'growth_rate' in config and config['growth_rate'] is not None:\n",
    "#                                 mean_points.append((x_value, float(config['growth_rate']), float(pol_lim)))\n",
    "                        \n",
    "#                         if len(mean_points) > 1:\n",
    "#                             # Sort by actual (non-log) policy limit to ensure correct ordering\n",
    "#                             sorted_points = sorted(mean_points, key=lambda p: p[2])\n",
    "#                             x_coords = [p[0] for p in sorted_points]\n",
    "#                             y_coords = [p[1] for p in sorted_points]\n",
    "#                             ax.plot(x_coords, y_coords,\n",
    "#                                     color='#cc0000',\n",
    "#                                     linewidth=2,\n",
    "#                                     alpha=1.0,\n",
    "#                                     zorder=9)\n",
    "\n",
    "#                         # Formatting\n",
    "#                         ax.set_xlabel('Policy Limit (log scale)', fontsize=10)\n",
    "#                         ax.set_ylabel('Growth Rate', fontsize=10)\n",
    "#                         ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "\n",
    "#                         # Set title for each subplot\n",
    "#                         # thresh_label = threshold if threshold != 'None' else 'No Tail'\n",
    "#                         # ax.set_title(f'Threshold: {thresh_label}\\nShape: {shape_param}',\n",
    "#                         #             fontsize=9)\n",
    "\n",
    "#                         # Set axis limits\n",
    "#                         # ax.set_xlim(x_min, x_max)\n",
    "#                         ax.set_xlim(np.log10(25000000* 0.9),\n",
    "#                                     np.log10(500000000 * 1.1))\n",
    "#                         # ax.set_ylim(y_min, y_max)\n",
    "\n",
    "#                         # Set x-ticks to show actual policy limit values\n",
    "#                         ax.set_xticks([np.log10(25e6),\n",
    "#                                         np.log10(50e6),\n",
    "#                                         np.log10(75e6),\n",
    "#                                         np.log10(100e6), \n",
    "#                                         np.log10(150e6),\n",
    "#                                         np.log10(250e6),\n",
    "#                                         np.log10(350e6),\n",
    "#                                         np.log10(500e6)])\n",
    "#                         ax.set_xticklabels(['$25M',\n",
    "#                                             '$50M',\n",
    "#                                             '$75M', \n",
    "#                                             '$100M', \n",
    "#                                             '$150M',\n",
    "#                                             '$250M', \n",
    "#                                             '$350M',\n",
    "#                                             '$500M'])\n",
    "\n",
    "#                 # Color legend (percentiles + mean)\n",
    "#                 color_elements = []\n",
    "#                 for pct in legend_percentiles:\n",
    "#                     color_elements.append(mpatches.Patch(color=cmap(pct),\n",
    "#                                                         label=f'{int(pct*100)}th %ile',\n",
    "#                                                         edgecolor='black',\n",
    "#                                                         linewidth=0.5))\n",
    "#                 color_elements.append(mpatches.Patch(color='#cc0000',\n",
    "#                                                     label='Mean',\n",
    "#                                                     edgecolor='#cc0000',\n",
    "#                                                     linewidth=0.5))\n",
    "\n",
    "#                 fig.legend(handles=color_elements, loc='upper center',\n",
    "#                             bbox_to_anchor=(0.5, 0.0), title='Percentile',\n",
    "#                             frameon=False, fontsize=9, ncol=len(color_elements))\n",
    "\n",
    "#                 plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "\n",
    "#                 # Save figure\n",
    "#                 filename = f'cache/efficiency_frontier_base_cap({cap/1_000_000:.0f}M).png'\n",
    "#                 plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "#                 print(f'Saved: {filename}')\n",
    "#                 plt.close()\n",
    "\n",
    "\n",
    "# create_efficiency_frontier_plots_base_only(ins_only_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928bc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
