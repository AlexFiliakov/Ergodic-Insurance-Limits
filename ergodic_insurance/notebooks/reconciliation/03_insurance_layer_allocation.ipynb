{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-00-md",
   "metadata": {},
   "source": [
    "# Reconciliation #03: Insurance Layer Allocation\n",
    "\n",
    "## Overview\n",
    "This notebook verifies that loss events are correctly allocated across a\n",
    "multi-layer insurance program. Specifically it checks:\n",
    "\n",
    "- The retention is absorbed correctly before any layer responds.\n",
    "- Each layer pays within its attachment point and per-occurrence limit.\n",
    "- Aggregate limits deplete correctly across multiple claims.\n",
    "- **No dollars appear or disappear** -- the conservation equation holds for\n",
    "  every claim:\n",
    "  `Retention + Sum(Layer Recoveries) + Uninsured Excess == Ground-Up Loss`\n",
    "\n",
    "## Prerequisites\n",
    "- `ergodic_insurance` package installed\n",
    "- `_reconciliation_helpers.py` in the same directory\n",
    "\n",
    "## Estimated runtime\n",
    "< 10 seconds\n",
    "\n",
    "## Audience\n",
    "Actuaries, developers, and QA engineers validating the insurance allocation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-01-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setup: imports, helpers, and reproducibility.\"\"\"\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- reconciliation helpers ------------------------------------------------\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(\".\")))\n",
    "# Also add the reconciliation directory itself\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(\".\")), \"ergodic_insurance\", \"notebooks\", \"reconciliation\"))\n",
    "# And the notebook's own directory\n",
    "sys.path.insert(0, os.path.abspath(os.path.dirname(\"_reconciliation_helpers.py\")))\n",
    "\n",
    "from _reconciliation_helpers import (\n",
    "    ReconciliationChecker, final_summary, section_header,\n",
    "    notebook_header, timed_cell, fmt_dollar, display_df\n",
    ")\n",
    "\n",
    "# --- insurance APIs -------------------------------------------------------\n",
    "from ergodic_insurance.insurance_program import (\n",
    "    InsuranceProgram, EnhancedInsuranceLayer\n",
    ")\n",
    "\n",
    "# --- reproducibility -------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_header(\n",
    "    3,\n",
    "    \"Insurance Layer Allocation\",\n",
    "    \"Verify that loss events are correctly allocated across a multi-layer \"\n",
    "    \"insurance program -- retention, per-occurrence limits, aggregate depletion, \"\n",
    "    \"and dollar conservation.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03-md-config",
   "metadata": {},
   "source": [
    "## 1. Layer Configuration\n",
    "\n",
    "We build a 3-layer program on top of a $50K self-insured retention:\n",
    "\n",
    "| Layer | Attachment | Limit | Covers |\n",
    "|-------|-----------|-------|--------|\n",
    "| Retention | $0 | $50K | $0 -- $50K |\n",
    "| Layer 1 (Primary) | $50K | $50K | $50K -- $100K |\n",
    "| Layer 2 (1st Excess) | $100K | $200K | $100K -- $300K |\n",
    "| Layer 3 (Umbrella) | $300K | $500K | $300K -- $800K |\n",
    "\n",
    "Any loss above $800K is **uninsured excess**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04-layers",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_header(\"1. Layer Configuration\")\n",
    "\n",
    "RETENTION = 50_000\n",
    "\n",
    "layer_1 = EnhancedInsuranceLayer(\n",
    "    attachment_point=50_000,\n",
    "    limit=50_000,\n",
    "    base_premium_rate=0.05,\n",
    ")\n",
    "layer_2 = EnhancedInsuranceLayer(\n",
    "    attachment_point=100_000,\n",
    "    limit=200_000,\n",
    "    base_premium_rate=0.03,\n",
    ")\n",
    "layer_3 = EnhancedInsuranceLayer(\n",
    "    attachment_point=300_000,\n",
    "    limit=500_000,\n",
    "    base_premium_rate=0.01,\n",
    ")\n",
    "\n",
    "program = InsuranceProgram(\n",
    "    layers=[layer_1, layer_2, layer_3],\n",
    "    deductible=RETENTION,\n",
    "    name=\"Reconciliation Test Program\",\n",
    ")\n",
    "\n",
    "# Display the program summary\n",
    "summary = program.get_program_summary()\n",
    "print(f\"Program: {summary['program_name']}\")\n",
    "print(f\"Deductible (SIR): {fmt_dollar(summary['deductible'])}\")\n",
    "print(f\"Total coverage above SIR: {fmt_dollar(summary['total_coverage'])}\")\n",
    "print(f\"Maximum covered loss: {fmt_dollar(RETENTION + summary['total_coverage'])}\")\n",
    "print()\n",
    "\n",
    "layer_df = pd.DataFrame(summary[\"layers\"])\n",
    "layer_df.columns = [\"Attachment\", \"Limit\", \"Exhaustion Pt\", \"Reinstatements\", \"Premium\"]\n",
    "layer_df.index = [\"Layer 1 (Primary)\", \"Layer 2 (1st Excess)\", \"Layer 3 (Umbrella)\"]\n",
    "for col in [\"Attachment\", \"Limit\", \"Exhaustion Pt\", \"Premium\"]:\n",
    "    layer_df[col] = layer_df[col].apply(lambda v: fmt_dollar(v))\n",
    "display_df(layer_df, \"Program Layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-05-md-allocation",
   "metadata": {},
   "source": [
    "## 2. Per-Occurrence Allocation\n",
    "\n",
    "We process a series of known loss sizes designed to exercise every boundary\n",
    "in the program:\n",
    "\n",
    "| Loss | Expected Allocation |\n",
    "|------|--------------------|\n",
    "| $25K | Entirely within retention |\n",
    "| $75K | Retention + partial Layer 1 |\n",
    "| $150K | Retention + full Layer 1 + partial Layer 2 |\n",
    "| $400K | Retention + full L1 + full L2 + partial L3 |\n",
    "| $1M | Retention + full L1 + full L2 + full L3 + $200K uninsured |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-06-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_header(\"2. Per-Occurrence Allocation\")\n",
    "\n",
    "checker_allocation = ReconciliationChecker(section=\"Per-Occurrence Allocation\")\n",
    "\n",
    "# Reset program for clean state\n",
    "program.reset_annual()\n",
    "\n",
    "test_losses = [25_000, 75_000, 150_000, 400_000, 1_000_000]\n",
    "loss_labels = [\"$25K\", \"$75K\", \"$150K\", \"$400K\", \"$1M\"]\n",
    "\n",
    "# Expected allocations (retention, layer_1, layer_2, layer_3, uninsured_excess)\n",
    "expected = {\n",
    "    25_000:    {\"retention\": 25_000,  \"L1\": 0,      \"L2\": 0,       \"L3\": 0,       \"uninsured\": 0},\n",
    "    75_000:    {\"retention\": 50_000,  \"L1\": 25_000, \"L2\": 0,       \"L3\": 0,       \"uninsured\": 0},\n",
    "    150_000:   {\"retention\": 50_000,  \"L1\": 50_000, \"L2\": 50_000,  \"L3\": 0,       \"uninsured\": 0},\n",
    "    400_000:   {\"retention\": 50_000,  \"L1\": 50_000, \"L2\": 200_000, \"L3\": 100_000, \"uninsured\": 0},\n",
    "    1_000_000: {\"retention\": 50_000,  \"L1\": 50_000, \"L2\": 200_000, \"L3\": 500_000, \"uninsured\": 200_000},\n",
    "}\n",
    "\n",
    "allocation_rows = []\n",
    "\n",
    "with timed_cell(\"Per-Occurrence Allocation\"):\n",
    "    for loss in test_losses:\n",
    "        # Process each loss independently -- reset between claims\n",
    "        program.reset_annual()\n",
    "        result = program.process_claim(loss)\n",
    "\n",
    "        # Extract per-layer payments\n",
    "        layer_payments = {0: 0.0, 1: 0.0, 2: 0.0}\n",
    "        for lp in result.layers_triggered:\n",
    "            layer_payments[lp.layer_index] = lp.payment\n",
    "\n",
    "        total_insurance = result.insurance_recovery\n",
    "        # Retention is what the insured pays minus the uncovered excess portion\n",
    "        # In the ClaimResult, deductible_paid = original deductible + uncovered_loss\n",
    "        retention_actual = min(loss, RETENTION)\n",
    "        uninsured_actual = result.uncovered_loss\n",
    "\n",
    "        exp = expected[loss]\n",
    "\n",
    "        allocation_rows.append({\n",
    "            \"Loss\": fmt_dollar(loss),\n",
    "            \"Retention\": fmt_dollar(retention_actual),\n",
    "            \"Layer 1\": fmt_dollar(layer_payments[0]),\n",
    "            \"Layer 2\": fmt_dollar(layer_payments[1]),\n",
    "            \"Layer 3\": fmt_dollar(layer_payments[2]),\n",
    "            \"Uninsured\": fmt_dollar(uninsured_actual),\n",
    "            \"Total Check\": fmt_dollar(retention_actual + total_insurance + uninsured_actual),\n",
    "        })\n",
    "\n",
    "        # --- Conservation check ---\n",
    "        reconstructed = retention_actual + total_insurance + uninsured_actual\n",
    "        checker_allocation.assert_close(\n",
    "            reconstructed, loss, tol=0.01,\n",
    "            message=f\"Conservation: {fmt_dollar(loss)} loss\",\n",
    "        )\n",
    "\n",
    "        # --- Layer-specific checks ---\n",
    "        checker_allocation.assert_close(\n",
    "            layer_payments[0], exp[\"L1\"], tol=0.01,\n",
    "            message=f\"Layer 1 payment for {fmt_dollar(loss)} loss\",\n",
    "        )\n",
    "        checker_allocation.assert_close(\n",
    "            layer_payments[1], exp[\"L2\"], tol=0.01,\n",
    "            message=f\"Layer 2 payment for {fmt_dollar(loss)} loss\",\n",
    "        )\n",
    "        checker_allocation.assert_close(\n",
    "            layer_payments[2], exp[\"L3\"], tol=0.01,\n",
    "            message=f\"Layer 3 payment for {fmt_dollar(loss)} loss\",\n",
    "        )\n",
    "        checker_allocation.assert_close(\n",
    "            uninsured_actual, exp[\"uninsured\"], tol=0.01,\n",
    "            message=f\"Uninsured excess for {fmt_dollar(loss)} loss\",\n",
    "        )\n",
    "\n",
    "alloc_df = pd.DataFrame(allocation_rows)\n",
    "display_df(alloc_df, \"Per-Occurrence Allocation Results\")\n",
    "\n",
    "checker_allocation.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-07-md-chart",
   "metadata": {},
   "source": [
    "### Stacked Bar Chart -- Layer Allocation by Loss Size\n",
    "\n",
    "For each test loss, the chart shows the dollar allocation to each bucket:\n",
    "retention (grey), Layer 1 (blue), Layer 2 (orange), Layer 3 (green), and\n",
    "uninsured excess (red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Stacked bar chart of layer allocation.\"\"\"\n",
    "\n",
    "# Re-collect numeric data for charting\n",
    "chart_data = {\"Retention\": [], \"Layer 1\": [], \"Layer 2\": [], \"Layer 3\": [], \"Uninsured\": []}\n",
    "\n",
    "for loss in test_losses:\n",
    "    program.reset_annual()\n",
    "    result = program.process_claim(loss)\n",
    "    lp = {0: 0.0, 1: 0.0, 2: 0.0}\n",
    "    for p in result.layers_triggered:\n",
    "        lp[p.layer_index] = p.payment\n",
    "    chart_data[\"Retention\"].append(min(loss, RETENTION))\n",
    "    chart_data[\"Layer 1\"].append(lp[0])\n",
    "    chart_data[\"Layer 2\"].append(lp[1])\n",
    "    chart_data[\"Layer 3\"].append(lp[2])\n",
    "    chart_data[\"Uninsured\"].append(result.uncovered_loss)\n",
    "\n",
    "colors = [\"#999999\", \"#4a86c8\", \"#f5a623\", \"#2ecc71\", \"#e74c3c\"]\n",
    "categories = list(chart_data.keys())\n",
    "x = np.arange(len(test_losses))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bottom = np.zeros(len(test_losses))\n",
    "\n",
    "for cat, color in zip(categories, colors):\n",
    "    vals = np.array(chart_data[cat])\n",
    "    ax.bar(x, vals, bottom=bottom, label=cat, color=color, width=0.6)\n",
    "    bottom += vals\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(loss_labels)\n",
    "ax.set_xlabel(\"Ground-Up Loss\")\n",
    "ax.set_ylabel(\"Dollars\")\n",
    "ax.set_title(\"Insurance Layer Allocation by Loss Size\")\n",
    "ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda v, _: f\"${v:,.0f}\"))\n",
    "ax.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-09-md-boundary",
   "metadata": {},
   "source": [
    "## 3. Boundary Testing\n",
    "\n",
    "Verify behaviour at the exact attachment points and limit exhaustion points\n",
    "for each layer. These are the most likely places for off-by-one errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_header(\"3. Boundary Testing\")\n",
    "\n",
    "checker_boundary = ReconciliationChecker(section=\"Boundary Tests\")\n",
    "\n",
    "# Boundary losses: at, just below, and just above each critical point\n",
    "boundary_tests = [\n",
    "    # (loss, description, expected_L1, expected_L2, expected_L3)\n",
    "    (50_000,       \"At retention (L1 attach)\",       0,       0,       0),\n",
    "    (50_001,       \"Just above L1 attach\",            1,       0,       0),\n",
    "    (100_000,      \"L1 exhausted / L2 attach\",  50_000,       0,       0),\n",
    "    (100_001,      \"Just above L2 attach\",      50_000,       1,       0),\n",
    "    (300_000,      \"L2 exhausted / L3 attach\",  50_000, 200_000,       0),\n",
    "    (300_001,      \"Just above L3 attach\",      50_000, 200_000,       1),\n",
    "    (800_000,      \"L3 exhausted\",              50_000, 200_000, 500_000),\n",
    "    (800_001,      \"Just above L3 exhaust\",     50_000, 200_000, 500_000),\n",
    "]\n",
    "\n",
    "with timed_cell(\"Boundary Tests\"):\n",
    "    for loss, desc, exp_l1, exp_l2, exp_l3 in boundary_tests:\n",
    "        program.reset_annual()\n",
    "        result = program.process_claim(loss)\n",
    "\n",
    "        lp = {0: 0.0, 1: 0.0, 2: 0.0}\n",
    "        for p in result.layers_triggered:\n",
    "            lp[p.layer_index] = p.payment\n",
    "\n",
    "        # Check each layer\n",
    "        checker_boundary.assert_close(\n",
    "            lp[0], exp_l1, tol=0.01,\n",
    "            message=f\"L1 @ {desc}\",\n",
    "        )\n",
    "        checker_boundary.assert_close(\n",
    "            lp[1], exp_l2, tol=0.01,\n",
    "            message=f\"L2 @ {desc}\",\n",
    "        )\n",
    "        checker_boundary.assert_close(\n",
    "            lp[2], exp_l3, tol=0.01,\n",
    "            message=f\"L3 @ {desc}\",\n",
    "        )\n",
    "\n",
    "        # Conservation always holds\n",
    "        retention_actual = min(loss, RETENTION)\n",
    "        reconstructed = retention_actual + result.insurance_recovery + result.uncovered_loss\n",
    "        checker_boundary.assert_close(\n",
    "            reconstructed, loss, tol=0.01,\n",
    "            message=f\"Conservation @ {desc}\",\n",
    "        )\n",
    "\n",
    "        # Each layer recovery <= its limit\n",
    "        checker_boundary.check(\n",
    "            lp[0] <= layer_1.limit + 0.01,\n",
    "            f\"L1 <= limit @ {desc}\",\n",
    "            f\"{fmt_dollar(lp[0])} <= {fmt_dollar(layer_1.limit)}\",\n",
    "        )\n",
    "        checker_boundary.check(\n",
    "            lp[1] <= layer_2.limit + 0.01,\n",
    "            f\"L2 <= limit @ {desc}\",\n",
    "            f\"{fmt_dollar(lp[1])} <= {fmt_dollar(layer_2.limit)}\",\n",
    "        )\n",
    "        checker_boundary.check(\n",
    "            lp[2] <= layer_3.limit + 0.01,\n",
    "            f\"L3 <= limit @ {desc}\",\n",
    "            f\"{fmt_dollar(lp[2])} <= {fmt_dollar(layer_3.limit)}\",\n",
    "        )\n",
    "\n",
    "checker_boundary.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11-md-aggregate",
   "metadata": {},
   "source": "## 4. Aggregate Limit Depletion\n\nWe configure Layer 1 as a **hybrid** layer with a $100K aggregate limit\n(2x the per-occurrence limit of $50K). After enough claims exhaust\nthat aggregate, subsequent claims should get **zero** recovery from Layer 1\neven though they individually exceed its attachment point.\n\nTest sequence: six $75K claims. Each claim puts $25K into Layer 1\n($75K loss minus $50K attachment = $25K, within the $50K per-occurrence cap).\n\n- Claims 1--4: Layer 1 pays $25K each (aggregate used = $25K, $50K, $75K, $100K).\n- Claims 5--6: Layer 1 aggregate exhausted ($100K used), pays $0.\n- Layer 2 and Layer 3 remain unaffected (per-occurrence, no aggregate)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12-aggregate",
   "metadata": {},
   "outputs": [],
   "source": "section_header(\"4. Aggregate Limit Depletion\")\n\nchecker_aggregate = ReconciliationChecker(section=\"Aggregate Depletion\")\n\n# Rebuild Layer 1 with a hybrid limit (per-occurrence $50K, aggregate $100K)\nlayer_1_agg = EnhancedInsuranceLayer(\n    attachment_point=50_000,\n    limit=50_000,\n    base_premium_rate=0.05,\n    limit_type=\"hybrid\",\n    per_occurrence_limit=50_000,\n    aggregate_limit=100_000,\n)\n\n# Layers 2 and 3 remain per-occurrence (no aggregate constraint)\nprogram_agg = InsuranceProgram(\n    layers=[layer_1_agg, layer_2, layer_3],\n    deductible=RETENTION,\n    name=\"Aggregate Test Program\",\n)\n\nclaim_amount = 75_000  # Each claim: $50K retention + $25K into Layer 1\nn_claims = 6\n\n# Each $75K claim puts $25K into L1 (75K - 50K attachment = 25K).\n# Aggregate limit is $100K, so 4 claims x $25K = $100K exhausts the aggregate.\n# Claims 5 and 6 should get $0 from Layer 1.\n\nagg_rows = []\nl1_cumulative = 0.0\n\nwith timed_cell(\"Aggregate Depletion\"):\n    for i in range(1, n_claims + 1):\n        result = program_agg.process_claim(claim_amount)\n\n        lp = {0: 0.0, 1: 0.0, 2: 0.0}\n        for p in result.layers_triggered:\n            lp[p.layer_index] = p.payment\n\n        l1_cumulative += lp[0]\n        retention_actual = min(claim_amount, RETENTION)\n        reconstructed = retention_actual + result.insurance_recovery + result.uncovered_loss\n\n        agg_rows.append({\n            \"Claim #\": i,\n            \"Loss\": fmt_dollar(claim_amount),\n            \"Retention\": fmt_dollar(retention_actual),\n            \"L1 Payment\": fmt_dollar(lp[0]),\n            \"L1 Cumulative\": fmt_dollar(l1_cumulative),\n            \"L2 Payment\": fmt_dollar(lp[1]),\n            \"L3 Payment\": fmt_dollar(lp[2]),\n            \"Uninsured\": fmt_dollar(result.uncovered_loss),\n        })\n\n        # Conservation check\n        checker_aggregate.assert_close(\n            reconstructed, claim_amount, tol=0.01,\n            message=f\"Conservation: claim #{i}\",\n        )\n\n        # Layer 1 aggregate depletion logic\n        if i <= 4:\n            # First four claims: each should get $25K from L1\n            # (4 x $25K = $100K aggregate)\n            checker_aggregate.assert_close(\n                lp[0], 25_000, tol=0.01,\n                message=f\"L1 pays $25K on claim #{i} (aggregate not yet exhausted)\",\n            )\n        else:\n            # Claims 5+: L1 aggregate ($100K) is exhausted\n            checker_aggregate.check(\n                lp[0] <= 0.01,\n                f\"L1 pays $0 on claim #{i} (aggregate exhausted)\",\n                f\"L1 payment = {fmt_dollar(lp[0])}\",\n            )\n\n# Verify cumulative L1 does not exceed aggregate\nchecker_aggregate.check(\n    l1_cumulative <= 100_000 + 0.01,\n    f\"L1 cumulative ({fmt_dollar(l1_cumulative)}) <= aggregate limit ($100,000)\",\n    f\"{fmt_dollar(l1_cumulative)} <= $100,000\",\n)\n\n# Verify cumulative L1 equals exactly $100K (fully used)\nchecker_aggregate.assert_close(\n    l1_cumulative, 100_000, tol=0.01,\n    message=\"L1 aggregate fully utilized (exactly $100K paid)\",\n)\n\nagg_df = pd.DataFrame(agg_rows)\ndisplay_df(agg_df, \"Aggregate Depletion Trace\")\n\nchecker_aggregate.display_results()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13-agg-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Chart: Layer 1 aggregate depletion over successive claims.\"\"\"\n",
    "\n",
    "# Re-run to collect numeric data for chart\n",
    "program_agg.reset_annual()\n",
    "l1_payments = []\n",
    "l1_running = []\n",
    "running = 0.0\n",
    "\n",
    "for _ in range(n_claims):\n",
    "    result = program_agg.process_claim(claim_amount)\n",
    "    lp = {0: 0.0, 1: 0.0, 2: 0.0}\n",
    "    for p in result.layers_triggered:\n",
    "        lp[p.layer_index] = p.payment\n",
    "    l1_payments.append(lp[0])\n",
    "    running += lp[0]\n",
    "    l1_running.append(running)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Left: per-claim Layer 1 payment\n",
    "claim_nums = list(range(1, n_claims + 1))\n",
    "bar_colors = [\"#4a86c8\" if p > 0 else \"#cccccc\" for p in l1_payments]\n",
    "ax1.bar(claim_nums, l1_payments, color=bar_colors, edgecolor=\"#333\")\n",
    "ax1.set_xlabel(\"Claim #\")\n",
    "ax1.set_ylabel(\"Layer 1 Payment\")\n",
    "ax1.set_title(\"Layer 1 Per-Claim Payment\")\n",
    "ax1.yaxis.set_major_formatter(mticker.FuncFormatter(lambda v, _: f\"${v:,.0f}\"))\n",
    "ax1.set_xticks(claim_nums)\n",
    "\n",
    "# Right: cumulative Layer 1 vs aggregate limit\n",
    "ax2.plot(claim_nums, l1_running, marker=\"o\", color=\"#4a86c8\", linewidth=2, label=\"Cumulative L1\")\n",
    "ax2.axhline(100_000, color=\"#e74c3c\", linestyle=\"--\", linewidth=2, label=\"Aggregate Limit ($100K)\")\n",
    "ax2.set_xlabel(\"Claim #\")\n",
    "ax2.set_ylabel(\"Cumulative Payment\")\n",
    "ax2.set_title(\"Layer 1 Aggregate Depletion\")\n",
    "ax2.yaxis.set_major_formatter(mticker.FuncFormatter(lambda v, _: f\"${v:,.0f}\"))\n",
    "ax2.set_xticks(claim_nums)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14-md-summary",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "Combine all check results across sections and display the overall verdict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary(checker_allocation, checker_boundary, checker_aggregate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
