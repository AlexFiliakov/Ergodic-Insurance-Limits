{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Metrics Suite for Tail Risk Analysis\n",
    "\n",
    "This notebook demonstrates the comprehensive risk metrics suite for quantifying tail risk in manufacturing insurance applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('.'))))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Import our modules\n",
    "from ergodic_insurance.src.risk_metrics import RiskMetrics, compare_risk_metrics\n",
    "from ergodic_insurance.src.loss_distributions import (\n",
    "    LognormalLoss, ParetoLoss, ManufacturingLossGenerator\n",
    ")\n",
    "\n",
    "print(\"Modules loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Manufacturing Loss Scenarios\n",
    "\n",
    "First, let's generate realistic loss scenarios for a manufacturing company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate losses using ManufacturingLossGenerator\n",
    "generator = ManufacturingLossGenerator(\n",
    "    annual_revenue=50_000_000,  # $50M annual revenue\n",
    "    attritional_frequency_params={'lambda_base': 5, 'revenue_scaling': 0.3},\n",
    "    large_frequency_params={'lambda_base': 0.5, 'revenue_scaling': 0.2},\n",
    "    attritional_severity_params={'mean': 50_000, 'cv': 0.8},\n",
    "    large_severity_params={'mean': 2_000_000, 'cv': 1.2},\n",
    "    catastrophe_params={'frequency': 0.02, 'min_loss': 10_000_000, 'alpha': 2.5},\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Simulate 10,000 annual loss scenarios\n",
    "n_simulations = 10000\n",
    "annual_losses = []\n",
    "\n",
    "for _ in range(n_simulations):\n",
    "    events = generator.generate_annual_losses()\n",
    "    total_loss = sum(event.amount for event in events)\n",
    "    annual_losses.append(total_loss)\n",
    "\n",
    "annual_losses = np.array(annual_losses)\n",
    "\n",
    "print(f\"Generated {n_simulations:,} annual loss scenarios\")\n",
    "print(f\"Mean annual loss: ${np.mean(annual_losses):,.0f}\")\n",
    "print(f\"Median annual loss: ${np.median(annual_losses):,.0f}\")\n",
    "print(f\"Max annual loss: ${np.max(annual_losses):,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Core Risk Metrics\n",
    "\n",
    "Now let's calculate the key risk metrics: VaR, TVaR, PML, and Expected Shortfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize risk metrics calculator\n",
    "metrics = RiskMetrics(annual_losses, seed=42)\n",
    "\n",
    "# Calculate VaR at different confidence levels\n",
    "confidence_levels = [0.90, 0.95, 0.99, 0.995, 0.999]\n",
    "var_results = {}\n",
    "tvar_results = {}\n",
    "\n",
    "print(\"Value at Risk (VaR) and Tail VaR (TVaR)\\n\" + \"=\"*50)\n",
    "print(f\"{'Confidence':<12} {'VaR':>15} {'TVaR':>15} {'TVaR/VaR':>10}\")\n",
    "print(\"-\"*52)\n",
    "\n",
    "for conf in confidence_levels:\n",
    "    var_val = metrics.var(conf)\n",
    "    tvar_val = metrics.tvar(conf)\n",
    "    var_results[conf] = var_val\n",
    "    tvar_results[conf] = tvar_val\n",
    "    \n",
    "    print(f\"{conf:>10.1%}  ${var_val:>14,.0f}  ${tvar_val:>14,.0f}  {tvar_val/var_val:>9.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PML for standard return periods\n",
    "return_periods = [10, 25, 50, 100, 200, 250, 500, 1000]\n",
    "pml_results = {}\n",
    "\n",
    "print(\"\\nProbable Maximum Loss (PML)\\n\" + \"=\"*40)\n",
    "print(f\"{'Return Period':<15} {'PML':>15} {'Annual Prob':>12}\")\n",
    "print(\"-\"*42)\n",
    "\n",
    "for period in return_periods:\n",
    "    pml_val = metrics.pml(period)\n",
    "    pml_results[period] = pml_val\n",
    "    annual_prob = 1/period\n",
    "    \n",
    "    print(f\"{period:>10}-year  ${pml_val:>14,.0f}  {annual_prob:>11.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate additional metrics\n",
    "print(\"\\nAdditional Risk Metrics\\n\" + \"=\"*40)\n",
    "\n",
    "# Expected Shortfall at VaR(99%) threshold\n",
    "var_99 = var_results[0.99]\n",
    "es_99 = metrics.expected_shortfall(var_99)\n",
    "print(f\"Expected Shortfall (99% threshold): ${es_99:,.0f}\")\n",
    "\n",
    "# Economic Capital\n",
    "ec_999 = metrics.economic_capital(0.999)\n",
    "print(f\"Economic Capital (99.9%): ${ec_999:,.0f}\")\n",
    "\n",
    "# Maximum Drawdown\n",
    "max_dd = metrics.maximum_drawdown()\n",
    "print(f\"Maximum Drawdown: ${max_dd:,.0f}\")\n",
    "\n",
    "# Tail Index (heaviness of tail)\n",
    "tail_idx = metrics.tail_index()\n",
    "print(f\"Tail Index (Hill estimator): {tail_idx:.2f}\")\n",
    "print(f\"  → {'Heavy' if tail_idx < 3 else 'Moderate'} tail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Risk Metrics\n",
    "\n",
    "Let's create comprehensive visualizations of the loss distribution and risk metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive risk visualization\n",
    "fig = metrics.plot_distribution(\n",
    "    bins=50,\n",
    "    show_metrics=True,\n",
    "    confidence_levels=[0.95, 0.99, 0.995]\n",
    ")\n",
    "plt.suptitle('Manufacturing Loss Distribution and Risk Metrics', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bootstrap Confidence Intervals\n",
    "\n",
    "Calculate confidence intervals for risk metrics using bootstrap methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VaR with bootstrap confidence intervals\n",
    "print(\"VaR with 95% Bootstrap Confidence Intervals\\n\" + \"=\"*50)\n",
    "print(f\"{'Confidence':<12} {'VaR':>15} {'CI Lower':>15} {'CI Upper':>15}\")\n",
    "print(\"-\"*57)\n",
    "\n",
    "for conf in [0.95, 0.99, 0.995]:\n",
    "    result = metrics.var(conf, bootstrap_ci=True, n_bootstrap=1000)\n",
    "    ci_lower, ci_upper = result.confidence_interval\n",
    "    \n",
    "    print(f\"{conf:>10.1%}  ${result.value:>14,.0f}  ${ci_lower:>14,.0f}  ${ci_upper:>14,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Coherence Properties Testing\n",
    "\n",
    "Verify that TVaR satisfies the properties of a coherent risk measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test coherence properties\n",
    "coherence_results = metrics.coherence_test()\n",
    "\n",
    "print(\"Coherence Properties of TVaR\\n\" + \"=\"*40)\n",
    "for property_name, satisfied in coherence_results.items():\n",
    "    status = \"✓ Satisfied\" if satisfied else \"✗ Not satisfied\"\n",
    "    print(f\"{property_name.replace('_', ' ').title()}: {status}\")\n",
    "\n",
    "print(\"\\nNote: A coherent risk measure satisfies:\")\n",
    "print(\"  1. Monotonicity\")\n",
    "print(\"  2. Sub-additivity\")\n",
    "print(\"  3. Positive homogeneity\")\n",
    "print(\"  4. Translation invariance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Different Loss Scenarios\n",
    "\n",
    "Compare risk metrics across different operational scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate different scenarios\n",
    "scenarios = {}\n",
    "\n",
    "# Base case\n",
    "scenarios['Base Case'] = annual_losses\n",
    "\n",
    "# High frequency scenario (more claims)\n",
    "generator_high_freq = ManufacturingLossGenerator(\n",
    "    annual_revenue=50_000_000,\n",
    "    attritional_frequency_params={'lambda_base': 8, 'revenue_scaling': 0.3},\n",
    "    large_frequency_params={'lambda_base': 0.8, 'revenue_scaling': 0.2},\n",
    "    attritional_severity_params={'mean': 50_000, 'cv': 0.8},\n",
    "    large_severity_params={'mean': 2_000_000, 'cv': 1.2},\n",
    "    seed=43\n",
    ")\n",
    "\n",
    "high_freq_losses = []\n",
    "for _ in range(5000):\n",
    "    events = generator_high_freq.generate_annual_losses()\n",
    "    high_freq_losses.append(sum(e.amount for e in events))\n",
    "scenarios['High Frequency'] = np.array(high_freq_losses)\n",
    "\n",
    "# High severity scenario (larger claims)\n",
    "generator_high_sev = ManufacturingLossGenerator(\n",
    "    annual_revenue=50_000_000,\n",
    "    attritional_frequency_params={'lambda_base': 5, 'revenue_scaling': 0.3},\n",
    "    large_frequency_params={'lambda_base': 0.5, 'revenue_scaling': 0.2},\n",
    "    attritional_severity_params={'mean': 75_000, 'cv': 0.8},\n",
    "    large_severity_params={'mean': 4_000_000, 'cv': 1.5},\n",
    "    seed=44\n",
    ")\n",
    "\n",
    "high_sev_losses = []\n",
    "for _ in range(5000):\n",
    "    events = generator_high_sev.generate_annual_losses()\n",
    "    high_sev_losses.append(sum(e.amount for e in events))\n",
    "scenarios['High Severity'] = np.array(high_sev_losses)\n",
    "\n",
    "# Compare scenarios\n",
    "comparison_df = compare_risk_metrics(scenarios, confidence_levels=[0.95, 0.99, 0.995])\n",
    "print(\"Risk Metrics Comparison Across Scenarios\")\n",
    "print(\"=\"*60)\n",
    "display(comparison_df.round(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Return Period Analysis\n",
    "\n",
    "Analyze the relationship between return periods and loss magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate return period curves for all scenarios\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Return period curves\n",
    "return_periods = np.array([2, 5, 10, 25, 50, 100, 200, 500, 1000])\n",
    "\n",
    "for scenario_name, losses in scenarios.items():\n",
    "    scenario_metrics = RiskMetrics(losses)\n",
    "    periods, loss_values = scenario_metrics.return_period_curve(return_periods)\n",
    "    ax1.semilogx(periods, loss_values / 1e6, 'o-', label=scenario_name, linewidth=2, markersize=6)\n",
    "\n",
    "ax1.set_xlabel('Return Period (years)', fontsize=12)\n",
    "ax1.set_ylabel('Loss Amount ($M)', fontsize=12)\n",
    "ax1.set_title('Return Period Curves', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3, which='both')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Exceedance probability\n",
    "for scenario_name, losses in scenarios.items():\n",
    "    sorted_losses = np.sort(losses)[::-1]\n",
    "    exceedance_prob = np.arange(1, len(sorted_losses) + 1) / len(sorted_losses)\n",
    "    ax2.semilogy(sorted_losses / 1e6, exceedance_prob, '-', label=scenario_name, linewidth=2)\n",
    "\n",
    "ax2.set_xlabel('Loss Amount ($M)', fontsize=12)\n",
    "ax2.set_ylabel('Annual Exceedance Probability', fontsize=12)\n",
    "ax2.set_title('Exceedance Probability Curves', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3, which='both')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Insurance Limit Selection Using Risk Metrics\n",
    "\n",
    "Demonstrate how risk metrics inform insurance limit selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze insurance limit options\n",
    "print(\"Insurance Limit Selection Analysis\\n\" + \"=\"*50)\n",
    "\n",
    "# Define potential insurance limits based on risk metrics\n",
    "limit_options = {\n",
    "    'Conservative': metrics.var(0.95),\n",
    "    'Standard': metrics.var(0.99),\n",
    "    'PML-100': metrics.pml(100),\n",
    "    'PML-250': metrics.pml(250),\n",
    "    'Aggressive': metrics.tvar(0.99),\n",
    "}\n",
    "\n",
    "# Calculate coverage statistics for each limit\n",
    "print(f\"{'Limit Option':<15} {'Limit Amount':>15} {'Coverage %':>12} {'Avg Uncovered':>15}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for option_name, limit in limit_options.items():\n",
    "    covered_pct = np.mean(annual_losses <= limit) * 100\n",
    "    uncovered_losses = annual_losses[annual_losses > limit] - limit\n",
    "    avg_uncovered = np.mean(uncovered_losses) if len(uncovered_losses) > 0 else 0\n",
    "    \n",
    "    print(f\"{option_name:<15} ${limit:>14,.0f} {covered_pct:>11.1f}% ${avg_uncovered:>14,.0f}\")\n",
    "\n",
    "# Recommendation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Recommendation:\")\n",
    "print(f\"  • For cost-conscious: Use VaR(95%) = ${limit_options['Conservative']:,.0f}\")\n",
    "print(f\"  • For balanced approach: Use PML-100 = ${limit_options['PML-100']:,.0f}\")\n",
    "print(f\"  • For comprehensive coverage: Use TVaR(99%) = ${limit_options['Aggressive']:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Statistics\n",
    "\n",
    "Complete statistical summary of the loss distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive summary statistics\n",
    "summary = metrics.summary_statistics()\n",
    "\n",
    "print(\"Loss Distribution Summary Statistics\\n\" + \"=\"*40)\n",
    "for stat_name, value in summary.items():\n",
    "    if stat_name == 'count':\n",
    "        print(f\"{stat_name.capitalize():<15}: {value:,.0f}\")\n",
    "    elif stat_name in ['skewness', 'kurtosis']:\n",
    "        print(f\"{stat_name.capitalize():<15}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"{stat_name.capitalize():<15}: ${value:,.0f}\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"Interpretation:\")\n",
    "if summary['skewness'] > 1:\n",
    "    print(\"  • Highly right-skewed distribution (heavy tail)\")\n",
    "elif summary['skewness'] > 0:\n",
    "    print(\"  • Moderately right-skewed distribution\")\n",
    "else:\n",
    "    print(\"  • Symmetric or left-skewed distribution\")\n",
    "\n",
    "if summary['kurtosis'] > 3:\n",
    "    print(\"  • Leptokurtic (fat tails, higher tail risk)\")\n",
    "elif summary['kurtosis'] < 3:\n",
    "    print(\"  • Platykurtic (thin tails, lower tail risk)\")\n",
    "else:\n",
    "    print(\"  • Mesokurtic (normal-like tails)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Risk-Adjusted Performance Metrics\n",
    "\n",
    "Calculate risk-adjusted metrics for investment decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume company generates returns that offset losses\n",
    "# Convert losses to returns for risk-adjusted metrics\n",
    "expected_revenue = 50_000_000\n",
    "operating_margin = 0.08\n",
    "expected_profit = expected_revenue * operating_margin\n",
    "\n",
    "# Net returns after losses\n",
    "net_returns = expected_profit - annual_losses\n",
    "\n",
    "# Calculate risk-adjusted metrics\n",
    "metrics_returns = RiskMetrics(-net_returns)  # Negative because we want returns, not losses\n",
    "risk_adjusted = metrics_returns.risk_adjusted_metrics(risk_free_rate=0.02)\n",
    "\n",
    "print(\"Risk-Adjusted Performance Metrics\\n\" + \"=\"*40)\n",
    "print(f\"Mean Return: ${-risk_adjusted['mean_return']:,.0f}\")\n",
    "print(f\"Volatility: ${risk_adjusted['volatility']:,.0f}\")\n",
    "print(f\"Sharpe Ratio: {risk_adjusted['sharpe_ratio']:.3f}\")\n",
    "print(f\"Sortino Ratio: {risk_adjusted['sortino_ratio']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"Interpretation:\")\n",
    "if risk_adjusted['sharpe_ratio'] > 1:\n",
    "    print(\"  • Excellent risk-adjusted returns\")\n",
    "elif risk_adjusted['sharpe_ratio'] > 0.5:\n",
    "    print(\"  • Good risk-adjusted returns\")\n",
    "elif risk_adjusted['sharpe_ratio'] > 0:\n",
    "    print(\"  • Positive but modest risk-adjusted returns\")\n",
    "else:\n",
    "    print(\"  • Negative risk-adjusted returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This comprehensive risk metrics suite provides:\n",
    "\n",
    "1. **VaR and TVaR** for regulatory compliance and risk limits\n",
    "2. **PML** for catastrophe modeling and reinsurance decisions\n",
    "3. **Expected Shortfall** for tail risk assessment\n",
    "4. **Economic Capital** for capital allocation\n",
    "5. **Return Period Curves** for insurance limit selection\n",
    "6. **Bootstrap Confidence Intervals** for uncertainty quantification\n",
    "7. **Coherence Testing** to verify risk measure properties\n",
    "8. **Risk-Adjusted Metrics** for investment decisions\n",
    "\n",
    "These metrics enable data-driven insurance optimization that transforms insurance from a cost center to a strategic growth enabler."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
