{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconciliation #05: Loss Distribution Calibration\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook verifies that the `ManufacturingLossGenerator` produces losses\n",
    "whose empirical frequency and severity match the configured theoretical\n",
    "parameters. Each of the three loss types (attritional, large, catastrophic)\n",
    "is checked for statistical consistency using Kolmogorov-Smirnov tests,\n",
    "moment comparisons, and CDF overlays.\n",
    "\n",
    "**What is tested:**\n",
    "- Attritional severity follows Lognormal(mean=25000, cv=1.5)\n",
    "- Large severity follows Lognormal(mean=2000000, cv=2.0)\n",
    "- Catastrophic severity follows Pareto(alpha=2.5, xm=1000000)\n",
    "- Each loss type has frequency consistent with its Poisson rate\n",
    "- Aggregate annual loss mean equals the sum of component means\n",
    "\n",
    "**Prerequisites:** `ergodic_insurance` package installed\n",
    "\n",
    "**Estimated runtime:** < 30 seconds\n",
    "\n",
    "**Audience:** Developers, actuaries validating model calibration"
   ]
  },
  {
   "cell_type": "code",
   "source": "\"\"\"Google Colab setup: mount Drive and install package dependencies.\n\nRun this cell first. If prompted to restart the runtime, do so, then re-run all cells.\nThis cell is a no-op when running locally.\n\"\"\"\nimport sys, os\nif 'google.colab' in sys.modules:\n    from google.colab import drive\n    drive.mount('/content/drive')\n\n    NOTEBOOK_DIR = '/content/drive/My Drive/Colab Notebooks/ei_notebooks/reconciliation'\n\n    if os.path.exists(os.path.join(NOTEBOOK_DIR, '_reconciliation_helpers.py')):\n        print(f\"Found helper module in {NOTEBOOK_DIR}\")\n        os.chdir(NOTEBOOK_DIR)\n        if NOTEBOOK_DIR not in sys.path:\n            sys.path.append(NOTEBOOK_DIR)\n    else:\n        print(f\"WARNING: _reconciliation_helpers.py not found in {NOTEBOOK_DIR}\")\n        print(\"Please update NOTEBOOK_DIR in this cell to the correct folder path.\")\n\n    !pip install git+https://github.com/AlexFiliakov/Ergodic-Insurance-Limits.git -q 2>&1 | tail -3\n    print('\\nSetup complete. If you see numpy/scipy import errors below,')\n    print('restart the runtime (Runtime > Restart runtime) and re-run all cells.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(\".\")))\n",
    "from _reconciliation_helpers import (\n",
    "    ReconciliationChecker, final_summary, section_header,\n",
    "    notebook_header, timed_cell, fmt_dollar, display_df\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as sp_stats\n",
    "\n",
    "from ergodic_insurance.loss_distributions import (\n",
    "    ManufacturingLossGenerator, LossEvent, LognormalLoss, ParetoLoss\n",
    ")\n",
    "\n",
    "notebook_header(\n",
    "    5,\n",
    "    \"Loss Distribution Calibration\",\n",
    "    \"Verify that generated losses match configured frequency and severity parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Loss Generator\n",
    "\n",
    "We use the default `ManufacturingLossGenerator` parameters at the reference\n",
    "revenue of $10M so that frequency scaling factors are exactly 1.0. This\n",
    "lets us compare directly against the base distribution parameters.\n",
    "\n",
    "| Component | Frequency | Severity Distribution | Key Parameters |\n",
    "|---|---|---|---|\n",
    "| Attritional | 5.0/yr | Lognormal | mean=\\$25,000, cv=1.5 |\n",
    "| Large | 0.3/yr | Lognormal | mean=\\$2,000,000, cv=2.0 |\n",
    "| Catastrophic | 0.03/yr | Pareto | alpha=2.5, xm=\\$1,000,000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "SEED = 42  # Fixed seed for reproducibility\nREVENUE = 10_000_000  # Reference revenue -> scaling factor = 1.0\nN_YEARS = 2_000  # Simulate many years to accumulate ~10K+ attritional events\n\n# Default parameters (from class definitions)\nATTRITIONAL_FREQ = 5.0\nATTRITIONAL_MEAN = 25_000\nATTRITIONAL_CV = 1.5\n\nLARGE_FREQ = 0.3\nLARGE_MEAN = 2_000_000\nLARGE_CV = 2.0\n\nCAT_FREQ = 0.03\nCAT_ALPHA = 2.5\nCAT_XM = 1_000_000\n\n# Theoretical Pareto mean: alpha * xm / (alpha - 1)\nCAT_THEORETICAL_MEAN = CAT_ALPHA * CAT_XM / (CAT_ALPHA - 1)\n\n# Theoretical lognormal std: mean * sqrt(exp(sigma^2) - 1) where sigma^2 = log(1 + cv^2)\ndef lognormal_std(mean, cv):\n    \"\"\"Theoretical standard deviation of a Lognormal(mean, cv) distribution.\"\"\"\n    return mean * cv  # by definition: cv = std / mean\n\n# Pareto variance: xm^2 * alpha / ((alpha-1)^2 * (alpha-2)) for alpha > 2\nCAT_THEORETICAL_VAR = (CAT_XM**2 * CAT_ALPHA) / ((CAT_ALPHA - 1)**2 * (CAT_ALPHA - 2))\nCAT_THEORETICAL_STD = np.sqrt(CAT_THEORETICAL_VAR)\n\nprint(f\"Simulation: {N_YEARS:,} years at ${REVENUE:,.0f} revenue\")\nprint(f\"Expected attritional events: ~{ATTRITIONAL_FREQ * N_YEARS:,.0f}\")\nprint(f\"Expected large events: ~{LARGE_FREQ * N_YEARS:,.0f}\")\nprint(f\"Expected catastrophic events: ~{CAT_FREQ * N_YEARS:,.0f}\")\nprint(f\"\\nTheoretical means:\")\nprint(f\"  Attritional severity: ${ATTRITIONAL_MEAN:,.0f}\")\nprint(f\"  Large severity:       ${LARGE_MEAN:,.0f}\")\nprint(f\"  Catastrophic severity: ${CAT_THEORETICAL_MEAN:,.0f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample\n",
    "\n",
    "Generate losses over the full simulation horizon in a single call, then\n",
    "separate by loss type for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timed_cell(\"Generate losses\"):\n",
    "    generator = ManufacturingLossGenerator(seed=SEED)\n",
    "    all_losses, sim_stats = generator.generate_losses(\n",
    "        duration=N_YEARS, revenue=REVENUE, include_catastrophic=True\n",
    "    )\n",
    "\n",
    "# Separate by type\n",
    "attritional_losses = [e for e in all_losses if e.loss_type == \"attritional\"]\n",
    "large_losses = [e for e in all_losses if e.loss_type == \"large\"]\n",
    "cat_losses = [e for e in all_losses if e.loss_type == \"catastrophic\"]\n",
    "\n",
    "attritional_amounts = np.array([e.amount for e in attritional_losses])\n",
    "large_amounts = np.array([e.amount for e in large_losses])\n",
    "cat_amounts = np.array([e.amount for e in cat_losses])\n",
    "\n",
    "print(f\"Total events generated: {len(all_losses):,}\")\n",
    "print(f\"  Attritional: {len(attritional_losses):,}\")\n",
    "print(f\"  Large:       {len(large_losses):,}\")\n",
    "print(f\"  Catastrophic: {len(cat_losses):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Attritional Losses\n",
    "\n",
    "Attritional losses use a **Lognormal** severity distribution with\n",
    "mean=$25,000 and CV=1.5. We compare the empirical moments against\n",
    "theoretical values and run a KS test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_header(\"Attritional Losses\")\n",
    "chk_att = ReconciliationChecker(\"Attritional Severity\")\n",
    "\n",
    "# --- Empirical statistics ---\n",
    "emp_mean_att = np.mean(attritional_amounts)\n",
    "emp_std_att = np.std(attritional_amounts, ddof=1)\n",
    "n_att = len(attritional_amounts)\n",
    "\n",
    "theo_mean_att = ATTRITIONAL_MEAN\n",
    "theo_std_att = lognormal_std(ATTRITIONAL_MEAN, ATTRITIONAL_CV)\n",
    "\n",
    "# Allow 10% relative tolerance for mean (generous for large samples)\n",
    "mean_rel_err_att = abs(emp_mean_att - theo_mean_att) / theo_mean_att\n",
    "chk_att.check(\n",
    "    mean_rel_err_att < 0.10,\n",
    "    \"Attritional mean within 10% of theoretical\",\n",
    "    f\"Empirical={fmt_dollar(emp_mean_att)}, Theoretical={fmt_dollar(theo_mean_att)}, RelErr={mean_rel_err_att:.4f}\"\n",
    ")\n",
    "\n",
    "# Std within 15% (higher tolerance due to lognormal skew)\n",
    "std_rel_err_att = abs(emp_std_att - theo_std_att) / theo_std_att\n",
    "chk_att.check(\n",
    "    std_rel_err_att < 0.15,\n",
    "    \"Attritional std within 15% of theoretical\",\n",
    "    f\"Empirical={fmt_dollar(emp_std_att)}, Theoretical={fmt_dollar(theo_std_att)}, RelErr={std_rel_err_att:.4f}\"\n",
    ")\n",
    "\n",
    "# --- KS test against theoretical lognormal ---\n",
    "# Compute lognormal mu/sigma from mean and cv\n",
    "sigma_att = np.sqrt(np.log(1 + ATTRITIONAL_CV**2))\n",
    "mu_att = np.log(ATTRITIONAL_MEAN) - sigma_att**2 / 2\n",
    "\n",
    "ks_stat_att, ks_p_att = sp_stats.kstest(\n",
    "    attritional_amounts,\n",
    "    lambda x: sp_stats.lognorm.cdf(x, s=sigma_att, scale=np.exp(mu_att))\n",
    ")\n",
    "chk_att.check(\n",
    "    ks_p_att > 0.01,\n",
    "    \"KS test: attritional ~ Lognormal (p > 0.01)\",\n",
    "    f\"KS stat={ks_stat_att:.4f}, p-value={ks_p_att:.4f}\"\n",
    ")\n",
    "\n",
    "# --- Summary table ---\n",
    "att_summary = pd.DataFrame({\n",
    "    \"Parameter\": [\"Mean\", \"Std Dev\", \"Count\", \"KS p-value\"],\n",
    "    \"Expected\": [f\"${theo_mean_att:,.0f}\", f\"${theo_std_att:,.0f}\",\n",
    "                 f\"~{ATTRITIONAL_FREQ * N_YEARS:,.0f}\", \"> 0.01\"],\n",
    "    \"Observed\": [f\"${emp_mean_att:,.0f}\", f\"${emp_std_att:,.0f}\",\n",
    "                 f\"{n_att:,}\", f\"{ks_p_att:.4f}\"],\n",
    "    \"Status\": [\n",
    "        \"PASS\" if mean_rel_err_att < 0.10 else \"FAIL\",\n",
    "        \"PASS\" if std_rel_err_att < 0.15 else \"FAIL\",\n",
    "        \"PASS\" if abs(n_att - ATTRITIONAL_FREQ * N_YEARS) / (ATTRITIONAL_FREQ * N_YEARS) < 0.10 else \"FAIL\",\n",
    "        \"PASS\" if ks_p_att > 0.01 else \"FAIL\",\n",
    "    ]\n",
    "})\n",
    "display_df(att_summary, \"Attritional Loss Calibration\")\n",
    "\n",
    "# --- CDF plot ---\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "sorted_att = np.sort(attritional_amounts)\n",
    "ecdf_att = np.arange(1, len(sorted_att) + 1) / len(sorted_att)\n",
    "ax.plot(sorted_att, ecdf_att, label=\"Empirical CDF\", linewidth=1.5)\n",
    "\n",
    "x_theo = np.linspace(sorted_att.min(), np.percentile(sorted_att, 99.5), 500)\n",
    "theo_cdf_att = sp_stats.lognorm.cdf(x_theo, s=sigma_att, scale=np.exp(mu_att))\n",
    "ax.plot(x_theo, theo_cdf_att, '--', label=\"Theoretical Lognormal CDF\", linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel(\"Loss Amount ($)\")\n",
    "ax.set_ylabel(\"Cumulative Probability\")\n",
    "ax.set_title(\"Attritional Losses: Empirical vs Theoretical CDF\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "chk_att.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Large Losses\n",
    "\n",
    "Large losses use a **Lognormal** severity distribution with\n",
    "mean=$2,000,000 and CV=2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_header(\"Large Losses\")\n",
    "chk_large = ReconciliationChecker(\"Large Loss Severity\")\n",
    "\n",
    "# --- Empirical statistics ---\n",
    "emp_mean_lg = np.mean(large_amounts)\n",
    "emp_std_lg = np.std(large_amounts, ddof=1)\n",
    "n_lg = len(large_amounts)\n",
    "\n",
    "theo_mean_lg = LARGE_MEAN\n",
    "theo_std_lg = lognormal_std(LARGE_MEAN, LARGE_CV)\n",
    "\n",
    "# Large losses have high CV so allow 20% tolerance for mean\n",
    "mean_rel_err_lg = abs(emp_mean_lg - theo_mean_lg) / theo_mean_lg\n",
    "chk_large.check(\n",
    "    mean_rel_err_lg < 0.20,\n",
    "    \"Large loss mean within 20% of theoretical\",\n",
    "    f\"Empirical={fmt_dollar(emp_mean_lg)}, Theoretical={fmt_dollar(theo_mean_lg)}, RelErr={mean_rel_err_lg:.4f}\"\n",
    ")\n",
    "\n",
    "# Std within 30% (very high CV makes std estimation noisy)\n",
    "std_rel_err_lg = abs(emp_std_lg - theo_std_lg) / theo_std_lg\n",
    "chk_large.check(\n",
    "    std_rel_err_lg < 0.30,\n",
    "    \"Large loss std within 30% of theoretical\",\n",
    "    f\"Empirical={fmt_dollar(emp_std_lg)}, Theoretical={fmt_dollar(theo_std_lg)}, RelErr={std_rel_err_lg:.4f}\"\n",
    ")\n",
    "\n",
    "# --- KS test ---\n",
    "sigma_lg = np.sqrt(np.log(1 + LARGE_CV**2))\n",
    "mu_lg = np.log(LARGE_MEAN) - sigma_lg**2 / 2\n",
    "\n",
    "ks_stat_lg, ks_p_lg = sp_stats.kstest(\n",
    "    large_amounts,\n",
    "    lambda x: sp_stats.lognorm.cdf(x, s=sigma_lg, scale=np.exp(mu_lg))\n",
    ")\n",
    "chk_large.check(\n",
    "    ks_p_lg > 0.01,\n",
    "    \"KS test: large ~ Lognormal (p > 0.01)\",\n",
    "    f\"KS stat={ks_stat_lg:.4f}, p-value={ks_p_lg:.4f}\"\n",
    ")\n",
    "\n",
    "# --- Summary table ---\n",
    "lg_summary = pd.DataFrame({\n",
    "    \"Parameter\": [\"Mean\", \"Std Dev\", \"Count\", \"KS p-value\"],\n",
    "    \"Expected\": [f\"${theo_mean_lg:,.0f}\", f\"${theo_std_lg:,.0f}\",\n",
    "                 f\"~{LARGE_FREQ * N_YEARS:,.0f}\", \"> 0.01\"],\n",
    "    \"Observed\": [f\"${emp_mean_lg:,.0f}\", f\"${emp_std_lg:,.0f}\",\n",
    "                 f\"{n_lg:,}\", f\"{ks_p_lg:.4f}\"],\n",
    "    \"Status\": [\n",
    "        \"PASS\" if mean_rel_err_lg < 0.20 else \"FAIL\",\n",
    "        \"PASS\" if std_rel_err_lg < 0.30 else \"FAIL\",\n",
    "        \"PASS\" if abs(n_lg - LARGE_FREQ * N_YEARS) / (LARGE_FREQ * N_YEARS) < 0.15 else \"FAIL\",\n",
    "        \"PASS\" if ks_p_lg > 0.01 else \"FAIL\",\n",
    "    ]\n",
    "})\n",
    "display_df(lg_summary, \"Large Loss Calibration\")\n",
    "\n",
    "# --- CDF plot ---\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "sorted_lg = np.sort(large_amounts)\n",
    "ecdf_lg = np.arange(1, len(sorted_lg) + 1) / len(sorted_lg)\n",
    "ax.plot(sorted_lg, ecdf_lg, label=\"Empirical CDF\", linewidth=1.5)\n",
    "\n",
    "x_theo_lg = np.linspace(sorted_lg.min(), np.percentile(sorted_lg, 99.5), 500)\n",
    "theo_cdf_lg = sp_stats.lognorm.cdf(x_theo_lg, s=sigma_lg, scale=np.exp(mu_lg))\n",
    "ax.plot(x_theo_lg, theo_cdf_lg, '--', label=\"Theoretical Lognormal CDF\", linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel(\"Loss Amount ($)\")\n",
    "ax.set_ylabel(\"Cumulative Probability\")\n",
    "ax.set_title(\"Large Losses: Empirical vs Theoretical CDF\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "chk_large.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Catastrophic Losses\n",
    "\n",
    "Catastrophic losses use a **Pareto** severity distribution with\n",
    "alpha=2.5 and xm=$1,000,000. The theoretical mean is\n",
    "alpha * xm / (alpha - 1) = $1,666,667. All sampled values must\n",
    "be >= xm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_header(\"Catastrophic Losses\")\n",
    "chk_cat = ReconciliationChecker(\"Catastrophic Severity\")\n",
    "\n",
    "# --- Basic sanity: all values >= xm ---\n",
    "chk_cat.check(\n",
    "    len(cat_amounts) > 0,\n",
    "    \"At least one catastrophic event generated\",\n",
    "    f\"Count={len(cat_amounts)}\"\n",
    ")\n",
    "\n",
    "if len(cat_amounts) > 0:\n",
    "    chk_cat.check(\n",
    "        np.all(cat_amounts >= CAT_XM),\n",
    "        f\"All catastrophic losses >= xm (${CAT_XM:,.0f})\",\n",
    "        f\"Min observed={fmt_dollar(np.min(cat_amounts))}\"\n",
    "    )\n",
    "\n",
    "    # --- Empirical statistics ---\n",
    "    emp_mean_cat = np.mean(cat_amounts)\n",
    "    emp_std_cat = np.std(cat_amounts, ddof=1)\n",
    "    n_cat = len(cat_amounts)\n",
    "\n",
    "    theo_mean_cat = CAT_THEORETICAL_MEAN\n",
    "    theo_std_cat = CAT_THEORETICAL_STD\n",
    "\n",
    "    # Pareto is heavy-tailed, so allow wider tolerance (30% for mean)\n",
    "    mean_rel_err_cat = abs(emp_mean_cat - theo_mean_cat) / theo_mean_cat\n",
    "    chk_cat.check(\n",
    "        mean_rel_err_cat < 0.30,\n",
    "        \"Catastrophic mean within 30% of theoretical\",\n",
    "        f\"Empirical={fmt_dollar(emp_mean_cat)}, Theoretical={fmt_dollar(theo_mean_cat)}, RelErr={mean_rel_err_cat:.4f}\"\n",
    "    )\n",
    "\n",
    "    # --- KS test against Pareto ---\n",
    "    # Pareto CDF: F(x) = 1 - (xm/x)^alpha for x >= xm\n",
    "    def pareto_cdf(x):\n",
    "        x = np.atleast_1d(np.asarray(x, dtype=float))\n",
    "        result = np.zeros_like(x)\n",
    "        mask = x >= CAT_XM\n",
    "        result[mask] = 1.0 - (CAT_XM / x[mask]) ** CAT_ALPHA\n",
    "        return result if len(x) > 1 else float(result[0])\n",
    "\n",
    "    ks_stat_cat, ks_p_cat = sp_stats.kstest(cat_amounts, pareto_cdf)\n",
    "    chk_cat.check(\n",
    "        ks_p_cat > 0.01,\n",
    "        \"KS test: catastrophic ~ Pareto (p > 0.01)\",\n",
    "        f\"KS stat={ks_stat_cat:.4f}, p-value={ks_p_cat:.4f}\"\n",
    "    )\n",
    "\n",
    "    # --- Summary table ---\n",
    "    cat_summary = pd.DataFrame({\n",
    "        \"Parameter\": [\"Mean\", \"Std Dev\", \"Min >= xm\", \"Count\", \"KS p-value\"],\n",
    "        \"Expected\": [\n",
    "            f\"${theo_mean_cat:,.0f}\", f\"${theo_std_cat:,.0f}\",\n",
    "            \"Yes\", f\"~{CAT_FREQ * N_YEARS:,.0f}\", \"> 0.01\"\n",
    "        ],\n",
    "        \"Observed\": [\n",
    "            f\"${emp_mean_cat:,.0f}\", f\"${emp_std_cat:,.0f}\",\n",
    "            \"Yes\" if np.all(cat_amounts >= CAT_XM) else \"No\",\n",
    "            f\"{n_cat:,}\", f\"{ks_p_cat:.4f}\"\n",
    "        ],\n",
    "        \"Status\": [\n",
    "            \"PASS\" if mean_rel_err_cat < 0.30 else \"FAIL\",\n",
    "            \"--\",\n",
    "            \"PASS\" if np.all(cat_amounts >= CAT_XM) else \"FAIL\",\n",
    "            \"PASS\" if abs(n_cat - CAT_FREQ * N_YEARS) / max(CAT_FREQ * N_YEARS, 1) < 0.40 else \"FAIL\",\n",
    "            \"PASS\" if ks_p_cat > 0.01 else \"FAIL\",\n",
    "        ]\n",
    "    })\n",
    "    display_df(cat_summary, \"Catastrophic Loss Calibration\")\n",
    "\n",
    "    # --- CDF plot ---\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    sorted_cat = np.sort(cat_amounts)\n",
    "    ecdf_cat = np.arange(1, len(sorted_cat) + 1) / len(sorted_cat)\n",
    "    ax.plot(sorted_cat, ecdf_cat, label=\"Empirical CDF\", linewidth=1.5)\n",
    "\n",
    "    x_theo_cat = np.linspace(CAT_XM, np.percentile(sorted_cat, 99.5), 500)\n",
    "    theo_cdf_cat = 1.0 - (CAT_XM / x_theo_cat) ** CAT_ALPHA\n",
    "    ax.plot(x_theo_cat, theo_cdf_cat, '--', label=\"Theoretical Pareto CDF\", linewidth=1.5)\n",
    "\n",
    "    ax.set_xlabel(\"Loss Amount ($)\")\n",
    "    ax.set_ylabel(\"Cumulative Probability\")\n",
    "    ax.set_title(\"Catastrophic Losses: Empirical vs Theoretical CDF\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No catastrophic events generated (expected ~60 over 2000 years).\")\n",
    "    print(\"This is extremely unlikely and indicates a problem.\")\n",
    "\n",
    "chk_cat.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Frequency Validation\n",
    "\n",
    "Each loss type is generated via a Poisson process. We verify that the\n",
    "empirical per-year event counts match the expected Poisson rate by\n",
    "running a chi-square goodness-of-fit test on the observed yearly\n",
    "frequency distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_header(\"Frequency Validation\")\n",
    "chk_freq = ReconciliationChecker(\"Poisson Frequency\")\n",
    "\n",
    "def count_per_year(losses, n_years):\n",
    "    \"\"\"Bin loss events into integer year buckets and count per year.\"\"\"\n",
    "    counts = np.zeros(n_years, dtype=int)\n",
    "    for e in losses:\n",
    "        yr = int(e.time)\n",
    "        if 0 <= yr < n_years:\n",
    "            counts[yr] += 1\n",
    "    return counts\n",
    "\n",
    "def poisson_gof_test(observed_counts, expected_lambda, label):\n",
    "    \"\"\"Chi-square goodness-of-fit test against Poisson(lambda).\n",
    "    \n",
    "    Groups counts into bins to ensure adequate expected frequencies (>= 5).\n",
    "    Returns (chi2_stat, p_value, passed).\n",
    "    \"\"\"\n",
    "    max_k = max(int(expected_lambda + 4 * np.sqrt(expected_lambda)), int(np.max(observed_counts)) + 1)\n",
    "    max_k = min(max_k, 50)  # Cap for efficiency\n",
    "    \n",
    "    # Bin observed counts\n",
    "    bins = list(range(max_k + 1)) + [max_k + 100]  # last bin is overflow\n",
    "    observed_hist, _ = np.histogram(observed_counts, bins=bins)\n",
    "    \n",
    "    # Expected counts from Poisson\n",
    "    n_total = len(observed_counts)\n",
    "    expected_probs = [sp_stats.poisson.pmf(k, expected_lambda) for k in range(max_k)]\n",
    "    expected_probs.append(1.0 - sp_stats.poisson.cdf(max_k - 1, expected_lambda))  # overflow\n",
    "    expected_hist = np.array(expected_probs) * n_total\n",
    "    \n",
    "    # Merge bins with expected < 5\n",
    "    merged_obs = []\n",
    "    merged_exp = []\n",
    "    acc_obs = 0\n",
    "    acc_exp = 0.0\n",
    "    for o, e in zip(observed_hist, expected_hist):\n",
    "        acc_obs += o\n",
    "        acc_exp += e\n",
    "        if acc_exp >= 5.0:\n",
    "            merged_obs.append(acc_obs)\n",
    "            merged_exp.append(acc_exp)\n",
    "            acc_obs = 0\n",
    "            acc_exp = 0.0\n",
    "    # Fold remainder into last bin\n",
    "    if acc_obs > 0 or acc_exp > 0:\n",
    "        if merged_obs:\n",
    "            merged_obs[-1] += acc_obs\n",
    "            merged_exp[-1] += acc_exp\n",
    "        else:\n",
    "            merged_obs.append(acc_obs)\n",
    "            merged_exp.append(acc_exp)\n",
    "    \n",
    "    merged_obs = np.array(merged_obs, dtype=float)\n",
    "    merged_exp = np.array(merged_exp, dtype=float)\n",
    "    \n",
    "    if len(merged_obs) < 2:\n",
    "        return 0.0, 1.0, True  # Not enough bins to test\n",
    "    \n",
    "    chi2, p_value = sp_stats.chisquare(merged_obs, merged_exp)\n",
    "    return chi2, p_value, p_value > 0.01\n",
    "\n",
    "# --- Attritional frequency ---\n",
    "att_counts = count_per_year(attritional_losses, N_YEARS)\n",
    "att_obs_lambda = np.mean(att_counts)\n",
    "chi2_att, p_att, pass_att = poisson_gof_test(att_counts, ATTRITIONAL_FREQ, \"Attritional\")\n",
    "\n",
    "chk_freq.check(\n",
    "    abs(att_obs_lambda - ATTRITIONAL_FREQ) / ATTRITIONAL_FREQ < 0.05,\n",
    "    f\"Attritional avg frequency ~ {ATTRITIONAL_FREQ:.1f}/yr\",\n",
    "    f\"Observed={att_obs_lambda:.3f}/yr, Expected={ATTRITIONAL_FREQ:.1f}/yr\"\n",
    ")\n",
    "chk_freq.check(\n",
    "    pass_att,\n",
    "    \"Attritional frequency ~ Poisson (chi-square p > 0.01)\",\n",
    "    f\"chi2={chi2_att:.2f}, p={p_att:.4f}\"\n",
    ")\n",
    "\n",
    "# --- Large frequency ---\n",
    "lg_counts = count_per_year(large_losses, N_YEARS)\n",
    "lg_obs_lambda = np.mean(lg_counts)\n",
    "chi2_lg, p_lg, pass_lg = poisson_gof_test(lg_counts, LARGE_FREQ, \"Large\")\n",
    "\n",
    "chk_freq.check(\n",
    "    abs(lg_obs_lambda - LARGE_FREQ) / LARGE_FREQ < 0.10,\n",
    "    f\"Large avg frequency ~ {LARGE_FREQ:.1f}/yr\",\n",
    "    f\"Observed={lg_obs_lambda:.3f}/yr, Expected={LARGE_FREQ:.1f}/yr\"\n",
    ")\n",
    "chk_freq.check(\n",
    "    pass_lg,\n",
    "    \"Large frequency ~ Poisson (chi-square p > 0.01)\",\n",
    "    f\"chi2={chi2_lg:.2f}, p={p_lg:.4f}\"\n",
    ")\n",
    "\n",
    "# --- Catastrophic frequency ---\n",
    "cat_counts = count_per_year(cat_losses, N_YEARS)\n",
    "cat_obs_lambda = np.mean(cat_counts)\n",
    "# For very low-frequency events, use a simple mean comparison\n",
    "chk_freq.check(\n",
    "    abs(cat_obs_lambda - CAT_FREQ) / CAT_FREQ < 0.40,\n",
    "    f\"Catastrophic avg frequency ~ {CAT_FREQ:.2f}/yr\",\n",
    "    f\"Observed={cat_obs_lambda:.4f}/yr, Expected={CAT_FREQ:.2f}/yr (40% tol for rare events)\"\n",
    ")\n",
    "\n",
    "# Display frequency summary\n",
    "freq_summary = pd.DataFrame({\n",
    "    \"Loss Type\": [\"Attritional\", \"Large\", \"Catastrophic\"],\n",
    "    \"Expected Freq (/yr)\": [ATTRITIONAL_FREQ, LARGE_FREQ, CAT_FREQ],\n",
    "    \"Observed Freq (/yr)\": [att_obs_lambda, lg_obs_lambda, cat_obs_lambda],\n",
    "    \"Total Events\": [len(attritional_losses), len(large_losses), len(cat_losses)],\n",
    "    \"Chi-sq p-value\": [f\"{p_att:.4f}\", f\"{p_lg:.4f}\", \"N/A (rare)\"],\n",
    "})\n",
    "display_df(freq_summary, \"Frequency Calibration Summary\")\n",
    "\n",
    "chk_freq.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aggregate Check\n",
    "\n",
    "The combined annual expected loss should approximately equal the sum of\n",
    "component expected losses:\n",
    "\n",
    "$$E[L_{total}] = \\lambda_{att} \\cdot E[S_{att}] + \\lambda_{lg} \\cdot E[S_{lg}] + \\lambda_{cat} \\cdot E[S_{cat}]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_header(\"Aggregate Check\")\n",
    "chk_agg = ReconciliationChecker(\"Annual Aggregate\")\n",
    "\n",
    "# Theoretical annual expected loss per component\n",
    "theo_annual_att = ATTRITIONAL_FREQ * ATTRITIONAL_MEAN\n",
    "theo_annual_lg = LARGE_FREQ * LARGE_MEAN\n",
    "theo_annual_cat = CAT_FREQ * CAT_THEORETICAL_MEAN\n",
    "theo_annual_total = theo_annual_att + theo_annual_lg + theo_annual_cat\n",
    "\n",
    "# Empirical annual loss\n",
    "emp_total = sim_stats[\"total_amount\"]\n",
    "emp_annual = emp_total / N_YEARS\n",
    "\n",
    "# Component annual losses\n",
    "emp_annual_att = sim_stats[\"attritional_amount\"] / N_YEARS\n",
    "emp_annual_lg = sim_stats[\"large_amount\"] / N_YEARS\n",
    "emp_annual_cat = sim_stats[\"catastrophic_amount\"] / N_YEARS\n",
    "\n",
    "# Check aggregate mean within 15%\n",
    "agg_rel_err = abs(emp_annual - theo_annual_total) / theo_annual_total\n",
    "chk_agg.check(\n",
    "    agg_rel_err < 0.15,\n",
    "    \"Aggregate annual loss within 15% of theoretical\",\n",
    "    f\"Empirical={fmt_dollar(emp_annual)}/yr, Theoretical={fmt_dollar(theo_annual_total)}/yr, RelErr={agg_rel_err:.4f}\"\n",
    ")\n",
    "\n",
    "# Check attritional component\n",
    "att_agg_err = abs(emp_annual_att - theo_annual_att) / theo_annual_att\n",
    "chk_agg.check(\n",
    "    att_agg_err < 0.10,\n",
    "    \"Attritional annual loss within 10% of theoretical\",\n",
    "    f\"Empirical={fmt_dollar(emp_annual_att)}/yr, Theoretical={fmt_dollar(theo_annual_att)}/yr\"\n",
    ")\n",
    "\n",
    "# Check large component\n",
    "lg_agg_err = abs(emp_annual_lg - theo_annual_lg) / theo_annual_lg\n",
    "chk_agg.check(\n",
    "    lg_agg_err < 0.20,\n",
    "    \"Large annual loss within 20% of theoretical\",\n",
    "    f\"Empirical={fmt_dollar(emp_annual_lg)}/yr, Theoretical={fmt_dollar(theo_annual_lg)}/yr\"\n",
    ")\n",
    "\n",
    "# Check that total == sum of components (exact, from simulation stats)\n",
    "component_sum = sim_stats[\"attritional_amount\"] + sim_stats[\"large_amount\"] + sim_stats[\"catastrophic_amount\"]\n",
    "chk_agg.check(\n",
    "    abs(emp_total - component_sum) < 0.01,\n",
    "    \"Total loss == sum of component losses (exact)\",\n",
    "    f\"Total={fmt_dollar(emp_total)}, Sum={fmt_dollar(component_sum)}\"\n",
    ")\n",
    "\n",
    "# Display aggregate summary\n",
    "agg_summary = pd.DataFrame({\n",
    "    \"Component\": [\"Attritional\", \"Large\", \"Catastrophic\", \"TOTAL\"],\n",
    "    \"Theoretical Annual\": [\n",
    "        fmt_dollar(theo_annual_att), fmt_dollar(theo_annual_lg),\n",
    "        fmt_dollar(theo_annual_cat), fmt_dollar(theo_annual_total)\n",
    "    ],\n",
    "    \"Empirical Annual\": [\n",
    "        fmt_dollar(emp_annual_att), fmt_dollar(emp_annual_lg),\n",
    "        fmt_dollar(emp_annual_cat), fmt_dollar(emp_annual)\n",
    "    ],\n",
    "    \"Relative Error\": [\n",
    "        f\"{att_agg_err:.2%}\", f\"{lg_agg_err:.2%}\",\n",
    "        f\"{abs(emp_annual_cat - theo_annual_cat) / max(theo_annual_cat, 1):.2%}\",\n",
    "        f\"{agg_rel_err:.2%}\"\n",
    "    ],\n",
    "})\n",
    "display_df(agg_summary, \"Annual Aggregate Loss Summary\")\n",
    "\n",
    "chk_agg.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary(chk_att, chk_large, chk_cat, chk_freq, chk_agg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
