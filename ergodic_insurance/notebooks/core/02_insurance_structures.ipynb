{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance Structures and Visualization\n",
    "\n",
    "## Overview\n",
    "- **What this notebook does:** Demonstrates multi-layer insurance program design, layer optimization, premium sensitivity analysis, and technical visualizations of insurance structures (correlation, premium decomposition, capital efficiency).\n",
    "- **Prerequisites:** [core/01_loss_distributions.ipynb](01_loss_distributions.ipynb)\n",
    "- **Estimated runtime:** 1--3 minutes\n",
    "- **Audience:** [Practitioner]\n",
    "\n",
    "## Why Multi-Layer Structures?\n",
    "Real-world insurance programs are built from multiple layers, each with its own attachment point, limit, and premium rate. This notebook shows how to design, analyze, and optimize these structures, and includes technical visualizations of correlation structure, premium loading decomposition, and capital efficiency frontiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ergodic_insurance import InsuranceProgram, EnhancedInsuranceLayer\n",
    "from ergodic_insurance.loss_distributions import ManufacturingLossGenerator\n",
    "from ergodic_insurance.visualization import WSJ_COLORS, format_currency\n",
    "from ergodic_insurance.visualization.technical_plots import (\n",
    "    plot_correlation_structure,\n",
    "    plot_premium_decomposition,\n",
    "    plot_capital_efficiency_frontier_3d,\n",
    ")\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVENUE = 10_000_000\n",
    "N_SIMULATIONS = 1_000\n",
    "\n",
    "LOSS_GENERATOR = ManufacturingLossGenerator(\n",
    "    attritional_params={'base_frequency': 5.0, 'severity_mean': 50_000, 'severity_cv': 0.8},\n",
    "    large_params={'base_frequency': 0.5, 'severity_mean': 2_000_000, 'severity_cv': 1.2},\n",
    "    catastrophic_params={'base_frequency': 0.02, 'severity_xm': 10_000_000, 'severity_alpha': 2.5},\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Default three-layer insurance program\n",
    "DEFAULT_LAYERS = [\n",
    "    EnhancedInsuranceLayer(0, 5_000_000, 0.015),\n",
    "    EnhancedInsuranceLayer(5_000_000, 20_000_000, 0.008),\n",
    "    EnhancedInsuranceLayer(25_000_000, 25_000_000, 0.004),\n",
    "]\n",
    "\n",
    "print(\"Insurance structures notebook configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Layer Structure Analysis\n",
    "\n",
    "Analyze how a three-layer program distributes recoveries across layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = InsuranceProgram(DEFAULT_LAYERS)\n",
    "results = []\n",
    "layer_utilization = {i: [] for i in range(3)}\n",
    "\n",
    "for _ in range(N_SIMULATIONS):\n",
    "    events, _ = LOSS_GENERATOR.generate_losses(duration=1.0, revenue=REVENUE)\n",
    "    total_loss = sum(e.amount for e in events)\n",
    "    total_recovery = 0\n",
    "    layer_recoveries = [0, 0, 0]\n",
    "\n",
    "    for event in events:\n",
    "        details = program.process_claim(event.amount)\n",
    "        total_recovery += details['insurance_recovery']\n",
    "        for layer_info in details['layers_triggered']:\n",
    "            layer_recoveries[layer_info['layer_index']] += layer_info['payment']\n",
    "\n",
    "    results.append({'total_loss': total_loss, 'total_recovery': total_recovery,\n",
    "                    'retained': total_loss - total_recovery})\n",
    "    for i in range(3):\n",
    "        layer_utilization[i].append(layer_recoveries[i])\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "\n",
    "total_premium = program.calculate_annual_premium()\n",
    "print(f\"Insurance Program Summary\")\n",
    "print(f\"={'=' * 60}\")\n",
    "print(f\"Total Annual Premium: ${total_premium:,.0f}\")\n",
    "print(f\"Average Annual Recovery: ${res_df['total_recovery'].mean():,.0f}\")\n",
    "print(f\"Average Annual Retention: ${res_df['retained'].mean():,.0f}\")\n",
    "print(f\"Loss Ratio: {100 * res_df['total_recovery'].mean() / total_premium:.1f}%\")\n",
    "\n",
    "print(f\"\\nLayer Utilization:\")\n",
    "for i in range(3):\n",
    "    util = layer_utilization[i]\n",
    "    print(f\"  Layer {i+1}: Avg recovery ${np.mean(util):,.0f}, \"\n",
    "          f\"Triggered {100 * (np.array(util) > 0).mean():.1f}% of years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Layer Configuration Optimization\n",
    "\n",
    "Compare conservative, balanced, aggressive, and data-driven configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate loss scenarios for optimization\n",
    "annual_losses = []\n",
    "for _ in range(N_SIMULATIONS):\n",
    "    events, stats = LOSS_GENERATOR.generate_losses(duration=1.0, revenue=REVENUE)\n",
    "    annual_losses.append(stats['total_amount'])\n",
    "annual_losses = np.array(annual_losses)\n",
    "\n",
    "p90 = np.percentile(annual_losses, 90)\n",
    "p99 = np.percentile(annual_losses, 99)\n",
    "p995 = np.percentile(annual_losses, 99.5)\n",
    "\n",
    "configurations = [\n",
    "    {'name': 'Conservative', 'attachments': [0, 1_000_000, 5_000_000],\n",
    "     'limits': [1_000_000, 4_000_000, 20_000_000], 'rates': [0.025, 0.015, 0.008]},\n",
    "    {'name': 'Balanced', 'attachments': [0, 5_000_000, 25_000_000],\n",
    "     'limits': [5_000_000, 20_000_000, 25_000_000], 'rates': [0.015, 0.008, 0.004]},\n",
    "    {'name': 'Aggressive', 'attachments': [1_000_000, 10_000_000, 50_000_000],\n",
    "     'limits': [9_000_000, 40_000_000, 50_000_000], 'rates': [0.012, 0.006, 0.002]},\n",
    "    {'name': 'Data-Driven', 'attachments': [0, p90, p99],\n",
    "     'limits': [p90, p99 - p90, p995 - p99], 'rates': [0.018, 0.009, 0.003]},\n",
    "]\n",
    "\n",
    "opt_results = []\n",
    "for config in configurations:\n",
    "    layers = [EnhancedInsuranceLayer(config['attachments'][i], config['limits'][i], config['rates'][i])\n",
    "              for i in range(3)]\n",
    "    prog = InsuranceProgram(layers)\n",
    "    premium = prog.calculate_annual_premium()\n",
    "    recoveries = []\n",
    "    for loss in annual_losses:\n",
    "        details = prog.process_claim(loss)\n",
    "        recoveries.append(details['insurance_recovery'])\n",
    "\n",
    "    opt_results.append({\n",
    "        'Configuration': config['name'], 'Premium': premium,\n",
    "        'Avg Recovery': np.mean(recoveries),\n",
    "        'Avg Retention': np.mean(annual_losses) - np.mean(recoveries),\n",
    "        'Loss Ratio': np.mean(recoveries) / premium if premium > 0 else 0,\n",
    "        'Efficiency': np.mean(recoveries) / np.mean(annual_losses),\n",
    "    })\n",
    "\n",
    "opt_df = pd.DataFrame(opt_results)\n",
    "print(\"Layer Configuration Comparison:\")\n",
    "print(opt_df.to_string(index=False))\n",
    "print(f\"\\nBest efficiency: {opt_df.loc[opt_df['Efficiency'].idxmax(), 'Configuration']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Premium Sensitivity Analysis\n",
    "\n",
    "How sensitive are net benefits to changes in premium rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rates = [0.015, 0.008, 0.004]\n",
    "base_attachments = [0, 5_000_000, 25_000_000]\n",
    "base_limits = [5_000_000, 20_000_000, 25_000_000]\n",
    "\n",
    "multipliers = np.linspace(0.5, 2.0, 16)\n",
    "sens_results = []\n",
    "\n",
    "for mult in multipliers:\n",
    "    adjusted_rates = [r * mult for r in base_rates]\n",
    "    layers = [EnhancedInsuranceLayer(base_attachments[i], base_limits[i], adjusted_rates[i])\n",
    "              for i in range(3)]\n",
    "    prog = InsuranceProgram(layers)\n",
    "    premium = prog.calculate_annual_premium()\n",
    "    recoveries = [prog.process_claim(loss)['insurance_recovery'] for loss in annual_losses]\n",
    "    sens_results.append({\n",
    "        'multiplier': mult, 'premium': premium,\n",
    "        'avg_recovery': np.mean(recoveries),\n",
    "        'loss_ratio': np.mean(recoveries) / premium if premium > 0 else 0,\n",
    "        'net_benefit': np.mean(recoveries) - premium,\n",
    "    })\n",
    "\n",
    "sens_df = pd.DataFrame(sens_results)\n",
    "optimal_mult = sens_df.loc[sens_df['net_benefit'].idxmax(), 'multiplier']\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Premium vs Recovery', 'Net Benefit'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=sens_df['multiplier'], y=sens_df['premium'], mode='lines',\n",
    "                         name='Premium', line=dict(color=WSJ_COLORS['blue'], width=2)), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=sens_df['multiplier'], y=sens_df['avg_recovery'], mode='lines',\n",
    "                         name='Avg Recovery', line=dict(color=WSJ_COLORS['orange'], width=2, dash='dash')),\n",
    "              row=1, col=1)\n",
    "\n",
    "colors = ['green' if x > 0 else 'red' for x in sens_df['net_benefit']]\n",
    "fig.add_trace(go.Bar(x=sens_df['multiplier'], y=sens_df['net_benefit'],\n",
    "                     marker_color=colors), row=1, col=2)\n",
    "\n",
    "fig.update_layout(height=400, title_text='Premium Rate Sensitivity Analysis')\n",
    "fig.update_xaxes(title_text='Rate Multiplier')\n",
    "fig.update_yaxes(title_text='Amount', tickformat='$.2s', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Net Benefit', tickformat='$.2s', row=1, col=2)\n",
    "fig.show()\n",
    "\n",
    "print(f\"Optimal rate multiplier: {optimal_mult:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Risk Correlation Structure (Figure B2)\n",
    "\n",
    "Visualize correlations between operational and financial risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1_000\n",
    "operational_data = np.exp(np.random.multivariate_normal(\n",
    "    [0, 0, 0], [[1.0, 0.6, 0.3], [0.6, 1.0, 0.4], [0.3, 0.4, 1.0]], n_samples)) * 10_000\n",
    "financial_data = np.exp(np.random.multivariate_normal(\n",
    "    [0, 0, 0], [[1.0, 0.8, 0.5], [0.8, 1.0, 0.7], [0.5, 0.7, 1.0]], n_samples)) * 50_000\n",
    "\n",
    "risk_data = {\"Operational\": operational_data, \"Financial\": financial_data}\n",
    "\n",
    "fig = plot_correlation_structure(\n",
    "    risk_data, correlation_type=\"pearson\",\n",
    "    title=\"Risk Correlation Structure Analysis\", figsize=(16, 10), show_copula=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Premium Loading Decomposition (Figure C4)\n",
    "\n",
    "Break down premiums into expected loss, volatility load, tail load, expenses, and profit margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premium_components = {\n",
    "    \"Small Company\": {\n",
    "        \"Primary ($0-5M)\": {\n",
    "            \"expected_loss\": 250_000, \"volatility_load\": 75_000, \"tail_load\": 50_000,\n",
    "            \"expense_load\": 87_500, \"profit_margin\": 37_500,\n",
    "        },\n",
    "        \"Excess ($5-15M)\": {\n",
    "            \"expected_loss\": 100_000, \"volatility_load\": 40_000, \"tail_load\": 35_000,\n",
    "            \"expense_load\": 35_000, \"profit_margin\": 15_000,\n",
    "        },\n",
    "    },\n",
    "    \"Large Company\": {\n",
    "        \"Primary ($0-10M)\": {\n",
    "            \"expected_loss\": 800_000, \"volatility_load\": 120_000, \"tail_load\": 100_000,\n",
    "            \"expense_load\": 150_000, \"profit_margin\": 80_000,\n",
    "        },\n",
    "        \"Excess ($10-25M)\": {\n",
    "            \"expected_loss\": 300_000, \"volatility_load\": 75_000, \"tail_load\": 75_000,\n",
    "            \"expense_load\": 60_000, \"profit_margin\": 40_000,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "fig = plot_premium_decomposition(\n",
    "    premium_components,\n",
    "    title=\"Premium Loading Decomposition by Company Size and Layer\",\n",
    "    figsize=(14, 8), show_percentages=True,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"Expected loss typically represents 40-60% of premium.\")\n",
    "print(\"Volatility and tail loads increase for higher layers.\")\n",
    "print(\"Expense ratios decrease with company size (economies of scale).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Capital Efficiency Frontier (Figure C5)\n",
    "\n",
    "3D visualization showing the trade-off between ROE, ruin probability, and insurance spend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_efficiency_surface(n_ruin=25, n_spend=30, base_roe=0.12, spend_max=1.5e6):\n",
    "    ruin_probs = np.linspace(0.001, 0.15, n_ruin)\n",
    "    insurance_spends = np.linspace(0, spend_max, n_spend)\n",
    "    roe_surface = np.zeros((n_ruin, n_spend))\n",
    "    for i, ruin in enumerate(ruin_probs):\n",
    "        for j, spend in enumerate(insurance_spends):\n",
    "            roe = base_roe * (1 - ruin * 2) - (spend / 10e6) * 0.5\n",
    "            roe += min(spend / spend_max, 1) * 0.08 * (1 - ruin)\n",
    "            roe += np.random.normal(0, 0.005)\n",
    "            roe_surface[i, j] = max(roe, 0)\n",
    "    return {\"roe\": roe_surface, \"ruin_prob\": ruin_probs, \"insurance_spend\": insurance_spends}\n",
    "\n",
    "efficiency_data = {\"Small\": generate_efficiency_surface()}\n",
    "\n",
    "# Optimal path\n",
    "n_pts = 20\n",
    "optimal_paths = {\"Small\": np.column_stack([\n",
    "    np.linspace(0.10, 0.01, n_pts),\n",
    "    np.linspace(0.2e6, 1.0e6, n_pts),\n",
    "    np.linspace(0.08, 0.11, n_pts) + 0.02 * np.sin(np.pi * np.linspace(0, 1, n_pts)),\n",
    "])}\n",
    "\n",
    "fig = plot_capital_efficiency_frontier_3d(\n",
    "    efficiency_data, optimal_paths=optimal_paths,\n",
    "    title=\"Capital Efficiency Frontier: ROE vs Ruin vs Insurance Spend\",\n",
    "    figsize=(14, 10), view_angles=(25, 45),\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"The optimal path (red line) shows the trade-off between insurance cost and risk reduction.\")\n",
    "print(\"More insurance can actually improve ROE when risk-adjusted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Multi-layer programs provide more efficient risk transfer than single large layers.\n",
    "- Data-driven attachment points (aligned with loss distribution percentiles) outperform ad-hoc structures.\n",
    "- Premium sensitivity analysis reveals diminishing returns beyond certain rate levels.\n",
    "- Correlation analysis is critical for understanding aggregate risk exposures.\n",
    "- The capital efficiency frontier shows that insurance can enhance ROE when properly structured.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **See the ergodic advantage:** [core/03_ergodic_advantage.ipynb](03_ergodic_advantage.ipynb)\n",
    "- **Run large-scale Monte Carlo:** [core/04_monte_carlo_simulation.ipynb](04_monte_carlo_simulation.ipynb)\n",
    "- **Optimize insurance programs:** [optimization/01_retention_optimization.ipynb](../optimization/01_retention_optimization.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
