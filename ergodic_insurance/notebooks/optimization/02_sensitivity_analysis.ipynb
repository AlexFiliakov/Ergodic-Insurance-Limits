{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis for Insurance Optimization\n",
    "\n",
    "## Overview\n",
    "Systematic sensitivity analysis to understand how parameter changes affect optimal insurance decisions and business outcomes.  Covers one-at-a-time sweeps, tornado diagrams, two-way interaction heatmaps, and market-scenario stress testing.\n",
    "\n",
    "- **Prerequisites**: [optimization/01_optimization_overview](01_optimization_overview.ipynb)\n",
    "- **Estimated runtime**: 2-4 minutes\n",
    "- **Audience**: [Practitioner]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from ergodic_insurance.sensitivity import (\n",
    "    SensitivityAnalyzer,\n",
    "    SensitivityResult,\n",
    "    TwoWaySensitivityResult,\n",
    ")\n",
    "from ergodic_insurance.sensitivity_visualization import (\n",
    "    plot_tornado_diagram,\n",
    "    plot_two_way_sensitivity,\n",
    "    plot_parameter_sweep,\n",
    "    plot_sensitivity_matrix,\n",
    "    create_sensitivity_report,\n",
    ")\n",
    "from ergodic_insurance.manufacturer import WidgetManufacturer\n",
    "from ergodic_insurance.business_optimizer import (\n",
    "    BusinessOptimizer, BusinessConstraints, BusinessObjective,\n",
    ")\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Base Configuration\n",
    "\n",
    "The `SensitivityAnalyzer` takes a baseline configuration dictionary and an optimizer that maps any configuration to optimization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config = {\n",
    "    # Manufacturing parameters\n",
    "    \"initial_assets\": 10_000_000,\n",
    "    \"asset_turnover\": 1.0,\n",
    "    \"base_operating_margin\": 0.08,\n",
    "    \"tax_rate\": 0.25,\n",
    "    # Loss parameters\n",
    "    \"loss_frequency\": 5.0,\n",
    "    \"loss_severity_mean\": 100_000,\n",
    "    \"loss_severity_cv\": 1.5,\n",
    "    # Insurance parameters\n",
    "    \"base_premium_rate\": 0.02,\n",
    "    \"deductible\": 50_000,\n",
    "    \"coverage_limit\": 5_000_000,\n",
    "    # Constraints\n",
    "    \"max_ruin_probability\": 0.01,\n",
    "    \"min_roe_target\": 0.15,\n",
    "    \"max_premium_budget\": 0.03,\n",
    "}\n",
    "\n",
    "print(\"Base Configuration:\")\n",
    "for k, v in base_config.items():\n",
    "    if isinstance(v, float) and v < 1:\n",
    "        print(f\"  {k}: {v:.1%}\")\n",
    "    elif isinstance(v, (int, float)) and v > 1000:\n",
    "        print(f\"  {k}: ${v:,.0f}\")\n",
    "    else:\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightweight optimizer for demonstration (deterministic model)\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class _Strategy:\n",
    "    expected_roe: float\n",
    "    bankruptcy_risk: float\n",
    "    growth_rate: float\n",
    "    capital_efficiency: float\n",
    "    deductible: float\n",
    "    premium_rate: float\n",
    "\n",
    "class DemoOptimizer:\n",
    "    \"\"\"Simplified optimizer that returns deterministic results from config values.\"\"\"\n",
    "    def optimize(self, config):\n",
    "        freq = config.get(\"loss_frequency\", 5)\n",
    "        sev = config.get(\"loss_severity_mean\", 100_000)\n",
    "        prem = config.get(\"base_premium_rate\", 0.02)\n",
    "        ded = config.get(\"deductible\", 50_000)\n",
    "        margin = config.get(\"base_operating_margin\", 0.08)\n",
    "\n",
    "        base_roe = margin * 2\n",
    "        freq_impact = (5 - freq) * 0.01\n",
    "        sev_impact = (100_000 - sev) / 1_000_000\n",
    "        prem_impact = -prem * 2\n",
    "\n",
    "        class _Result:\n",
    "            optimal_strategy = _Strategy(\n",
    "                expected_roe=max(0.05, min(0.30, base_roe + freq_impact + sev_impact + prem_impact)),\n",
    "                bankruptcy_risk=max(0.001, min(0.05, freq * sev / 100_000_000)),\n",
    "                growth_rate=max(0.02, min(0.15, margin * 0.8)),\n",
    "                capital_efficiency=0.75 + margin,\n",
    "                deductible=ded,\n",
    "                premium_rate=prem,\n",
    "            )\n",
    "        return _Result()\n",
    "\n",
    "optimizer = DemoOptimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Sensitivity Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = Path(\"cache/sensitivity\")\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "analyzer = SensitivityAnalyzer(\n",
    "    base_config=base_config,\n",
    "    optimizer=optimizer,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Analyzer ready  |  {len(base_config)} parameters  |  cache: {cache_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. One-at-a-Time (OAT) Parameter Sweep\n",
    "\n",
    "Vary each parameter individually while holding others at baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_result = analyzer.analyze_parameter(\n",
    "    \"loss_frequency\", param_range=(3, 8), n_points=11,\n",
    ")\n",
    "\n",
    "print(f\"Loss Frequency sweep: {freq_result.variations[0]:.1f} - {freq_result.variations[-1]:.1f}\")\n",
    "for metric in [\"optimal_roe\", \"bankruptcy_risk\", \"growth_rate\"]:\n",
    "    impact = freq_result.calculate_impact(metric)\n",
    "    lo, hi = freq_result.get_metric_bounds(metric)\n",
    "    print(f\"  {metric:20s}  elasticity={impact:+.3f}  range=[{lo:.3f}, {hi:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_parameter_sweep(\n",
    "    freq_result,\n",
    "    metrics=[\"optimal_roe\", \"bankruptcy_risk\", \"growth_rate\"],\n",
    "    title=\"Impact of Loss Frequency on Key Metrics\",\n",
    "    figsize=(12, 4),\n",
    "    mark_baseline=True,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tornado Diagram -- Parameter Impact Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_parameters = [\n",
    "    \"loss_frequency\",\n",
    "    \"loss_severity_mean\",\n",
    "    \"loss_severity_cv\",\n",
    "    \"base_premium_rate\",\n",
    "    \"deductible\",\n",
    "    \"base_operating_margin\",\n",
    "    \"asset_turnover\",\n",
    "]\n",
    "\n",
    "tornado_data = analyzer.create_tornado_diagram(\n",
    "    parameters=key_parameters,\n",
    "    metric=\"optimal_roe\",\n",
    "    relative_range=0.3,\n",
    "    n_points=5,\n",
    ")\n",
    "\n",
    "print(\"Parameter Impact Ranking (by ROE impact range):\")\n",
    "for i, row in tornado_data.iterrows():\n",
    "    print(f\"  {i+1}. {row['parameter']:25s}  impact={row['impact']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_tornado_diagram(\n",
    "    tornado_data,\n",
    "    title=\"Sensitivity Tornado Diagram\",\n",
    "    metric_label=\"Impact on Expected ROE\",\n",
    "    figsize=(10, 6),\n",
    "    n_params=7,\n",
    "    show_values=True,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Two-Way Sensitivity (Interaction Heatmap)\n",
    "\n",
    "Explore how **loss frequency** and **loss severity** interact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_way = analyzer.analyze_two_way(\n",
    "    param1=\"loss_frequency\",\n",
    "    param2=\"loss_severity_mean\",\n",
    "    param1_range=(3, 8),\n",
    "    param2_range=(50_000, 200_000),\n",
    "    n_points1=8,\n",
    "    n_points2=8,\n",
    "    metric=\"optimal_roe\",\n",
    ")\n",
    "\n",
    "print(f\"ROE grid: {two_way.metric_grid.shape}  \"\n",
    "      f\"range=[{two_way.metric_grid.min():.3f}, {two_way.metric_grid.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_two_way_sensitivity(\n",
    "    two_way,\n",
    "    title=\"ROE Sensitivity: Loss Frequency vs Severity\",\n",
    "    cmap=\"RdYlGn\",\n",
    "    figsize=(10, 8),\n",
    "    show_contours=True,\n",
    "    contour_levels=10,\n",
    "    optimal_point=(5.0, 100_000),\n",
    "    fmt=\".2%\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feasibility region: where ROE > 15%\n",
    "TARGET_ROE = 0.15\n",
    "optimal_mask = two_way.find_optimal_region(TARGET_ROE, tolerance=0.1)\n",
    "n_feasible = optimal_mask.sum()\n",
    "n_total = optimal_mask.size\n",
    "\n",
    "print(f\"Target ROE: {TARGET_ROE:.0%}\")\n",
    "print(f\"Feasible cells: {n_feasible}/{n_total} ({100 * n_feasible / n_total:.0f}%)\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "X, Y = np.meshgrid(two_way.values1, two_way.values2, indexing=\"ij\")\n",
    "ax.contourf(X, Y, optimal_mask.astype(float), levels=[0, 0.5, 1],\n",
    "            colors=[\"#ffcccc\", \"#ccffcc\"], alpha=0.4)\n",
    "ax.contour(X, Y, two_way.metric_grid, levels=[TARGET_ROE],\n",
    "           colors=\"black\", linewidths=2)\n",
    "ax.set_xlabel(\"Loss Frequency (claims/year)\")\n",
    "ax.set_ylabel(\"Loss Severity Mean ($)\")\n",
    "ax.set_title(f\"Feasible Region for ROE > {TARGET_ROE:.0%}\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-Metric Cross-Parameter Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_compare = [\"optimal_roe\", \"bankruptcy_risk\", \"growth_rate\", \"capital_efficiency\"]\n",
    "params_to_compare = [\"loss_frequency\", \"loss_severity_mean\",\n",
    "                     \"base_premium_rate\", \"base_operating_margin\"]\n",
    "\n",
    "impact_df = pd.DataFrame(index=metrics_to_compare, columns=params_to_compare, dtype=float)\n",
    "\n",
    "for param in params_to_compare:\n",
    "    result = analyzer.analyze_parameter(param, relative_range=0.3, n_points=5)\n",
    "    for metric in metrics_to_compare:\n",
    "        impact_df.loc[metric, param] = abs(result.calculate_impact(metric))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.heatmap(impact_df.astype(float), annot=True, fmt=\".3f\", cmap=\"YlOrRd\",\n",
    "            cbar_kws={\"label\": \"Elasticity (absolute)\"})\n",
    "ax.set_title(\"Parameter Sensitivity Across Different Metrics\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Most sensitive parameter per metric:\")\n",
    "for metric in metrics_to_compare:\n",
    "    best = impact_df.loc[metric].astype(float).idxmax()\n",
    "    print(f\"  {metric:25s} -> {best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **Operating margin** and **loss frequency** are usually the most impactful parameters on ROE.\n",
    "- **Two-way analysis** reveals interaction effects that single-parameter sweeps miss (e.g., high frequency *and* high severity can push the company out of the feasible region).\n",
    "- The `SensitivityAnalyzer` caches results automatically, so repeated analyses are fast.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [optimization/03_pareto_analysis](03_pareto_analysis.ipynb) -- multi-objective trade-offs on a Pareto frontier\n",
    "- [optimization/05_parameter_sweeps](05_parameter_sweeps.ipynb) -- grid-search over larger parameter spaces\n",
    "- [optimization/04_retention_optimization](04_retention_optimization.ipynb) -- detailed deductible optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
