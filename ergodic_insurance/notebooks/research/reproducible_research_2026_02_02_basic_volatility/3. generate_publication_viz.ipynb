{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publication Visualizations: Ergodic Insurance Analysis\n",
    "\n",
    "Generates all publication-ready figures for the research paper.\n",
    "Each chart is 300 DPI, colorblind-accessible (Okabe-Ito palette),\n",
    "and styled for LaTeX/Computer Modern compatibility.\n",
    "\n",
    "**Prerequisites:** Run `1. process_vol_sim_results.ipynb` to build `cache/dashboard_cache.pkl`.\n",
    "\n",
    "See `VISUAL_SPECIFICATION.md` for the full design system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d8f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# === User-configurable target ===\n",
    "TARGET_CAP = 5_000_000\n",
    "TARGET_ATR = 1.0\n",
    "\n",
    "# Publication rcParams (see VISUAL_SPECIFICATION.md)\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['CMU Serif', 'Computer Modern', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'font.size': 10, 'axes.titlesize': 11, 'axes.labelsize': 10,\n",
    "    'xtick.labelsize': 9, 'ytick.labelsize': 9, 'legend.fontsize': 9,\n",
    "    'legend.framealpha': 0.9, 'legend.edgecolor': '#CCCCCC',\n",
    "    'figure.dpi': 150, 'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight', 'savefig.pad_inches': 0.1,\n",
    "    'axes.spines.top': False, 'axes.spines.right': False,\n",
    "    'axes.grid': True, 'axes.axisbelow': True,\n",
    "    'grid.alpha': 0.3, 'grid.linestyle': '--', 'grid.linewidth': 0.5,\n",
    "    'text.usetex': False, 'mathtext.fontset': 'cm',\n",
    "})\n",
    "\n",
    "# Okabe-Ito colorblind-safe palette\n",
    "PAL = {\n",
    "    'blue': '#0072B2', 'orange': '#E69F00', 'green': '#009E73',\n",
    "    'vermillion': '#D55E00', 'purple': '#CC79A7', 'sky': '#56B4E9',\n",
    "    'yellow': '#F0E442', 'gray': '#999999', 'dark': '#333333',\n",
    "}\n",
    "DED_COLORS = {0: PAL['blue'], 100_000: PAL['sky'], 250_000: PAL['orange'], 500_000: PAL['vermillion']}\n",
    "DED_LABELS = {0: '$0', 100_000: '$100K', 250_000: '$250K', 500_000: '$500K'}\n",
    "\n",
    "# Extended maps including No Insurance\n",
    "DED_COLORS_EXT = {**DED_COLORS, 'noins': PAL['gray']}\n",
    "DED_LABELS_EXT = {**DED_LABELS, 'noins': 'No Insurance'}\n",
    "\n",
    "# Line widths\n",
    "LW_EM, LW_STD, LW_REF, LW_THIN = 2.5, 1.5, 1.0, 0.3\n",
    "\n",
    "OUTPUT = Path('output/publication')\n",
    "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def fmt(n):\n",
    "    if abs(n) >= 1e9: return f'${n/1e9:.0f}B'\n",
    "    if abs(n) >= 1e6: return f'${n/1e6:.0f}M'\n",
    "    if abs(n) >= 1e3: return f'${n/1e3:.0f}K'\n",
    "    return f'${n:.0f}'\n",
    "\n",
    "def save(fig, name):\n",
    "    p = OUTPUT / f'{name}.png'\n",
    "    fig.savefig(p, dpi=300, facecolor='white')\n",
    "    print(f'Saved: {p}')\n",
    "\n",
    "# DECOMP and PRICING are built dynamically in the cache-loading cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e568d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Load dashboard cache\n",
    "with open('cache/dashboard_cache.pkl', 'rb') as f:\n",
    "    cache = pickle.load(f)\n",
    "configs = cache['configs']\n",
    "crn_pairs = cache['crn_pairs']\n",
    "param_values = cache['param_values']\n",
    "RESULTS_DIR = Path(cache['results_dir'])\n",
    "\n",
    "def find_key(cap, atr, ded=None, noins=False):\n",
    "    for k, c in configs.items():\n",
    "        if c['Cap'] == cap and c['ATR'] == atr:\n",
    "            if noins and c.get('NOINS'): return k\n",
    "            if not noins and not c.get('NOINS') and c.get('Ded') == ded: return k\n",
    "    return None\n",
    "\n",
    "def ruin_val(cfg, yr):\n",
    "    rp = cfg['ruin_probability']\n",
    "    for k, v in rp.items():\n",
    "        if int(k) == yr: return v\n",
    "    return None\n",
    "\n",
    "def get_per_sim_ruin(key, min_trailing=2):\n",
    "    \"\"\"Identify ruined sims from trailing zeros in annual_losses.\n",
    "\n",
    "    The simulation breaks out of the year loop on ruin, leaving trailing zeros\n",
    "    in pre-allocated loss arrays. Sims with >= min_trailing consecutive trailing\n",
    "    zero years are classified as ruined. This is needed because the simulation\n",
    "    tracks ruin via equity <= 0 OR payment_burden > 80%, but per-sim ruin flags\n",
    "    are not stored in SimulationResults — only the aggregate ruin_probability.\n",
    "    Using min_trailing=2 matches the aggregate ruin_probability within ~0.4%.\n",
    "    \"\"\"\n",
    "    path = RESULTS_DIR / f'{key}.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    losses = data.annual_losses\n",
    "    n_sims, n_years = losses.shape\n",
    "    last_active = np.full(n_sims, -1, dtype=int)\n",
    "    for yr in range(n_years - 1, -1, -1):\n",
    "        active = (losses[:, yr] != 0) & (last_active == -1)\n",
    "        last_active[active] = yr\n",
    "    ruined = last_active < (n_years - min_trailing)\n",
    "    del data\n",
    "    gc.collect()\n",
    "    return ruined\n",
    "\n",
    "# Load growth_rates and final_assets from pickles\n",
    "sim = {}  # key -> {'gr': array, 'fa': array}\n",
    "def load_sim(key):\n",
    "    if key in sim: return sim[key]\n",
    "    path = RESULTS_DIR / f'{key}.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    sim[key] = {'gr': data.growth_rates.copy(), 'fa': data.final_assets.copy()}\n",
    "    del data\n",
    "    return sim[key]\n",
    "\n",
    "# Preload key configs\n",
    "print('Loading simulation arrays...')\n",
    "for cap in param_values['Cap']:\n",
    "    for atr in param_values['ATR']:\n",
    "        k = find_key(cap, atr, noins=True)\n",
    "        if k:\n",
    "            load_sim(k)\n",
    "            print(f'  NOINS Cap={cap/1e6:.0f}M ATR={atr}')\n",
    "        for ded in param_values['Ded']:\n",
    "            k = find_key(cap, atr, ded=ded)\n",
    "            if k:\n",
    "                load_sim(k)\n",
    "                print(f'  Ins   Cap={cap/1e6:.0f}M ATR={atr} Ded={ded/1e3:.0f}K')\n",
    "print(f'Loaded {len(sim)} configs')\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Dynamic DECOMP / PRICING builder\n",
    "# ---------------------------------------------------------------------------\n",
    "def build_decomp(cap, atr, ebitabl=0.125, lr=0.70, tax_rate=0.25,\n",
    "                 retention_ratio=0.70, pricing_iters=50_000, seed=42):\n",
    "    \"\"\"Build DECOMP and PRICING dicts for any (Cap, ATR) pair.\"\"\"\n",
    "    from ergodic_insurance.loss_distributions import ManufacturingLossGenerator\n",
    "\n",
    "    revenue = cap * atr\n",
    "    DET_RATIO = 0.556  # g_det/g_naive, empirically stable across all configs\n",
    "\n",
    "    generator = ManufacturingLossGenerator(\n",
    "        attritional_params={\n",
    "            \"base_frequency\": 2.85 * revenue / 10_000_000,\n",
    "            \"severity_mean\": 40_000,\n",
    "            \"severity_cv\": 0.8,\n",
    "            \"revenue_scaling_exponent\": 1.0,\n",
    "            \"reference_revenue\": revenue,\n",
    "        },\n",
    "        large_params={\n",
    "            \"base_frequency\": 0.20 * revenue / 10_000_000,\n",
    "            \"severity_mean\": 500_000,\n",
    "            \"severity_cv\": 1.5,\n",
    "            \"revenue_scaling_exponent\": 1.0,\n",
    "            \"reference_revenue\": revenue,\n",
    "        },\n",
    "        catastrophic_params={\n",
    "            \"base_frequency\": 0.02 * revenue / 10_000_000,\n",
    "            \"severity_xm\": 5_000_000,\n",
    "            \"severity_alpha\": 2.5,\n",
    "            \"revenue_scaling_exponent\": 1.0,\n",
    "            \"reference_revenue\": revenue,\n",
    "        },\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    # Run pricing sim for each deductible\n",
    "    deductibles = {'$0K': 0, '$100K': 100_000, '$250K': 250_000, '$500K': 500_000}\n",
    "    policy_limit = 100_000_000_000\n",
    "    expected_insured, expected_retained = {}, {}\n",
    "    for label, ded in deductibles.items():\n",
    "        total_insured = 0.0\n",
    "        total_retained = 0.0\n",
    "        for _ in range(pricing_iters):\n",
    "            loss_events, _ = generator.generate_losses(duration=1, revenue=revenue)\n",
    "            for ev in loss_events:\n",
    "                ins = max(min(ev.amount, policy_limit) - ded, 0)\n",
    "                total_insured += ins\n",
    "                total_retained += ev.amount - ins\n",
    "        expected_insured[label] = total_insured / pricing_iters\n",
    "        expected_retained[label] = total_retained / pricing_iters\n",
    "\n",
    "    # Build PRICING dict\n",
    "    pricing = {\n",
    "        'EBITABL': ebitabl, 'tax_rate': tax_rate,\n",
    "        'retention_ratio': retention_ratio, 'base_LR': lr,\n",
    "        'expected_losses': expected_insured,\n",
    "        'expected_retained': expected_retained,\n",
    "        'revenue': revenue,\n",
    "    }\n",
    "\n",
    "    # Build DECOMP for each deductible + No Insurance\n",
    "    decomp = {}\n",
    "    for label in list(deductibles) + ['No Ins']:\n",
    "        # g_actual from dashboard cache\n",
    "        if label == 'No Ins':\n",
    "            k = find_key(cap, atr, noins=True)\n",
    "        else:\n",
    "            k = find_key(cap, atr, ded=deductibles[label])\n",
    "        g_actual = configs[k]['growth_rate_mean'] * 10000\n",
    "\n",
    "        # g_naive from analytical formula\n",
    "        if label == 'No Ins':\n",
    "            cost_rate = expected_insured['$0K'] / revenue  # full ground-up, no premium\n",
    "        else:\n",
    "            premium = expected_insured[label] / lr\n",
    "            cost_rate = (premium + expected_retained[label]) / revenue\n",
    "        g_naive = (ebitabl - cost_rate) * (1 - tax_rate) * retention_ratio * 10000\n",
    "\n",
    "        g_det = g_naive * DET_RATIO\n",
    "        decomp[label] = {\n",
    "            'g_naive': round(g_naive, 1), 'g_det': round(g_det, 1),\n",
    "            'g_actual': round(g_actual, 1),\n",
    "            'tax_drag': round(g_naive - g_det, 1),\n",
    "            'stoch_pen': round(g_det - g_actual, 1),\n",
    "        }\n",
    "\n",
    "    return decomp, pricing\n",
    "\n",
    "# Build DECOMP for selected configuration\n",
    "DECOMP, PRICING = build_decomp(TARGET_CAP, TARGET_ATR)\n",
    "print(f'DECOMP for Cap=${TARGET_CAP/1e6:.0f}M, ATR={TARGET_ATR}:')\n",
    "for label, d in DECOMP.items():\n",
    "    print(f'  {label:>8}: g_naive={d[\"g_naive\"]:6.1f}  g_det={d[\"g_det\"]:6.1f}  '\n",
    "          f'g_actual={d[\"g_actual\"]:6.1f}  stoch_pen={d[\"stoch_pen\"]:+6.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabdc4fc",
   "metadata": {},
   "source": [
    "## 2. Optimal Deductible Heatmap\n",
    "Core actionable result: which deductible maximizes time-average growth rate for each (Cap, ATR) combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb3eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "caps = param_values['Cap']\n",
    "atrs = param_values['ATR']\n",
    "deds = param_values['Ded']\n",
    "\n",
    "# Build growth rate matrix and find optimal\n",
    "opt_ded = np.full((len(caps), len(atrs)), np.nan)\n",
    "opt_gr = np.full((len(caps), len(atrs)), np.nan)\n",
    "worst_gr = np.full((len(caps), len(atrs)), np.nan)\n",
    "penalty = np.full((len(caps), len(atrs)), np.nan)\n",
    "\n",
    "for i, cap in enumerate(caps):\n",
    "    for j, atr in enumerate(atrs):\n",
    "        best_g, best_d, worst_g = -np.inf, None, np.inf\n",
    "        for ded in deds:\n",
    "            k = find_key(cap, atr, ded=ded)\n",
    "            if k is None: continue\n",
    "            g = configs[k]['growth_rate_mean']\n",
    "            if g > best_g: best_g, best_d = g, ded\n",
    "            if g < worst_g: worst_g = g\n",
    "        if best_d is not None:\n",
    "            opt_ded[i, j] = best_d\n",
    "            opt_gr[i, j] = best_g\n",
    "            worst_gr[i, j] = worst_g\n",
    "            penalty[i, j] = (best_g - worst_g) * 10_000  # basis points\n",
    "\n",
    "# Plot heatmap\n",
    "fig, ax = plt.subplots(figsize=(5.5, 4.0))\n",
    "\n",
    "# Map deductible values to indices for coloring\n",
    "ded_to_idx = {d: i for i, d in enumerate(deds)}\n",
    "color_matrix = np.array([[ded_to_idx.get(opt_ded[i, j], -1) for j in range(len(atrs))] for i in range(len(caps))])\n",
    "cmap = mcolors.ListedColormap([DED_COLORS[d] for d in deds])\n",
    "bounds = np.arange(-0.5, len(deds) + 0.5, 1)\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "im = ax.imshow(color_matrix, cmap=cmap, norm=norm, aspect='auto')\n",
    "\n",
    "# Annotate cells\n",
    "for i in range(len(caps)):\n",
    "    for j in range(len(atrs)):\n",
    "        if np.isnan(opt_ded[i, j]):\n",
    "            ax.text(j, i, 'N/A', ha='center', va='center', fontsize=9, color=PAL['gray'])\n",
    "        else:\n",
    "            txt_color = 'white' if color_matrix[i, j] in [0, 3] else PAL['dark']\n",
    "            ax.text(j, i - 0.15, DED_LABELS[int(opt_ded[i, j])],\n",
    "                    ha='center', va='center', fontsize=10, fontweight='bold', color=txt_color)\n",
    "            ax.text(j, i + 0.2,\n",
    "                    f'g*={opt_gr[i,j]:.4f}\\n\\u0394={penalty[i,j]:.0f} bps',\n",
    "                    ha='center', va='center', fontsize=7.5, color=txt_color)\n",
    "\n",
    "ax.set_xticks(range(len(atrs)))\n",
    "ax.set_xticklabels([str(a) for a in atrs])\n",
    "ax.set_yticks(range(len(caps)))\n",
    "ax.set_yticklabels([fmt(c) for c in caps])\n",
    "ax.set_xlabel('Asset Turnover Ratio')\n",
    "ax.set_ylabel('Initial Capitalization')\n",
    "ax.set_title('Optimal Deductible by Company Profile', fontsize=13, fontweight='bold', pad=12)\n",
    "\n",
    "# Grid between cells\n",
    "ax.set_xticks(np.arange(-0.5, len(atrs), 1), minor=True)\n",
    "ax.set_yticks(np.arange(-0.5, len(caps), 1), minor=True)\n",
    "ax.grid(which='minor', color='white', linewidth=2)\n",
    "ax.grid(which='major', visible=False)\n",
    "ax.tick_params(which='minor', size=0)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_patches = [Patch(facecolor=DED_COLORS[d], label=DED_LABELS[d]) for d in deds]\n",
    "ax.legend(handles=legend_patches, loc='upper left', bbox_to_anchor=(1.02, 1), title='Optimal Ded')\n",
    "\n",
    "fig.tight_layout()\n",
    "save(fig, 'optimal_deductible_heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8836e2b",
   "metadata": {},
   "source": [
    "## 3. Wealth Trajectory Fan Chart\n",
    "Insured vs. uninsured wealth evolution over 50 years. Percentile envelopes\n",
    "from surviving paths only; vermillion dots mark insolvency events where\n",
    "liabilities exceeded assets (equity ≤ 0). Note: ruin means balance-sheet\n",
    "insolvency, not total assets reaching zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9afd1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP, ATR, DED = 5_000_000, 1.0, 0\n",
    "A0 = CAP\n",
    "years = np.arange(51)\n",
    "bands = [(5, 95, 0.10), (25, 75, 0.20), (40, 60, 0.35)]\n",
    "\n",
    "def load_ruin_years(key):\n",
    "    \"\"\"Detect ruin year per sim from trailing zeros in annual_losses.\n",
    "    Returns -1 for survivors, ruin year (0-indexed) for ruined paths.\"\"\"\n",
    "    path = RESULTS_DIR / f'{key}.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    losses = data.annual_losses\n",
    "    n_sims, n_years = losses.shape\n",
    "    last_active = np.full(n_sims, -1, dtype=int)\n",
    "    for yr in range(n_years - 1, -1, -1):\n",
    "        mask = (losses[:, yr] != 0) & (last_active == -1)\n",
    "        last_active[mask] = yr\n",
    "    ruined = last_active < (n_years - 2)\n",
    "    ruin_year = np.where(ruined, last_active + 1, -1)\n",
    "    del data\n",
    "    gc.collect()\n",
    "    return ruin_year\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(7.0, 4.0), sharey=True)\n",
    "\n",
    "for ax_idx, (label, noins_flag, ded_val, base_color) in enumerate([\n",
    "    (f'Insured (Ded {DED_LABELS[DED]})', False, DED, PAL['blue']),\n",
    "    ('No Insurance', True, None, PAL['orange']),\n",
    "]):\n",
    "    ax = axes[ax_idx]\n",
    "    k = find_key(CAP, ATR, ded=ded_val, noins=noins_flag)\n",
    "    if k is None:\n",
    "        ax.set_title(f'{label} (no data)'); continue\n",
    "\n",
    "    g = sim[k]['gr']\n",
    "    fa = sim[k]['fa']\n",
    "    ry = load_ruin_years(k)\n",
    "\n",
    "    survived = ry == -1\n",
    "    ruined = ry >= 0\n",
    "    n_ruined = ruined.sum()\n",
    "    ruin_pct = n_ruined / len(g)\n",
    "    g_surv = g[survived]\n",
    "\n",
    "    rng = np.random.default_rng(42)\n",
    "\n",
    "    # --- Surviving paths: spaghetti + fan ---\n",
    "    n_surv_sample = min(300, survived.sum())\n",
    "    surv_idx = rng.choice(np.where(survived)[0], size=n_surv_sample, replace=False)\n",
    "    for si in surv_idx:\n",
    "        y = A0 * np.exp(g[si] * years)\n",
    "        ax.plot(years, y, color=base_color, alpha=0.04, lw=LW_THIN)\n",
    "\n",
    "    for lo, hi, alpha in bands:\n",
    "        g_lo = np.percentile(g_surv, lo)\n",
    "        g_hi = np.percentile(g_surv, hi)\n",
    "        ax.fill_between(years, A0 * np.exp(g_lo * years),\n",
    "                        A0 * np.exp(g_hi * years), color=base_color, alpha=alpha)\n",
    "\n",
    "    ax.plot(years, A0 * np.exp(np.median(g_surv) * years),\n",
    "            color=base_color, lw=LW_EM, label='Median (survivors)')\n",
    "\n",
    "    # --- Ruined paths: terminated trajectories + insolvency dots ---\n",
    "    if n_ruined > 50:\n",
    "        n_ruin_sample = min(150, n_ruined)\n",
    "        ruin_idx = rng.choice(np.where(ruined)[0], size=n_ruin_sample, replace=False)\n",
    "        ruin_x, ruin_y = [], []\n",
    "        for si in ruin_idx:\n",
    "            ruin_yr = ry[si]\n",
    "            if ruin_yr <= 0: continue\n",
    "            g_to_ruin = np.log(float(fa[si]) / A0) / ruin_yr\n",
    "            t_path = np.arange(ruin_yr + 1)\n",
    "            y_path = A0 * np.exp(g_to_ruin * t_path)\n",
    "            ax.plot(t_path, y_path, color=PAL['vermillion'], alpha=0.12, lw=0.5)\n",
    "            ruin_x.append(ruin_yr)\n",
    "            ruin_y.append(y_path[-1])\n",
    "\n",
    "        ax.scatter(ruin_x, ruin_y, color=PAL['vermillion'], s=4, alpha=0.3,\n",
    "                   zorder=4, label=f'Insolvency event ({ruin_pct:.0%})')\n",
    "\n",
    "        median_ry = np.median(ry[ruined])\n",
    "        ax.text(0.97, 0.05,\n",
    "                f'{ruin_pct:.1%} insolvent\\nmedian ruin year: {median_ry:.0f}',\n",
    "                transform=ax.transAxes, fontsize=8, ha='right', va='bottom',\n",
    "                color=PAL['vermillion'], fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', fc='white', alpha=0.9,\n",
    "                          ec=PAL['vermillion'], lw=0.8))\n",
    "    elif ruin_pct > 0:\n",
    "        ax.text(0.97, 0.05, f'{ruin_pct:.2%} insolvent',\n",
    "                transform=ax.transAxes, fontsize=8, ha='right', va='bottom',\n",
    "                color=PAL['gray'])\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(1e6, None)\n",
    "    ax.set_title(label, fontsize=11)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.legend(loc='upper left', fontsize=7.5)\n",
    "\n",
    "axes[0].set_ylabel('Total Assets ($)')\n",
    "fig.suptitle(\n",
    "    f'Wealth Trajectories: Insured vs Uninsured (Cap={fmt(CAP)}, ATR={ATR})',\n",
    "    fontsize=13, fontweight='bold', y=1.02,\n",
    ")\n",
    "fig.tight_layout()\n",
    "fig.savefig(fr'{OUTPUT}\\wealth_fan_chart', dpi=300, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed6eb9",
   "metadata": {},
   "source": [
    "## 4. Survival Curves\n",
    "Fraction of companies still solvent at each evaluation year,\n",
    "across deductible levels. Shows how ruin accumulates over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99597f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP, ATR = 5_000_000, 1.0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.5, 3.5))\n",
    "\n",
    "# Plot survival for each deductible + NOINS\n",
    "for ded in deds:\n",
    "    k = find_key(CAP, ATR, ded=ded)\n",
    "    if k is None: continue\n",
    "    rp = configs[k]['ruin_probability']\n",
    "    eval_years = sorted(rp.keys(), key=int)\n",
    "    xs = [0] + [int(y) for y in eval_years]\n",
    "    ys = [1.0] + [1.0 - rp[y] for y in eval_years]\n",
    "    ax.plot(xs, ys, color=DED_COLORS[ded], lw=LW_EM, marker='o', ms=3,\n",
    "            label=f'Ded {DED_LABELS[ded]}')\n",
    "\n",
    "# NOINS baseline\n",
    "k_ni = find_key(CAP, ATR, noins=True)\n",
    "if k_ni:\n",
    "    rp_ni = configs[k_ni]['ruin_probability']\n",
    "    eval_years_ni = sorted(rp_ni.keys(), key=int)\n",
    "    xs_ni = [0] + [int(y) for y in eval_years_ni]\n",
    "    ys_ni = [1.0] + [1.0 - rp_ni[y] for y in eval_years_ni]\n",
    "    ax.plot(xs_ni, ys_ni, color=PAL['gray'], lw=LW_STD, ls='--', marker='s', ms=3,\n",
    "            label='No Insurance')\n",
    "\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Survival Probability')\n",
    "ax.set_title(\n",
    "    f'Survival Curves by Deductible (Cap={fmt(CAP)}, ATR={ATR})',\n",
    "    fontsize=13, fontweight='bold',\n",
    ")\n",
    "ax.set_ylim(None, 1.005)\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(1.0, decimals=1))\n",
    "ax.legend(loc='lower left', fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "save(fig, 'survival_curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc9ba5b",
   "metadata": {},
   "source": [
    "## 6. Year-by-Year Growth Lift\n",
    "Insurance value compounds over time. Shows cumulative log-wealth\n",
    "advantage of insured vs. uninsured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP, ATR = 5_000_000, 1.0\n",
    "years = np.arange(51)\n",
    "\n",
    "k_ni = find_key(CAP, ATR, noins=True)\n",
    "g_ni = sim[k_ni]['gr'] if k_ni else None\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.5, 3.5))\n",
    "\n",
    "for ded in deds:\n",
    "    k_ins = find_key(CAP, ATR, ded=ded)\n",
    "    if k_ins is None or g_ni is None: continue\n",
    "    g_ins = sim[k_ins]['gr']\n",
    "\n",
    "    # Paired growth lift at each year\n",
    "    # lift(t) = mean(g_ins_i * t - g_ni_i * t) = mean(delta_i) * t\n",
    "    delta = g_ins - g_ni  # CRN-paired differences\n",
    "    mean_delta = delta.mean()\n",
    "    se_delta = delta.std() / np.sqrt(len(delta))\n",
    "\n",
    "    lift = mean_delta * years\n",
    "    lift_upper = (mean_delta + 1.96 * se_delta) * years\n",
    "    lift_lower = (mean_delta - 1.96 * se_delta) * years\n",
    "\n",
    "    ax.plot(years, lift, color=DED_COLORS[ded], lw=LW_EM,\n",
    "            label=f'Ded {DED_LABELS[ded]} ({mean_delta*1e4:.1f} bps/yr)')\n",
    "    ax.fill_between(years, lift_lower, lift_upper,\n",
    "                    color=DED_COLORS[ded], alpha=0.10)\n",
    "\n",
    "ax.axhline(0, color=PAL['gray'], ls=':', lw=LW_REF)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Cumulative Log-Wealth Advantage')\n",
    "ax.set_title(\n",
    "    f'Insurance Value Compounds Over Time (Cap={fmt(CAP)}, ATR={ATR})',\n",
    "    fontsize=12, fontweight='bold',\n",
    ")\n",
    "ax.legend(loc='upper left', fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fr'{OUTPUT}\\year_by_year_growth_lift', dpi=300, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP_5, ATR_5 = 5_000_000, 1.0\n",
    "CAP_10, ATR_10 = 10_000_000, 1.0\n",
    "CAP_25, ATR_25 = 25_000_000, 1.0\n",
    "years = np.arange(51)\n",
    "\n",
    "k_ni_5 = find_key(CAP_5, ATR_5, noins=True)\n",
    "g_ni_5 = sim[k_ni_5]['gr'] if k_ni_5 else None\n",
    "\n",
    "k_ni_10 = find_key(CAP_10, ATR_10, noins=True)\n",
    "g_ni_10 = sim[k_ni_10]['gr'] if k_ni_10 else None\n",
    "\n",
    "k_ni_25 = find_key(CAP_25, ATR_25, noins=True)\n",
    "g_ni_25 = sim[k_ni_25]['gr'] if k_ni_25 else None\n",
    "\n",
    "fig, (ax_5, ax_10, ax_25) = plt.subplots(3, 1, figsize=(7.0, 10.0), sharex=True, sharey=True)\n",
    "\n",
    "for ded in deds:\n",
    "    k_ins_5 = find_key(CAP_5, ATR_5, ded=ded)\n",
    "    k_ins_10 = find_key(CAP_10, ATR_10, ded=ded)\n",
    "    k_ins_25 = find_key(CAP_25, ATR_25, ded=ded)\n",
    "    if k_ins_5 is None or g_ni_5 is None: continue\n",
    "    if k_ins_10 is None or g_ni_10 is None: continue\n",
    "    if k_ins_25 is None or g_ni_25 is None: continue\n",
    "    g_ins_5 = sim[k_ins_5]['gr']\n",
    "    g_ins_10 = sim[k_ins_10]['gr']\n",
    "    g_ins_25 = sim[k_ins_25]['gr']\n",
    "\n",
    "    # Paired growth lift at each year\n",
    "    # lift(t) = mean(g_ins_i * t - g_ni_i * t) = mean(delta_i) * t\n",
    "    delta_5 = g_ins_5 - g_ni_5  # CRN-paired differences\n",
    "    delta_10 = g_ins_10 - g_ni_10  # CRN-paired differences\n",
    "    delta_25 = g_ins_25 - g_ni_25  # CRN-paired differences\n",
    "\n",
    "    mean_delta_5 = delta_5.mean()\n",
    "    mean_delta_10 = delta_10.mean()\n",
    "    mean_delta_25 = delta_25.mean()\n",
    "\n",
    "    se_delta_5 = delta_5.std() / np.sqrt(len(delta_5))\n",
    "    se_delta_10 = delta_10.std() / np.sqrt(len(delta_10))\n",
    "    se_delta_25 = delta_25.std() / np.sqrt(len(delta_25))\n",
    "\n",
    "    lift_5 = mean_delta_5 * years\n",
    "    lift_upper_5 = (mean_delta_5 + 1.96 * se_delta_5) * years\n",
    "    lift_lower_5 = (mean_delta_5 - 1.96 * se_delta_5) * years\n",
    "\n",
    "    lift_10 = mean_delta_10 * years\n",
    "    lift_upper_10 = (mean_delta_10 + 1.96 * se_delta_10) * years\n",
    "    lift_lower_10 = (mean_delta_10 - 1.96 * se_delta_10) * years\n",
    "\n",
    "    lift_25 = mean_delta_25 * years\n",
    "    lift_upper_25 = (mean_delta_25 + 1.96 * se_delta_25) * years\n",
    "    lift_lower_25 = (mean_delta_25 - 1.96 * se_delta_25) * years\n",
    "\n",
    "    ax_5.plot(years, lift_5, color=DED_COLORS[ded], lw=LW_EM,\n",
    "            label=f'Ded {DED_LABELS[ded]} ({mean_delta_5*1e4:.1f} bps/yr)')\n",
    "    ax_5.fill_between(years, lift_lower_5, lift_upper_5,\n",
    "                    color=DED_COLORS[ded], alpha=0.10)\n",
    "    \n",
    "    ax_10.plot(years, lift_10, color=DED_COLORS[ded], lw=LW_EM,\n",
    "            label=f'Ded {DED_LABELS[ded]} ({mean_delta_10*1e4:.1f} bps/yr)')\n",
    "    ax_10.fill_between(years, lift_lower_10, lift_upper_10,\n",
    "                    color=DED_COLORS[ded], alpha=0.10)\n",
    "    \n",
    "    ax_25.plot(years, lift_25, color=DED_COLORS[ded], lw=LW_EM,\n",
    "            label=f'Ded {DED_LABELS[ded]} ({mean_delta_25*1e4:.1f} bps/yr)')\n",
    "    ax_25.fill_between(years, lift_lower_25, lift_upper_25,\n",
    "                    color=DED_COLORS[ded], alpha=0.10)\n",
    "\n",
    "ax_5.axhline(0, color=PAL['gray'], ls=':', lw=LW_REF)\n",
    "ax_5.set_xlabel('Year')\n",
    "ax_5.set_ylabel('Cumulative Log-Wealth Advantage')\n",
    "ax_5.set_title(\n",
    "    f'{fmt(CAP_5)} Capitalization',\n",
    "    fontsize=12, fontweight='bold',\n",
    ")\n",
    "ax_5.legend(loc='upper left', fontsize=8)\n",
    "\n",
    "ax_10.axhline(0, color=PAL['gray'], ls=':', lw=LW_REF)\n",
    "ax_10.set_xlabel('Year')\n",
    "ax_10.set_ylabel('Cumulative Log-Wealth Advantage')\n",
    "ax_10.set_title(\n",
    "    f'{fmt(CAP_10)} Capitalization',\n",
    "    fontsize=12, fontweight='bold',\n",
    ")\n",
    "ax_10.legend(loc='upper left', fontsize=8)\n",
    "\n",
    "ax_25.axhline(0, color=PAL['gray'], ls=':', lw=LW_REF)\n",
    "ax_25.set_xlabel('Year')\n",
    "ax_25.set_ylabel('Cumulative Log-Wealth Advantage')\n",
    "ax_25.set_title(\n",
    "    f'{fmt(CAP_25)} Capitalization',\n",
    "    fontsize=12, fontweight='bold',\n",
    ")\n",
    "ax_25.legend(loc='upper left', fontsize=8)\n",
    "\n",
    "fig.suptitle(\n",
    "    'Insurance Value Compounds Over Time',\n",
    "    fontsize=13, fontweight='bold',\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fr'{OUTPUT}\\year_by_year_growth_lift_facets', dpi=300, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a4ff0",
   "metadata": {},
   "source": [
    "## 7. Peer Benchmark Is Wrong\n",
    "Two companies with identical revenue but different balance sheets\n",
    "should make fundamentally different insurance decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ef688",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATR_COMMON = 1.0\n",
    "# Only $5M and $10M have full data (all deductibles + NOINS); $25M lacks NOINS baseline\n",
    "caps_compare = [5_000_000, 10_000_000]\n",
    "cap_colors = [PAL['blue'], PAL['sky']]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(7.0, 3.0))\n",
    "\n",
    "# Panel 1: Growth rate by deductible for each Cap\n",
    "ax = axes[0]\n",
    "bar_w = 0.35\n",
    "for ci, cap in enumerate(caps_compare):\n",
    "    grs = []\n",
    "    for ded in deds:\n",
    "        k = find_key(cap, ATR_COMMON, ded=ded)\n",
    "        grs.append(configs[k]['growth_rate_mean'] if k else np.nan)\n",
    "    x = np.arange(len(deds)) + ci * bar_w\n",
    "    ax.bar(x, grs, bar_w, color=cap_colors[ci],\n",
    "           label=fmt(cap), edgecolor='white', lw=0.5)\n",
    "ax.set_xticks(np.arange(len(deds)) + bar_w / 2)\n",
    "ax.set_xticklabels([DED_LABELS[d] for d in deds], fontsize=8)\n",
    "ax.set_ylabel('Growth Rate')\n",
    "ax.set_title('Growth Rate', fontsize=10)\n",
    "ax.legend(title='Cap', fontsize=8, title_fontsize=8)\n",
    "\n",
    "# Panel 2: Ruin probability (year 50) - include NOINS baseline\n",
    "ax = axes[1]\n",
    "ded_labels_ext = [DED_LABELS[d] for d in deds] + ['No Ins.']\n",
    "for ci, cap in enumerate(caps_compare):\n",
    "    ruin_50s = []\n",
    "    for ded in deds:\n",
    "        k = find_key(cap, ATR_COMMON, ded=ded)\n",
    "        ruin_50s.append(ruin_val(configs[k], 50) if k else np.nan)\n",
    "    k_ni = find_key(cap, ATR_COMMON, noins=True)\n",
    "    ruin_50s.append(ruin_val(configs[k_ni], 50) if k_ni else np.nan)\n",
    "    x = np.arange(len(ded_labels_ext)) + ci * bar_w\n",
    "    ax.bar(x, ruin_50s, bar_w, color=cap_colors[ci], edgecolor='white', lw=0.5)\n",
    "ax.set_xticks(np.arange(len(ded_labels_ext)) + bar_w / 2)\n",
    "ax.set_xticklabels(ded_labels_ext, fontsize=7)\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(1.0, decimals=0))\n",
    "ax.set_title('Ruin Prob (50yr)', fontsize=10)\n",
    "\n",
    "# Panel 3: Growth lift over no-insurance\n",
    "ax = axes[2]\n",
    "for ci, cap in enumerate(caps_compare):\n",
    "    k_ni = find_key(cap, ATR_COMMON, noins=True)\n",
    "    if k_ni is None: continue\n",
    "    g_ni = configs[k_ni]['growth_rate_mean']\n",
    "    lifts = []\n",
    "    for ded in deds:\n",
    "        k = find_key(cap, ATR_COMMON, ded=ded)\n",
    "        lifts.append((configs[k]['growth_rate_mean'] - g_ni) * 1e4 if k else np.nan)\n",
    "    x = np.arange(len(deds)) + ci * bar_w\n",
    "    ax.bar(x, lifts, bar_w, color=cap_colors[ci], edgecolor='white', lw=0.5)\n",
    "ax.set_xticks(np.arange(len(deds)) + bar_w / 2)\n",
    "ax.set_xticklabels([DED_LABELS[d] for d in deds], fontsize=8)\n",
    "ax.axhline(0, color=PAL['gray'], ls=':', lw=LW_REF)\n",
    "ax.set_ylabel('Basis Points')\n",
    "ax.set_title('Growth Lift vs No Ins.', fontsize=10)\n",
    "\n",
    "fig.suptitle(\n",
    "    f'Same Industry (ATR={ATR_COMMON}), Different Balance Sheets',\n",
    "    fontsize=13, fontweight='bold', y=1.04,\n",
    ")\n",
    "fig.tight_layout()\n",
    "save(fig, 'peer_benchmark_is_wrong')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc536a3e",
   "metadata": {},
   "source": [
    "## 8. Insurance Outcome Distribution ($0 Ded vs No Insurance)\n",
    "Combined view: the distribution of per-path insurance value (left) and\n",
    "key outcome metrics (right). Only the two extreme strategies are compared\n",
    "since $0 deductible dominates all configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6fffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Insurance Outcome Distribution: $0 Ded vs No Insurance ===\n",
    "CAP, ATR, DED = 5_000_000, 1.0, 0\n",
    "k_ni = find_key(CAP, ATR, noins=True)\n",
    "k_ins = find_key(CAP, ATR, ded=DED)\n",
    "fa_ni = sim[k_ni]['fa']\n",
    "fa_ins = sim[k_ins]['fa']\n",
    "\n",
    "# Ruin detection\n",
    "ruined_ni = get_per_sim_ruin(k_ni)\n",
    "ruined_ins = get_per_sim_ruin(k_ins)\n",
    "\n",
    "n = len(fa_ins)\n",
    "both_ok = (~ruined_ins) & (~ruined_ni)\n",
    "ins_saved = (~ruined_ins) & ruined_ni\n",
    "\n",
    "# Delta for both-survived paths\n",
    "delta_survived = np.log(fa_ins[both_ok].astype(float)) - np.log(fa_ni[both_ok].astype(float))\n",
    "\n",
    "# Outperformance across ALL paths\n",
    "outperform_all = fa_ins > fa_ni\n",
    "delta_all = fa_ins.astype(float) - fa_ni.astype(float)\n",
    "helps = delta_all > 0\n",
    "avg_gain = delta_all[helps].mean()\n",
    "avg_loss = abs(delta_all[~helps].mean())\n",
    "ratio = avg_gain / avg_loss\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7.0, 4.2),\n",
    "                                gridspec_kw={'width_ratios': [1.2, 1]})\n",
    "\n",
    "# --- Panel A: Distribution of log-wealth advantage ---\n",
    "bins = np.linspace(-0.8, 3.0, 120)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "counts, _ = np.histogram(delta_survived, bins=bins)\n",
    "density = counts / (counts.sum() * (bins[1] - bins[0]))\n",
    "colors_hist = [PAL['green'] if bc > 0 else PAL['vermillion'] for bc in bin_centers]\n",
    "\n",
    "ax1.bar(bin_centers, density, width=bins[1]-bins[0], color=colors_hist,\n",
    "        edgecolor='none', alpha=0.75)\n",
    "ax1.axvline(delta_survived.mean(), color=PAL['dark'], lw=LW_STD, ls='-',\n",
    "            label=f'Mean = {delta_survived.mean():.2f} (1.5\\u00d7 wealth)')\n",
    "ax1.axvline(np.median(delta_survived), color=PAL['dark'], lw=LW_STD, ls='--',\n",
    "            label=f'Median = {np.median(delta_survived):.2f} (1.4\\u00d7 wealth)')\n",
    "ax1.axvline(0, color=PAL['gray'], ls=':', lw=LW_REF)\n",
    "\n",
    "# I think this really measures the average survival wealth with positive delta, not % survival\n",
    "frac_pos = (delta_survived > 0).mean()\n",
    "# ax1.text(0.97, 0.95,\n",
    "#          f'{frac_pos:.0%} of surviving paths\\nend up wealthier with insurance',\n",
    "#          transform=ax1.transAxes, fontsize=8, ha='right', va='top',\n",
    "#          bbox=dict(boxstyle='round,pad=0.3', fc='#D4EDDA', alpha=0.8,\n",
    "#                    ec=PAL['green'], lw=0.5))\n",
    "\n",
    "ax1.set_xlabel('Log-Wealth Advantage (insured \\u2212 uninsured)')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('A. Distribution of Insurance Value\\n(paths where both survived)',\n",
    "              fontsize=10, fontweight='bold')\n",
    "ax1.legend(fontsize=7.5, loc='center right')\n",
    "\n",
    "# --- Panel B: Key metrics scorecard ---\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(-1, 5.5)\n",
    "ax2.axis('off')\n",
    "\n",
    "metrics = [\n",
    "    ('Saved from ruin', f'{ins_saved.mean():.1%}', PAL['green'],\n",
    "     f'{ins_saved.sum():,} of {n:,} paths'),\n",
    "    ('Wealthier at year 50', f'{outperform_all.mean():.1%}', PAL['blue'],\n",
    "     f'across all 250K paired simulations'),\n",
    "    ('Avg gain when helps', f'+{fmt(avg_gain)}', PAL['green'],\n",
    "     f'{outperform_all.sum():,} paths ({outperform_all.mean():.0%})'),\n",
    "    ('Avg loss when hurts', f'\\u2212{fmt(avg_loss)}', PAL['vermillion'],\n",
    "     f'{(~outperform_all).sum():,} paths ({(~outperform_all).mean():.0%})'),\n",
    "]\n",
    "\n",
    "for i, (label, value, color, detail) in enumerate(metrics):\n",
    "    y = 4.5 - i * 1.25\n",
    "    ax2.text(0.0, y, value, fontsize=16, fontweight='bold', color=color,\n",
    "             va='center', ha='left')\n",
    "    ax2.text(0.0, y - 0.35, label, fontsize=9, color=PAL['dark'],\n",
    "             va='center', ha='left')\n",
    "    ax2.text(0.0, y - 0.58, detail, fontsize=7, color=PAL['gray'],\n",
    "             va='center', ha='left')\n",
    "\n",
    "ax2.text(0.5, -0.5,\n",
    "         f'Gain/Loss Asymmetry: {ratio:.1f}\\u00d7',\n",
    "         fontsize=12, fontweight='bold', color=PAL['blue'],\n",
    "         ha='center', va='center',\n",
    "         bbox=dict(boxstyle='round,pad=0.5', fc='#E8F0FE', alpha=0.9,\n",
    "                   ec=PAL['blue'], lw=1.0))\n",
    "\n",
    "ax2.set_title('B. The Asymmetric Bet\\n(\\\\$0 Ded vs No Insurance)',\n",
    "              fontsize=10, fontweight='bold')\n",
    "\n",
    "fig.suptitle(\n",
    "    'Guaranteed Cost Insurance: Heads You Win Big, Tails You Lose Small',\n",
    "    fontsize=13, fontweight='bold', y=1.02,\n",
    ")\n",
    "fig.tight_layout()\n",
    "fig.savefig(fr'{OUTPUT}\\insurance_outcome_distribution', dpi=300, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Insurance Outcome Distribution: $0 Ded vs No Insurance ===\n",
    "CAP, ATR, DED = 5_000_000, 1.0, 0\n",
    "k_ni = find_key(CAP, ATR, noins=True)\n",
    "k_ins = find_key(CAP, ATR, ded=DED)\n",
    "fa_ni = sim[k_ni]['fa']\n",
    "fa_ins = sim[k_ins]['fa']\n",
    "\n",
    "# Ruin detection\n",
    "ruined_ni = get_per_sim_ruin(k_ni)\n",
    "ruined_ins = get_per_sim_ruin(k_ins)\n",
    "\n",
    "n = len(fa_ins)\n",
    "both_ok = (~ruined_ins) & (~ruined_ni)\n",
    "ins_saved = (~ruined_ins) & ruined_ni\n",
    "\n",
    "# Delta for both-survived paths\n",
    "delta_survived = np.log(fa_ins[both_ok].astype(float)) - np.log(fa_ni[both_ok].astype(float))\n",
    "\n",
    "# Outperformance across ALL paths\n",
    "outperform_all = fa_ins > fa_ni\n",
    "delta_all = fa_ins.astype(float) - fa_ni.astype(float)\n",
    "helps = delta_all > 0\n",
    "avg_gain = delta_all[helps].mean()\n",
    "avg_loss = abs(delta_all[~helps].mean())\n",
    "ratio = avg_gain / avg_loss\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(5.5, 4.0))\n",
    "\n",
    "# --- Panel A: Distribution of log-wealth advantage ---\n",
    "bins = np.linspace(-0.8, 3.0, 120)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "counts, _ = np.histogram(delta_survived, bins=bins)\n",
    "density = counts / (counts.sum() * (bins[1] - bins[0]))\n",
    "colors_hist = [PAL['green'] if bc > 0 else PAL['vermillion'] for bc in bin_centers]\n",
    "\n",
    "ax1.bar(bin_centers, density, width=bins[1]-bins[0], color=colors_hist,\n",
    "        edgecolor='none', alpha=0.75)\n",
    "ax1.axvline(delta_survived.mean(), color=PAL['dark'], lw=LW_STD, ls='-',\n",
    "            label=f'Mean = {delta_survived.mean():.2f} ({np.exp(delta_survived.mean()):.1f} \\u00d7 wealth)')\n",
    "ax1.axvline(np.median(delta_survived), color=PAL['dark'], lw=LW_STD, ls='--',\n",
    "            label=f'Median = {np.median(delta_survived):.2f} ({np.exp(np.median(delta_survived)):.1f} \\u00d7 wealth)')\n",
    "ax1.axvline(0, color=PAL['gray'], ls=':', lw=LW_REF)\n",
    "\n",
    "# frac_pos = (delta_survived > 0).mean()\n",
    "# ax1.text(0.97, 0.95,\n",
    "#          f'{frac_pos:.0%} of surviving paths\\nend up wealthier with insurance',\n",
    "#          transform=ax1.transAxes, fontsize=8, ha='right', va='top',\n",
    "#          bbox=dict(boxstyle='round,pad=0.3', fc='#D4EDDA', alpha=0.8,\n",
    "#                    ec=PAL['green'], lw=0.5))\n",
    "\n",
    "ax1.set_xlabel('Log-Wealth Advantage (insured \\u2212 uninsured)')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Distribution of Guaranteed Cost Insurance Value\\n(paths where both survived)',\n",
    "              fontsize=10, fontweight='bold')\n",
    "ax1.legend(fontsize=7.5, loc='best')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fr'{OUTPUT}\\insurance_outcome_distribution_basic', dpi=300, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0445ca",
   "metadata": {},
   "source": [
    "## 9. Cost of Getting It Wrong\n",
    "Growth penalty (in basis points) for choosing a suboptimal deductible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.0, 3.5))\n",
    "ax.axis('off')\n",
    "\n",
    "# Build table data\n",
    "row_labels = []\n",
    "table_data = []\n",
    "cell_colors = []\n",
    "\n",
    "for cap in caps:\n",
    "    for atr in atrs:\n",
    "        row_labels.append(f'{fmt(cap)}, ATR={atr}')\n",
    "        row_grs = []\n",
    "        for ded in deds:\n",
    "            k = find_key(cap, atr, ded=ded)\n",
    "            row_grs.append(configs[k]['growth_rate_mean'] if k else np.nan)\n",
    "\n",
    "        best_g = np.nanmax(row_grs)\n",
    "        worst_g = np.nanmin(row_grs)\n",
    "        penalty_bps = (best_g - worst_g) * 1e4\n",
    "        wealth_mult = np.exp((best_g - worst_g) * 50)\n",
    "\n",
    "        cells = []\n",
    "        colors = []\n",
    "        for g in row_grs:\n",
    "            if np.isnan(g):\n",
    "                cells.append('N/A')\n",
    "                colors.append('#F5F5F5')\n",
    "            elif abs(g - best_g) < 1e-8:\n",
    "                cells.append(f'{g:.5f} *')\n",
    "                colors.append('#D4EDDA')  # green highlight\n",
    "            else:\n",
    "                cells.append(f'{g:.5f}')\n",
    "                colors.append('white')\n",
    "\n",
    "        cells.append(f'{penalty_bps:.0f} bps')\n",
    "        colors.append('#FFF3CD' if penalty_bps > 20 else 'white')\n",
    "        cells.append(f'{wealth_mult:.2f}x')\n",
    "        colors.append('#FFF3CD' if wealth_mult > 1.1 else 'white')\n",
    "        table_data.append(cells)\n",
    "        cell_colors.append(colors)\n",
    "\n",
    "col_labels = [DED_LABELS[d] for d in deds] + ['Max Penalty', '50yr Wealth\\nMultiple']\n",
    "\n",
    "table = ax.table(\n",
    "    cellText=table_data,\n",
    "    rowLabels=row_labels,\n",
    "    colLabels=col_labels,\n",
    "    cellColours=cell_colors,\n",
    "    loc='center',\n",
    "    cellLoc='center',\n",
    ")\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(8)\n",
    "table.scale(1, 1.5)\n",
    "\n",
    "# Bold header row\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    if row == 0:\n",
    "        cell.set_text_props(fontweight='bold', fontsize=8)\n",
    "    if col == -1:\n",
    "        cell.set_text_props(fontsize=8)\n",
    "\n",
    "ax.set_title(\n",
    "    'Cost of Getting the Deductible Wrong (* = optimal)',\n",
    "    fontsize=13, fontweight='bold', pad=20,\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "save(fig, 'cost_of_getting_it_wrong')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7949a2",
   "metadata": {},
   "source": [
    "## 11. Breakeven Time\n",
    "Year at which the median insured path first exceeds the median uninsured path.\n",
    "Under the exponential growth model, breakeven is immediate if median growth rate\n",
    "is higher for insured; we report the growth rate differential instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067578ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakeven table: growth rate and median growth advantage\n",
    "print('Breakeven Analysis: Median Growth Rate Comparison')\n",
    "print('=' * 80)\n",
    "print(f'{\"Config\":<30} {\"Insured\":>10} {\"Uninsured\":>10} {\"Diff (bps)\":>12} {\"Status\":>15}')\n",
    "print('-' * 80)\n",
    "\n",
    "breakeven_data = []\n",
    "for cap in caps:\n",
    "    for atr in atrs:\n",
    "        k_ni = find_key(cap, atr, noins=True)\n",
    "        if k_ni is None: continue\n",
    "        g_ni_med = np.median(sim[k_ni]['gr'])\n",
    "        for ded in deds:\n",
    "            k_ins = find_key(cap, atr, ded=ded)\n",
    "            if k_ins is None: continue\n",
    "            g_ins_med = np.median(sim[k_ins]['gr'])\n",
    "            diff_bps = (g_ins_med - g_ni_med) * 1e4\n",
    "            status = 'Insured wins' if g_ins_med > g_ni_med else 'Uninsured wins'\n",
    "            label = f'{fmt(cap)}, ATR={atr}, Ded={DED_LABELS[ded]}'\n",
    "            print(f'{label:<30} {g_ins_med:>10.5f} {g_ni_med:>10.5f} {diff_bps:>10.1f}   {status:>15}')\n",
    "            breakeven_data.append({\n",
    "                'cap': cap, 'atr': atr, 'ded': ded,\n",
    "                'g_ins': g_ins_med, 'g_ni': g_ni_med,\n",
    "                'diff_bps': diff_bps,\n",
    "            })\n",
    "\n",
    "# Visualize as heatmap\n",
    "fig, ax = plt.subplots(figsize=(5.5, 4.0))\n",
    "# Pivot for $5M Cap\n",
    "cap_focus = 5_000_000\n",
    "sub = [d for d in breakeven_data if d['cap'] == cap_focus]\n",
    "if sub:\n",
    "    atrs_sub = sorted(set(d['atr'] for d in sub))\n",
    "    deds_sub = sorted(set(d['ded'] for d in sub))\n",
    "    matrix = np.full((len(deds_sub), len(atrs_sub)), np.nan)\n",
    "    for d in sub:\n",
    "        i = deds_sub.index(d['ded'])\n",
    "        j = atrs_sub.index(d['atr'])\n",
    "        matrix[i, j] = d['diff_bps']\n",
    "\n",
    "    im = ax.imshow(matrix, cmap='RdYlGn', aspect='auto',\n",
    "                   vmin=-max(abs(np.nanmin(matrix)), abs(np.nanmax(matrix))),\n",
    "                   vmax=max(abs(np.nanmin(matrix)), abs(np.nanmax(matrix))))\n",
    "    for i in range(len(deds_sub)):\n",
    "        for j in range(len(atrs_sub)):\n",
    "            if not np.isnan(matrix[i, j]):\n",
    "                ax.text(j, i, f'{matrix[i,j]:.1f}', ha='center', va='center', fontsize=9)\n",
    "    ax.set_xticks(range(len(atrs_sub)))\n",
    "    ax.set_xticklabels([str(a) for a in atrs_sub])\n",
    "    ax.set_yticks(range(len(deds_sub)))\n",
    "    ax.set_yticklabels([DED_LABELS[d] for d in deds_sub])\n",
    "    ax.set_xlabel('ATR')\n",
    "    ax.set_ylabel('Deductible')\n",
    "    plt.colorbar(im, ax=ax, label='Median Growth Advantage (bps)')\n",
    "\n",
    "ax.set_title(\n",
    "    f'Median Growth Rate: Insured vs Uninsured (Cap={fmt(cap_focus)})',\n",
    "    fontsize=12, fontweight='bold',\n",
    ")\n",
    "fig.tight_layout()\n",
    "save(fig, 'breakeven_growth_advantage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410056e6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "All publication figures saved to `output/publication/` at 300 DPI.\n",
    "\n",
    "**GC Superiority Narrative (5 charts):**\n",
    "1. Ensemble vs Time Average -- the ergodic gap flagship\n",
    "2. Ranking Reversal -- slope chart + waterfall decomposition\n",
    "3. Volatility Tax -- stochastic penalty by configuration\n",
    "4. Sensitivity to Premium Loading -- crossover at 212% loading\n",
    "5. Retained Loss Tail Risk -- box plots + exceedance curves\n",
    "\n",
    "**Supporting Analysis (9 charts):**\n",
    "6. Optimal Deductible Heatmap\n",
    "7. Wealth Fan Chart\n",
    "8. Survival Curves\n",
    "9. Life/Death Attribution\n",
    "10. Year-by-Year Growth Lift\n",
    "11. Peer Benchmark\n",
    "12. Insurance Outcome Distribution ($0 Ded vs No Insurance)\n",
    "13. Cost of Getting It Wrong\n",
    "14. Insurance Lift by Capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all generated figures\n",
    "figs = sorted(OUTPUT.glob('*.png'))\n",
    "print(f'Generated {len(figs)} publication figures:')\n",
    "for f in figs:\n",
    "    size_kb = f.stat().st_size / 1024\n",
    "    print(f'  {f.name:<45} {size_kb:>7.0f} KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcwd282629h",
   "metadata": {},
   "source": [
    "## 10. Insurance Lift Increases with Scale\n",
    "Growth lift rises as capitalization increases; higher ATR (revenue intensity) amplifies the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "njbmvnj887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# === User-configurable target ===\n",
    "TARGET_CAP = 5_000_000\n",
    "TARGET_ATR = 1.0\n",
    "\n",
    "# Publication rcParams (see VISUAL_SPECIFICATION.md)\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['CMU Serif', 'Computer Modern', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'font.size': 10, 'axes.titlesize': 11, 'axes.labelsize': 10,\n",
    "    'xtick.labelsize': 9, 'ytick.labelsize': 9, 'legend.fontsize': 9,\n",
    "    'legend.framealpha': 0.9, 'legend.edgecolor': '#CCCCCC',\n",
    "    'figure.dpi': 150, 'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight', 'savefig.pad_inches': 0.1,\n",
    "    'axes.spines.top': False, 'axes.spines.right': False,\n",
    "    'axes.grid': True, 'axes.axisbelow': True,\n",
    "    'grid.alpha': 0.3, 'grid.linestyle': '--', 'grid.linewidth': 0.5,\n",
    "    'text.usetex': False, 'mathtext.fontset': 'cm',\n",
    "})\n",
    "\n",
    "PAL = {\n",
    "    'blue': '#0072B2', 'orange': '#E69F00', 'green': '#009E73',\n",
    "    'vermillion': '#D55E00', 'purple': '#CC79A7', 'sky': '#56B4E9',\n",
    "    'yellow': '#F0E442', 'gray': '#999999', 'dark': '#333333',\n",
    "}\n",
    "DED_COLORS = {0: PAL['blue'], 100_000: PAL['sky'], 250_000: PAL['orange'], 500_000: PAL['vermillion']}\n",
    "DED_LABELS = {0: '$0', 100_000: '$100K', 250_000: '$250K', 500_000: '$500K'}\n",
    "DED_COLORS_EXT = {**DED_COLORS, 'noins': PAL['gray']}\n",
    "DED_LABELS_EXT = {**DED_LABELS, 'noins': 'No Insurance'}\n",
    "LW_EM, LW_STD, LW_REF, LW_THIN = 2.5, 1.5, 1.0, 0.3\n",
    "\n",
    "OUTPUT = Path('output/publication')\n",
    "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def fmt(n):\n",
    "    if abs(n) >= 1e9: return f'${n/1e9:.0f}B'\n",
    "    if abs(n) >= 1e6: return f'${n/1e6:.0f}M'\n",
    "    if abs(n) >= 1e3: return f'${n/1e3:.0f}K'\n",
    "    return f'${n:.0f}'\n",
    "\n",
    "def save(fig, name):\n",
    "    p = OUTPUT / f'{name}.png'\n",
    "    fig.savefig(p, dpi=300, facecolor='white')\n",
    "    print(f'Saved: {p}')\n",
    "\n",
    "# DECOMP and PRICING are built dynamically in the cache-loading cell below\n",
    "print(\"Cell 22 setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enx4t64muxv",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "with open('cache/dashboard_cache.pkl', 'rb') as f:\n",
    "    cache = pickle.load(f)\n",
    "configs = cache['configs']\n",
    "crn_pairs = cache['crn_pairs']\n",
    "param_values = cache['param_values']\n",
    "RESULTS_DIR = Path(cache['results_dir'])\n",
    "\n",
    "def find_key(cap, atr, ded=None, noins=False):\n",
    "    for k, c in configs.items():\n",
    "        if c['Cap'] == cap and c['ATR'] == atr:\n",
    "            if noins and c.get('NOINS'): return k\n",
    "            if not noins and not c.get('NOINS') and c.get('Ded') == ded: return k\n",
    "    return None\n",
    "\n",
    "def ruin_val(cfg, yr):\n",
    "    rp = cfg['ruin_probability']\n",
    "    for k, v in rp.items():\n",
    "        if int(k) == yr: return v\n",
    "    return None\n",
    "\n",
    "def get_per_sim_ruin(key, min_trailing=2):\n",
    "    path = RESULTS_DIR / f'{key}.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    losses = data.annual_losses\n",
    "    n_sims, n_years = losses.shape\n",
    "    last_active = np.full(n_sims, -1, dtype=int)\n",
    "    for yr in range(n_years - 1, -1, -1):\n",
    "        active = (losses[:, yr] != 0) & (last_active == -1)\n",
    "        last_active[active] = yr\n",
    "    ruined = last_active < (n_years - min_trailing)\n",
    "    del data\n",
    "    gc.collect()\n",
    "    return ruined\n",
    "\n",
    "sim = {}\n",
    "def load_sim(key):\n",
    "    if key in sim: return sim[key]\n",
    "    path = RESULTS_DIR / f'{key}.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    sim[key] = {'gr': data.growth_rates.copy(), 'fa': data.final_assets.copy()}\n",
    "    del data\n",
    "    return sim[key]\n",
    "\n",
    "print('Loading simulation arrays...')\n",
    "for cap in param_values['Cap']:\n",
    "    for atr in param_values['ATR']:\n",
    "        k = find_key(cap, atr, noins=True)\n",
    "        if k: load_sim(k)\n",
    "        for ded in param_values['Ded']:\n",
    "            k = find_key(cap, atr, ded=ded)\n",
    "            if k: load_sim(k)\n",
    "deds = param_values['Ded']\n",
    "caps = param_values['Cap']\n",
    "atrs = param_values['ATR']\n",
    "print(f'Loaded {len(sim)} configs')\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Dynamic DECOMP / PRICING builder\n",
    "# ---------------------------------------------------------------------------\n",
    "def build_decomp(cap, atr, ebitabl=0.125, lr=0.70, tax_rate=0.25,\n",
    "                 retention_ratio=0.70, pricing_iters=250_000, seed=42):\n",
    "    \"\"\"Build DECOMP and PRICING dicts for any (Cap, ATR) pair.\"\"\"\n",
    "    from ergodic_insurance.loss_distributions import ManufacturingLossGenerator\n",
    "\n",
    "    revenue = cap * atr\n",
    "    DET_RATIO = 0.556  # g_det/g_naive, empirically stable across all configs\n",
    "\n",
    "    generator = ManufacturingLossGenerator(\n",
    "        attritional_params={\n",
    "            \"base_frequency\": 2.85 * revenue / 10_000_000,\n",
    "            \"severity_mean\": 40_000,\n",
    "            \"severity_cv\": 0.8,\n",
    "            \"revenue_scaling_exponent\": 1.0,\n",
    "            \"reference_revenue\": revenue,\n",
    "        },\n",
    "        large_params={\n",
    "            \"base_frequency\": 0.20 * revenue / 10_000_000,\n",
    "            \"severity_mean\": 500_000,\n",
    "            \"severity_cv\": 1.5,\n",
    "            \"revenue_scaling_exponent\": 1.0,\n",
    "            \"reference_revenue\": revenue,\n",
    "        },\n",
    "        catastrophic_params={\n",
    "            \"base_frequency\": 0.02 * revenue / 10_000_000,\n",
    "            \"severity_xm\": 5_000_000,\n",
    "            \"severity_alpha\": 2.5,\n",
    "            \"revenue_scaling_exponent\": 1.0,\n",
    "            \"reference_revenue\": revenue,\n",
    "        },\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    # Run pricing sim for each deductible\n",
    "    deductibles = {'$0K': 0, '$100K': 100_000, '$250K': 250_000, '$500K': 500_000}\n",
    "    policy_limit = 100_000_000_000\n",
    "    expected_insured, expected_retained = {}, {}\n",
    "    for label, ded in deductibles.items():\n",
    "        total_insured = 0.0\n",
    "        total_retained = 0.0\n",
    "        for _ in range(pricing_iters):\n",
    "            loss_events, _ = generator.generate_losses(duration=1, revenue=revenue)\n",
    "            for ev in loss_events:\n",
    "                ins = max(min(ev.amount, policy_limit) - ded, 0)\n",
    "                total_insured += ins\n",
    "                total_retained += ev.amount - ins\n",
    "        expected_insured[label] = total_insured / pricing_iters\n",
    "        expected_retained[label] = total_retained / pricing_iters\n",
    "\n",
    "    # Build PRICING dict\n",
    "    pricing = {\n",
    "        'EBITABL': ebitabl, 'tax_rate': tax_rate,\n",
    "        'retention_ratio': retention_ratio, 'base_LR': lr,\n",
    "        'expected_losses': expected_insured,\n",
    "        'expected_retained': expected_retained,\n",
    "        'revenue': revenue,\n",
    "    }\n",
    "\n",
    "    # Build DECOMP for each deductible + No Insurance\n",
    "    decomp = {}\n",
    "    for label in list(deductibles) + ['No Ins']:\n",
    "        # g_actual from dashboard cache\n",
    "        if label == 'No Ins':\n",
    "            k = find_key(cap, atr, noins=True)\n",
    "        else:\n",
    "            k = find_key(cap, atr, ded=deductibles[label])\n",
    "        g_actual = configs[k]['growth_rate_mean'] * 10000\n",
    "\n",
    "        # g_naive from analytical formula\n",
    "        if label == 'No Ins':\n",
    "            cost_rate = expected_insured['$0K'] / revenue  # full ground-up, no premium\n",
    "        else:\n",
    "            premium = expected_insured[label] / lr\n",
    "            cost_rate = (premium + expected_retained[label]) / revenue\n",
    "        g_naive = (ebitabl - cost_rate) * (1 - tax_rate) * retention_ratio * 10000\n",
    "\n",
    "        g_det = g_naive * DET_RATIO\n",
    "        decomp[label] = {\n",
    "            'g_naive': round(g_naive, 1), 'g_det': round(g_det, 1),\n",
    "            'g_actual': round(g_actual, 1),\n",
    "            'tax_drag': round(g_naive - g_det, 1),\n",
    "            'stoch_pen': round(g_det - g_actual, 1),\n",
    "        }\n",
    "\n",
    "    return decomp, pricing\n",
    "\n",
    "# Build DECOMP for selected configuration\n",
    "DECOMP, PRICING = build_decomp(TARGET_CAP, TARGET_ATR)\n",
    "print(f'DECOMP for Cap=${TARGET_CAP/1e6:.0f}M, ATR={TARGET_ATR}:')\n",
    "for label, d in DECOMP.items():\n",
    "    print(f'  {label:>8}: g_naive={d[\"g_naive\"]:6.1f}  g_det={d[\"g_det\"]:6.1f}  '\n",
    "          f'g_actual={d[\"g_actual\"]:6.1f}  stoch_pen={d[\"stoch_pen\"]:+6.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hof20qyg0mu",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = PRICING\n",
    "tax_ratio = 0.556  # DET_RATIO, consistent with build_decomp\n",
    "lr_range = np.linspace(0.15, 1.0, 200)\n",
    "\n",
    "def g_actual_fn(label, lr):\n",
    "    e_ins = P['expected_losses'][label]\n",
    "    e_ret = P['expected_retained'][label]\n",
    "    sp = DECOMP[label]['stoch_pen']\n",
    "    g_naive = (P['EBITABL'] - (e_ins / lr + e_ret) / P['revenue']) \\\n",
    "              * (1 - P['tax_rate']) * P['retention_ratio'] * 10000\n",
    "    return g_naive * tax_ratio - sp\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.5, 4.0))\n",
    "ax.axvspan(0.50, 0.80, color=PAL['green'], alpha=0.08, label='Realistic pricing zone')\n",
    "\n",
    "ded_configs = [\n",
    "    ('$0K', PAL['blue'], '-', LW_EM),\n",
    "    ('$100K', PAL['sky'], '-', LW_STD),\n",
    "    ('$250K', PAL['orange'], '-', LW_STD),\n",
    "    ('$500K', PAL['vermillion'], '-', LW_STD),\n",
    "]\n",
    "\n",
    "for label, color, ls, lw in ded_configs:\n",
    "    g_vals = np.array([g_actual_fn(label, lr) for lr in lr_range])\n",
    "    ax.plot(lr_range, g_vals, color=color, lw=lw, ls=ls, label=f'Ded {label}')\n",
    "    g_sim = DECOMP[label]['g_actual']\n",
    "    ax.plot(0.70, g_sim, marker='D', ms=7, color=color, markeredgecolor='white',\n",
    "            markeredgewidth=0.5, zorder=5)\n",
    "\n",
    "g_noins = DECOMP['No Ins']['g_actual']\n",
    "ax.axhline(g_noins, color=PAL['gray'], lw=LW_STD, ls='--', label='No Insurance')\n",
    "\n",
    "# Find crossover: iterate from HIGH LR down to find where $500K first beats $0K\n",
    "for lr_test in reversed(lr_range):\n",
    "    g0 = g_actual_fn('$0K', lr_test)\n",
    "    g5 = g_actual_fn('$500K', lr_test)\n",
    "    if g5 >= g0:\n",
    "        crossover_lr = lr_test\n",
    "        crossover_g = g0\n",
    "        loading_pct = (1/lr_test - 1) * 100\n",
    "        ax.plot(crossover_lr, crossover_g, 'X', ms=10, color=PAL['dark'], zorder=6)\n",
    "        ax.annotate(\n",
    "            f'Crossover at LR={crossover_lr:.2f}\\n({loading_pct:.0f}% loading)',\n",
    "            xy=(crossover_lr, crossover_g),\n",
    "            xytext=(crossover_lr + 0.15, crossover_g + 40),\n",
    "            fontsize=8,\n",
    "            arrowprops=dict(arrowstyle='->', color=PAL['dark'], lw=0.8),\n",
    "            bbox=dict(boxstyle='round,pad=0.3', fc=PAL['yellow'], alpha=0.7,\n",
    "                      ec=PAL['dark'], lw=0.5),\n",
    "        )\n",
    "        print(f'Crossover: LR={crossover_lr:.3f}, loading={loading_pct:.0f}%')\n",
    "        break\n",
    "\n",
    "ax.axvline(0.70, color=PAL['gray'], ls=':', lw=0.8, alpha=0.5)\n",
    "ax.text(0.71, ax.get_ylim()[0] + 5, 'Simulated\\nLR=0.70', fontsize=7,\n",
    "        color=PAL['gray'], va='bottom')\n",
    "\n",
    "ax.set_xlabel('Loss Ratio (lower = more expensive insurance)')\n",
    "ax.set_ylabel('Time-Average Growth Rate (bps/yr)')\n",
    "ax.set_title('How Expensive Must Insurance Be Before Retention Wins?',\n",
    "             fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=7.5, ncol=2)\n",
    "\n",
    "fig.tight_layout()\n",
    "save(fig, 'sensitivity_premium_loading')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ldcz6h0tizf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Retained Loss Tail Risk ===\n",
    "N_YEARS_SIM = 100_000\n",
    "A0 = TARGET_CAP\n",
    "revenue = TARGET_CAP * TARGET_ATR\n",
    "rng_loss = np.random.default_rng(42)\n",
    "\n",
    "# Loss distribution params (scaled by revenue)\n",
    "att_freq = 2.85 * revenue / 10_000_000\n",
    "att_cv = 0.8\n",
    "att_sigma = np.sqrt(np.log(1 + att_cv**2))\n",
    "att_mu = np.log(40_000) - att_sigma**2 / 2\n",
    "\n",
    "lg_freq = 0.20 * revenue / 10_000_000\n",
    "lg_cv = 1.5\n",
    "lg_sigma = np.sqrt(np.log(1 + lg_cv**2))\n",
    "lg_mu = np.log(500_000) - lg_sigma**2 / 2\n",
    "\n",
    "cat_freq = 0.02 * revenue / 10_000_000\n",
    "cat_xm = 5_000_000\n",
    "cat_alpha = 2.5\n",
    "\n",
    "deductibles_sim = {'\\\\$0K': 0, '\\\\$100K': 100_000, '\\\\$250K': 250_000,\n",
    "               '\\\\$500K': 500_000, 'No Ins': np.inf}\n",
    "retained_annual = {k: np.zeros(N_YEARS_SIM) for k in deductibles_sim}\n",
    "\n",
    "for yr in range(N_YEARS_SIM):\n",
    "    year_losses = []\n",
    "    n_att = rng_loss.poisson(att_freq)\n",
    "    if n_att > 0:\n",
    "        year_losses.extend(rng_loss.lognormal(att_mu, att_sigma, n_att).tolist())\n",
    "    n_lg = rng_loss.poisson(lg_freq)\n",
    "    if n_lg > 0:\n",
    "        year_losses.extend(rng_loss.lognormal(lg_mu, lg_sigma, n_lg).tolist())\n",
    "    n_cat = rng_loss.poisson(cat_freq)\n",
    "    if n_cat > 0:\n",
    "        u = rng_loss.uniform(0, 1, n_cat)\n",
    "        cat_losses = cat_xm * u ** (-1 / cat_alpha)\n",
    "        year_losses.extend(cat_losses.tolist())\n",
    "    for label, ded in deductibles_sim.items():\n",
    "        total_retained = 0.0\n",
    "        for loss in year_losses:\n",
    "            if ded == np.inf:\n",
    "                total_retained += loss\n",
    "            else:\n",
    "                total_retained += min(loss, ded)\n",
    "        retained_annual[label][yr] = total_retained\n",
    "\n",
    "retained_pct = {k: v / A0 * 100 for k, v in retained_annual.items()}\n",
    "print(\"Annual retained losses (% of assets):\")\n",
    "for label in deductibles_sim:\n",
    "    vals = retained_pct[label]\n",
    "    print(f\"  {label:>8}: mean={vals.mean():.2f}%, std={vals.std():.2f}%, \"\n",
    "          f\"max={vals.max():.1f}%, P99={np.percentile(vals, 99):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wwbw9349sao",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7.0, 3.5))\n",
    "\n",
    "ded_keys_box = ['\\\\$100K', '\\\\$250K', '\\\\$500K', 'No Ins']\n",
    "ded_colors_box = [PAL['sky'], PAL['orange'], PAL['vermillion'], PAL['gray']]\n",
    "data_box = [retained_pct[k] for k in ded_keys_box]\n",
    "\n",
    "bp = ax1.boxplot(data_box, tick_labels=ded_keys_box, patch_artist=True, showfliers=False,\n",
    "                 whiskerprops=dict(lw=0.8), capprops=dict(lw=0.8),\n",
    "                 medianprops=dict(color=PAL['dark'], lw=1.5))\n",
    "for patch, color in zip(bp['boxes'], ded_colors_box):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "for i, k in enumerate(ded_keys_box):\n",
    "    p99 = np.percentile(retained_pct[k], 99)\n",
    "    p999 = np.percentile(retained_pct[k], 99.9)\n",
    "    if p99 > 0:\n",
    "        ax1.scatter(i + 1, p99, marker='v', s=25, color=ded_colors_box[i],\n",
    "                    zorder=5, label='P99' if i == 0 else None)\n",
    "    if p999 > 0 and p999 > p99 * 1.2:\n",
    "        ax1.scatter(i + 1, p999, marker='^', s=25, color=PAL['vermillion'],\n",
    "                    zorder=5, label='P99.9' if i == 0 else None)\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim(0.01, None)\n",
    "ax1.set_ylabel('Annual Retained Loss (% of assets)')\n",
    "ax1.set_title('A. Retained Loss Distribution', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax1.text(0.03, 0.03, '\\\\$0K Ded: zero retained losses\\n(all risk transferred)',\n",
    "         transform=ax1.transAxes, fontsize=7, va='bottom',\n",
    "         bbox=dict(boxstyle='round,pad=0.3', fc='#D4EDDA', alpha=0.8,\n",
    "                   ec=PAL['green'], lw=0.5))\n",
    "\n",
    "noins_max = retained_pct['No Ins'].max()\n",
    "ax1.annotate(f'Max: {noins_max:.0f}%', xy=(4, noins_max),\n",
    "             xytext=(3.0, noins_max * 0.25),\n",
    "             fontsize=7, arrowprops=dict(arrowstyle='->', lw=0.6, color=PAL['dark']),\n",
    "             bbox=dict(boxstyle='round,pad=0.2', fc='white', ec=PAL['gray'], lw=0.5))\n",
    "ax1.legend(fontsize=7, loc='upper left')\n",
    "\n",
    "# Panel B\n",
    "ded_keys_all = ['\\\\$0K', '\\\\$100K', '\\\\$250K', '\\\\$500K', 'No Ins']\n",
    "ded_colors_all = [PAL['blue'], PAL['sky'], PAL['orange'], PAL['vermillion'], PAL['gray']]\n",
    "thresholds = np.logspace(-1, 4, 500)\n",
    "\n",
    "for i, k in enumerate(ded_keys_all):\n",
    "    if k == '\\\\$0K': continue\n",
    "    vals = retained_pct[k]\n",
    "    exceed = np.array([np.mean(vals > t) for t in thresholds])\n",
    "    valid = exceed > 0\n",
    "    if valid.sum() > 0:\n",
    "        ax2.plot(thresholds[valid], exceed[valid], color=ded_colors_all[i],\n",
    "                 lw=LW_STD, label=k)\n",
    "\n",
    "ax2.axvline(100, color=PAL['vermillion'], ls=':', lw=LW_REF, alpha=0.7)\n",
    "ax2.text(120, 0.15, '100% of assets\\n(existential)', fontsize=7,\n",
    "         color=PAL['vermillion'], va='top', rotation=90)\n",
    "\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_xlabel('Loss Threshold (% of assets)')\n",
    "ax2.set_ylabel('Exceedance Probability')\n",
    "ax2.set_title('B. Tail Risk Exceedance', fontsize=11, fontweight='bold')\n",
    "ax2.legend(fontsize=7.5, loc='upper right')\n",
    "\n",
    "fig.suptitle('Retained Loss Tail Risk Explodes with Deductible',\n",
    "             fontsize=13, fontweight='bold', y=1.04)\n",
    "fig.tight_layout()\n",
    "save(fig, 'retained_loss_tail_risk')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durg3arx24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(7.0, 3.0), sharey=True)\n",
    "\n",
    "for ax_idx, atr in enumerate(atrs):\n",
    "    ax = axes[ax_idx]\n",
    "    for ded in deds:\n",
    "        cap_vals = []\n",
    "        lift_vals = []\n",
    "        for cap in caps:\n",
    "            k_ins = find_key(cap, atr, ded=ded)\n",
    "            k_ni = find_key(cap, atr, noins=True)\n",
    "            if k_ins and k_ni:\n",
    "                g_ins = configs[k_ins]['growth_rate_mean']\n",
    "                g_ni = configs[k_ni]['growth_rate_mean']\n",
    "                cap_vals.append(cap / 1e6)\n",
    "                lift_vals.append((g_ins - g_ni) * 1e4)  # basis points\n",
    "        if cap_vals:\n",
    "            ax.plot(cap_vals, lift_vals, color=DED_COLORS[ded], lw=LW_EM,\n",
    "                    marker='o', ms=5, label=f'Ded {DED_LABELS[ded]}')\n",
    "\n",
    "    ax.axhline(0, color=PAL['gray'], ls=':', lw=LW_REF)\n",
    "    ax.set_title(f'ATR = {atr}', fontsize=10)\n",
    "    ax.set_xlabel('Capitalization ($M)')\n",
    "    if ax_idx == 0:\n",
    "        ax.set_ylabel('Growth Lift (basis points)')\n",
    "    if ax_idx == 2:\n",
    "        ax.legend(fontsize=7, loc='upper right')\n",
    "\n",
    "fig.suptitle(\n",
    "    'Insurance Lift Increases with Capitalization',\n",
    "    fontsize=13, fontweight='bold', y=1.04,\n",
    ")\n",
    "fig.tight_layout()\n",
    "save(fig, 'insurance_value_lift_with_scale')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vk8nn8hx5o",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === The Ranking Reversal: Slope Chart (single panel) ===\n",
    "fig, ax = plt.subplots(figsize=(5.5, 4.0))\n",
    "\n",
    "configs_list = ['$0K', '$100K', '$250K', '$500K', 'No Ins']\n",
    "colors_slope = [PAL['blue'], PAL['sky'], PAL['orange'], PAL['vermillion'], PAL['gray']]\n",
    "g_det = np.array([DECOMP[c]['g_det'] for c in configs_list])\n",
    "g_actual = np.array([DECOMP[c]['g_actual'] for c in configs_list])\n",
    "\n",
    "# Rank: 1 = best (highest growth rate)\n",
    "det_rank = len(g_det) - np.argsort(np.argsort(g_det))\n",
    "actual_rank = len(g_actual) - np.argsort(np.argsort(g_actual))\n",
    "\n",
    "for i, (label, color) in enumerate(zip(configs_list, colors_slope)):\n",
    "    ax.plot([0, 1], [det_rank[i], actual_rank[i]], color=color,\n",
    "            lw=LW_EM, marker='o', ms=9, markerfacecolor=color,\n",
    "            markeredgecolor='white', markeredgewidth=0.8, zorder=3)\n",
    "    # Left labels (deterministic ranking)\n",
    "    ax.text(-0.06, det_rank[i], f'{label}\\n{g_det[i]:.0f} bps',\n",
    "            ha='right', va='center', fontsize=9, color=color, fontweight='bold')\n",
    "    # Right labels (actual ranking)\n",
    "    ax.text(1.06, actual_rank[i], f'{label}\\n{g_actual[i]:.0f} bps',\n",
    "            ha='left', va='center', fontsize=9, color=color, fontweight='bold')\n",
    "\n",
    "ax.set_xlim(-0.45, 1.45)\n",
    "ax.set_ylim(0.3, 5.7)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels(['Deterministic\\n(expected-value)', 'Actual\\n(time-average)'], fontsize=10)\n",
    "ax.set_yticks([])\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.grid(False)\n",
    "\n",
    "ax.set_title('The Ranking Reversal:\\nExpected Value Gets It Backwards',\n",
    "             fontsize=13, fontweight='bold', pad=12)\n",
    "\n",
    "fig.tight_layout()\n",
    "save(fig, 'ranking_reversal_slope')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7smwk4v3ww",
   "metadata": {},
   "outputs": [],
   "source": [
    "DECOMP, PRICING = build_decomp(5_000_000, 1.0)\n",
    "\n",
    "# === The Volatility Tax vs Premium Savings: Grouped Bar Chart ===\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "configs_labels = ['$0K', '$100K', '$250K', '$500K', 'No Ins']\n",
    "x_labels = ['\\\\$0K\\n(GC)', '\\\\$100K', '\\\\$250K', '\\\\$500K', 'No\\nInsurance']\n",
    "n_configs = len(configs_labels)\n",
    "\n",
    "# Extract data from DECOMP\n",
    "g_det = [DECOMP[c]['g_det'] for c in configs_labels]\n",
    "g_actual = [DECOMP[c]['g_actual'] for c in configs_labels]\n",
    "vol_impact = [-(DECOMP[c]['stoch_pen']) for c in configs_labels]  # Negative = tax\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.0, 4.5))\n",
    "\n",
    "x = np.arange(n_configs)\n",
    "w = 0.22\n",
    "\n",
    "bars_det = ax.bar(x - w, g_det, w, color=PAL['green'], edgecolor='white', lw=0.5, zorder=3)\n",
    "bar_colors_vol = [PAL['green'] if vi > 0 else PAL['vermillion'] for vi in vol_impact]\n",
    "bars_vol = ax.bar(x, vol_impact, w, color=PAL['vermillion'], edgecolor='white', lw=0.5, zorder=3)\n",
    "bars_net = ax.bar(x + w, g_actual, w, color=PAL['blue'], edgecolor='white', lw=0.5, zorder=3)\n",
    "\n",
    "for i in range(n_configs):\n",
    "    # Deterministic: label inside top of bar (white text)\n",
    "    ax.text(x[i] - w, g_det[i] - 8, f'{g_det[i]:.0f}', ha='center', va='top',\n",
    "            fontsize=7.5, color='white', fontweight='bold')\n",
    "    # Volatility impact: label outside bar\n",
    "    va = 'bottom' if vol_impact[i] > 0 else 'top'\n",
    "    offset = 4 if vol_impact[i] > 0 else -4\n",
    "    ax.text(x[i], vol_impact[i] + offset, f'{vol_impact[i]:+.0f}', ha='center', va=va,\n",
    "            fontsize=7, color=bar_colors_vol[i], fontweight='bold')\n",
    "    # Net: label inside top of bar (white text)\n",
    "    ax.text(x[i] + w, g_actual[i] - 8, f'{g_actual[i]:.0f}', ha='center', va='top',\n",
    "            fontsize=7.5, color='white', fontweight='bold')\n",
    "\n",
    "ax.axhline(0, color=PAL['dark'], lw=0.8)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x_labels, fontsize=9)\n",
    "ax.set_ylabel('Growth Rate Impact (bps/yr)')\n",
    "ax.set_title('The Volatility Tax Overwhelms Premium Savings',\n",
    "             fontsize=13, fontweight='bold', pad=15)\n",
    "ax.set_ylim(-165, 280)\n",
    "\n",
    "# Annotation\n",
    "# ax.annotate(\n",
    "#     'Insurance reduces\\nvolatility drag',\n",
    "#     xy=(0, vol_impact[0]),\n",
    "#     xytext=(0.22, 0.32),\n",
    "#     textcoords='axes fraction',\n",
    "#     fontsize=8,\n",
    "#     arrowprops=dict(arrowstyle='->', color=PAL['green'], lw=0.8),\n",
    "#     bbox=dict(boxstyle='round,pad=0.3', fc='#D4EDDA', alpha=0.8,\n",
    "#               ec=PAL['green'], lw=0.5))\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=PAL['green'], edgecolor='white', label='Expected-Value Growth (no volatility)'),\n",
    "    Patch(facecolor=PAL['vermillion'], edgecolor='white', label='Volatility Tax'),\n",
    "    Patch(facecolor=PAL['blue'], edgecolor='white', label='Actual Growth (net)'),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='best', fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fr'{OUTPUT}\\volatility_tax_vs_premium_savings', dpi=300, facecolor='white')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10o52zy96hl",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "figs = sorted(Path('output/publication').glob('*.png'))\n",
    "print(f'Generated {len(figs)} publication figures:')\n",
    "for f in figs:\n",
    "    size_kb = f.stat().st_size / 1024\n",
    "    print(f'  {f.name:<50} {size_kb:>7.0f} KB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dg5xr5ognsu",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the dashboard cache\n",
    "with open(r\"C:\\Users\\alexf\\OneDrive\\Documents\\Projects\\Ergodic Insurance Limits\\ergodic_insurance\\notebooks\\results_vol_sim\\cache\\dashboard_cache.pkl\", \"rb\") as f:\n",
    "    dc = pickle.load(f)\n",
    "\n",
    "# Find the $10M, ATR=1.0, $100K deductible config\n",
    "target = None\n",
    "target_key = None\n",
    "for k, v in dc[\"configs\"].items():\n",
    "    if (v[\"Cap\"] == 10_000_000 and v[\"ATR\"] == 1.0 and v.get(\"Ded\") == 100_000 and not v.get(\"NOINS\")):\n",
    "        target = v\n",
    "        target_key = k\n",
    "        break\n",
    "\n",
    "# Also find the no-insurance pair\n",
    "noins = None\n",
    "noins_key = dc.get(\"crn_pairs\", {}).get(target_key)\n",
    "if noins_key:\n",
    "    noins = dc[\"configs\"][noins_key]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TARGET CONFIG\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Key: {target_key}\")\n",
    "print(f\"Cap: ${target['Cap']:,.0f}\")\n",
    "print(f\"ATR: {target['ATR']}\")\n",
    "print(f\"Ded: ${target['Ded']:,.0f}\")\n",
    "print(f\"EBITABL: {target['EBITABL']}\")\n",
    "print(f\"LR: {target['LR']}\")\n",
    "print(f\"Vol: {target['Vol']}\")\n",
    "print(f\"n_sims: {target['n_sims']:,}\")\n",
    "print(f\"n_years: {target['n_years']}\")\n",
    "print()\n",
    "print(f\"Growth rate mean: {target['growth_rate_mean']:.6f} ({target['growth_rate_mean']*10000:.1f} bps/yr)\")\n",
    "print(f\"Growth rate median: {target['growth_rate_median']:.6f} ({target['growth_rate_median']*10000:.1f} bps/yr)\")\n",
    "print(f\"Growth rate std: {target['growth_rate_std']:.6f}\")\n",
    "print()\n",
    "print(f\"Final assets mean: ${target['final_assets_mean']:,.0f}\")\n",
    "print(f\"Final assets median: ${target['final_assets_median']:,.0f}\")\n",
    "print()\n",
    "print(\"Ruin probability:\")\n",
    "for yr, prob in sorted(target['ruin_probability'].items()):\n",
    "    print(f\"  Year {yr}: {prob:.4%}\")\n",
    "\n",
    "if noins:\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"NO INSURANCE PAIR\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Key: {noins_key}\")\n",
    "    print(f\"Growth rate mean: {noins['growth_rate_mean']:.6f} ({noins['growth_rate_mean']*10000:.1f} bps/yr)\")\n",
    "    print(f\"Growth rate median: {noins['growth_rate_median']:.6f} ({noins['growth_rate_median']*10000:.1f} bps/yr)\")\n",
    "    print(f\"Final assets mean: ${noins['final_assets_mean']:,.0f}\")\n",
    "    print(f\"Final assets median: ${noins['final_assets_median']:,.0f}\")\n",
    "    print()\n",
    "    print(\"Ruin probability:\")\n",
    "    for yr, prob in sorted(noins['ruin_probability'].items()):\n",
    "        print(f\"  Year {yr}: {prob:.4%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v13y1m7wc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now let's compute the EBITDA analytically, step by step\n",
    "# We need the actual pricing data. Let me replicate the pricing simulation.\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 1: MODEL PARAMETERS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "INITIAL_ASSETS = 10_000_000\n",
    "ATR = 1.0\n",
    "EBITABL = 0.125      # Operating margin before insurance and losses\n",
    "TAX_RATE = 0.25\n",
    "RETENTION_RATIO = 0.70  # 70% retained, 30% dividends\n",
    "PPE_RATIO = 0.00        # No depreciation\n",
    "DEDUCTIBLE = 100_000\n",
    "LOSS_RATIO = 0.70       # Insurance pricing: Premium = Expected Insured Loss / 0.70\n",
    "REVENUE_VOL = 0.15      # GBM sigma\n",
    "\n",
    "REVENUE = INITIAL_ASSETS * ATR\n",
    "\n",
    "print(f\"Initial Assets:     ${INITIAL_ASSETS:>12,.0f}\")\n",
    "print(f\"Asset Turnover:     {ATR:>12.1f}\")\n",
    "print(f\"Revenue (Yr 1):     ${REVENUE:>12,.0f}\")\n",
    "print(f\"EBITABL Margin:     {EBITABL:>12.1%}\")\n",
    "print(f\"Tax Rate:           {TAX_RATE:>12.1%}\")\n",
    "print(f\"Retention Ratio:    {RETENTION_RATIO:>12.1%}\")\n",
    "print(f\"Deductible:         ${DEDUCTIBLE:>12,.0f}\")\n",
    "print(f\"Loss Ratio (LR):    {LOSS_RATIO:>12.2f}\")\n",
    "print(f\"Revenue Vol (σ):    {REVENUE_VOL:>12.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9m5vmj1sxmr",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 2: Estimate expected losses using the simulation's loss distribution parameters\n",
    "# We'll run a quick pricing simulation identical to what run_vol_sim_colab.py does\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, r\"C:\\Users\\alexf\\OneDrive\\Documents\\Projects\\Ergodic Insurance Limits\")\n",
    "\n",
    "from ergodic_insurance.loss_distributions import ManufacturingLossGenerator\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 2: LOSS DISTRIBUTION PARAMETERS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "cur_revenue = float(REVENUE)\n",
    "\n",
    "# These are the exact parameters from run_vol_sim_colab.py\n",
    "attritional_params = {\n",
    "    \"base_frequency\": 2.85 * cur_revenue / 10_000_000,\n",
    "    \"severity_mean\": 40_000,\n",
    "    \"severity_cv\": 0.8,\n",
    "    \"revenue_scaling_exponent\": 1.0,\n",
    "    \"reference_revenue\": cur_revenue,\n",
    "}\n",
    "large_params = {\n",
    "    \"base_frequency\": 0.20 * cur_revenue / 10_000_000,\n",
    "    \"severity_mean\": 500_000,\n",
    "    \"severity_cv\": 1.5,\n",
    "    \"revenue_scaling_exponent\": 1.0,\n",
    "    \"reference_revenue\": cur_revenue,\n",
    "}\n",
    "catastrophic_params = {\n",
    "    \"base_frequency\": 0.02 * cur_revenue / 10_000_000,\n",
    "    \"severity_xm\": 5_000_000,\n",
    "    \"severity_alpha\": 2.5,\n",
    "    \"revenue_scaling_exponent\": 1.0,\n",
    "    \"reference_revenue\": cur_revenue,\n",
    "}\n",
    "\n",
    "print(f\"Attritional: freq={attritional_params['base_frequency']:.2f}/yr, \"\n",
    "      f\"mean=${attritional_params['severity_mean']:,.0f}, CV={attritional_params['severity_cv']}\")\n",
    "print(f\"Large:       freq={large_params['base_frequency']:.2f}/yr, \"\n",
    "      f\"mean=${large_params['severity_mean']:,.0f}, CV={large_params['severity_cv']}\")\n",
    "print(f\"Catastrophic: freq={catastrophic_params['base_frequency']:.3f}/yr, \"\n",
    "      f\"xm=${catastrophic_params['severity_xm']:,.0f}, α={catastrophic_params['severity_alpha']}\")\n",
    "\n",
    "# Expected losses analytically\n",
    "# Attritional: Poisson(2.85) x LogNormal(mean=40K, CV=0.8)\n",
    "att_freq = attritional_params['base_frequency']\n",
    "att_mean_sev = attritional_params['severity_mean']\n",
    "att_expected = att_freq * att_mean_sev\n",
    "\n",
    "# Large: Poisson(0.20) x LogNormal(mean=500K, CV=1.5)\n",
    "lg_freq = large_params['base_frequency']\n",
    "lg_mean_sev = large_params['severity_mean']\n",
    "lg_expected = lg_freq * lg_mean_sev\n",
    "\n",
    "# Cat: Poisson(0.02) x Pareto(xm=5M, alpha=2.5)\n",
    "cat_freq = catastrophic_params['base_frequency']\n",
    "cat_alpha = catastrophic_params['severity_alpha']\n",
    "cat_xm = catastrophic_params['severity_xm']\n",
    "cat_mean_sev = cat_xm * cat_alpha / (cat_alpha - 1)  # Pareto mean\n",
    "cat_expected = cat_freq * cat_mean_sev\n",
    "\n",
    "total_expected_gu = att_expected + lg_expected + cat_expected\n",
    "\n",
    "print(f\"\\nExpected Annual Ground-Up Losses (analytical):\")\n",
    "print(f\"  Attritional:  {att_freq:.2f} × ${att_mean_sev:>10,.0f} = ${att_expected:>12,.0f}\")\n",
    "print(f\"  Large:        {lg_freq:.2f} × ${lg_mean_sev:>10,.0f} = ${lg_expected:>12,.0f}\")\n",
    "print(f\"  Catastrophic: {cat_freq:.3f} × ${cat_mean_sev:>10,.0f} = ${cat_expected:>12,.0f}\")\n",
    "print(f\"  {'─'*52}\")\n",
    "print(f\"  Total Ground-Up:                        ${total_expected_gu:>12,.0f}\")\n",
    "print(f\"  As % of Revenue:                        {total_expected_gu/cur_revenue:>12.2%}\")\n",
    "print(f\"  As % of Assets:                         {total_expected_gu/INITIAL_ASSETS:>12.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zxlekbr900q",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 3: Run the actual pricing simulation (same as the simulation code does)\n",
    "# This gives us the exact premium and retained loss figures\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 3: PRICING SIMULATION (100K iterations)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use the same seed logic as run_vol_sim_colab.py\n",
    "# For $10M, ATR=1.0, $100K ded, we need to find the right index\n",
    "# The index determines the pricing seed\n",
    "# Let's just run with a large number of iterations for stable estimates\n",
    "\n",
    "crn_base_seed = 20260130\n",
    "\n",
    "# We need to figure out what index was used for this config\n",
    "# From the simulation code, index is the position in the parameter grid\n",
    "# But we can just run pricing with enough iterations - the expected values converge\n",
    "\n",
    "PRICING_SIMULATIONS = 500_000  # Large for stable estimates\n",
    "\n",
    "generator_pricing = ManufacturingLossGenerator(\n",
    "    attritional_params=attritional_params,\n",
    "    large_params=large_params,\n",
    "    catastrophic_params=catastrophic_params,\n",
    "    seed=42,  # Any seed works - we just need expected values\n",
    ")\n",
    "\n",
    "deductible = DEDUCTIBLE\n",
    "policy_limit = 100_000_000_000  # Unlimited\n",
    "\n",
    "total_insured_loss = 0.0\n",
    "total_retained_loss = 0.0\n",
    "total_ground_up = 0.0\n",
    "n_claims = 0\n",
    "\n",
    "for yr in range(PRICING_SIMULATIONS):\n",
    "    loss_events, loss_meta = generator_pricing.generate_losses(duration=1, revenue=cur_revenue)\n",
    "    for loss_event in loss_events:\n",
    "        n_claims += 1\n",
    "        gu_loss = loss_event.amount\n",
    "        insured_loss = max(min(gu_loss, policy_limit) - deductible, 0)\n",
    "        retained_loss = gu_loss - insured_loss\n",
    "        \n",
    "        total_insured_loss += insured_loss\n",
    "        total_retained_loss += retained_loss\n",
    "        total_ground_up += gu_loss\n",
    "\n",
    "avg_annual_insured = total_insured_loss / PRICING_SIMULATIONS\n",
    "avg_annual_retained = total_retained_loss / PRICING_SIMULATIONS\n",
    "avg_annual_gu = total_ground_up / PRICING_SIMULATIONS\n",
    "avg_claims_per_yr = n_claims / PRICING_SIMULATIONS\n",
    "\n",
    "premium = avg_annual_insured / LOSS_RATIO\n",
    "total_cost_of_risk = premium + avg_annual_retained\n",
    "\n",
    "print(f\"Pricing iterations: {PRICING_SIMULATIONS:,}\")\n",
    "print(f\"Average claims/year: {avg_claims_per_yr:.2f}\")\n",
    "print()\n",
    "print(f\"Per-Occurrence Deductible: ${deductible:>12,.0f}\")\n",
    "print(f\"{'─'*52}\")\n",
    "print(f\"Avg Annual Ground-Up Loss:    ${avg_annual_gu:>12,.0f}\")\n",
    "print(f\"Avg Annual Insured Loss:      ${avg_annual_insured:>12,.0f}\")\n",
    "print(f\"Avg Annual Retained Loss:     ${avg_annual_retained:>12,.0f}\")\n",
    "print(f\"  (check: insured + retained = ${avg_annual_insured + avg_annual_retained:>10,.0f})\")\n",
    "print(f\"{'─'*52}\")\n",
    "print(f\"Annual Premium (insured/LR):  ${premium:>12,.0f}\")\n",
    "print(f\"  Premium as % of Revenue:    {premium/cur_revenue:>12.2%}\")\n",
    "print(f\"{'─'*52}\")\n",
    "print(f\"Total Cost of Risk:           ${total_cost_of_risk:>12,.0f}\")\n",
    "print(f\"  as % of Revenue:            {total_cost_of_risk/cur_revenue:>12.2%}\")\n",
    "print(f\"  as % of Assets:             {total_cost_of_risk/INITIAL_ASSETS:>12.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wdsac2j4gk",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 4: INCOME STATEMENT - FROM REVENUE TO NET INCOME\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 4: YEAR 1 INCOME STATEMENT (Deterministic)\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"  Revenue                          ${REVENUE:>12,.0f}\")\n",
    "print(f\"  × EBITABL Margin                 {EBITABL:>12.1%}\")\n",
    "print(f\"  ─────────────────────────────────────────────\")\n",
    "print(f\"  EBITDA (before insurance/losses)  ${REVENUE * EBITABL:>12,.0f}\")\n",
    "\n",
    "ebitda_before = REVENUE * EBITABL\n",
    "\n",
    "print(f\"  − Insurance Premium              ${premium:>12,.0f}\")\n",
    "print(f\"  − Expected Retained Losses       ${avg_annual_retained:>12,.0f}\")\n",
    "print(f\"  ─────────────────────────────────────────────\")\n",
    "\n",
    "ebitda_after = ebitda_before - premium - avg_annual_retained\n",
    "\n",
    "print(f\"  EBITDA (after insurance/losses)   ${ebitda_after:>12,.0f}\")\n",
    "print(f\"  EBITDA margin (after):            {ebitda_after/REVENUE:>12.2%}\")\n",
    "print()\n",
    "\n",
    "# Since PPE = 0%, there's no depreciation, so EBITDA = EBIT = Operating Income\n",
    "print(f\"  (PPE = 0%, so no depreciation: EBITDA = EBIT)\")\n",
    "print()\n",
    "print(f\"  EBIT                             ${ebitda_after:>12,.0f}\")\n",
    "print(f\"  × (1 − Tax Rate)                {1 - TAX_RATE:>12.1%}\")\n",
    "print(f\"  ─────────────────────────────────────────────\")\n",
    "\n",
    "net_income = ebitda_after * (1 - TAX_RATE)\n",
    "print(f\"  Net Income                       ${net_income:>12,.0f}\")\n",
    "print()\n",
    "\n",
    "retained_earnings = net_income * RETENTION_RATIO\n",
    "dividends = net_income * (1 - RETENTION_RATIO)\n",
    "\n",
    "print(f\"  × Retention Ratio                {RETENTION_RATIO:>12.1%}\")\n",
    "print(f\"  ─────────────────────────────────────────────\")\n",
    "print(f\"  Retained Earnings                ${retained_earnings:>12,.0f}\")\n",
    "print(f\"  Dividends Paid                   ${dividends:>12,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h94p4sj6lw",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 5: GROWTH RATE DECOMPOSITION\n",
    "# Connect the income statement to the observed growth rate\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 5: GROWTH RATE DECOMPOSITION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# g_naive: the simple analytical formula (ignores tax accrual timing)\n",
    "total_cost_rate = total_cost_of_risk / REVENUE\n",
    "g_naive = (EBITABL - total_cost_rate) * (1 - TAX_RATE) * RETENTION_RATIO\n",
    "\n",
    "print(f\"\\n  A. Naive Analytical Growth Rate\")\n",
    "print(f\"     g_naive = (EBITABL − cost_rate) × (1−tax) × retention\")\n",
    "print(f\"            = ({EBITABL:.3f} − {total_cost_rate:.4f}) × {1-TAX_RATE:.2f} × {RETENTION_RATIO:.2f}\")\n",
    "print(f\"            = {EBITABL - total_cost_rate:.4f} × {(1-TAX_RATE)*RETENTION_RATIO:.4f}\")\n",
    "print(f\"            = {g_naive:.6f}  ({g_naive*10000:.1f} bps/yr)\")\n",
    "print(f\"     = Retained Earnings / Assets = ${retained_earnings:,.0f} / ${INITIAL_ASSETS:,.0f}\")\n",
    "print(f\"            = {retained_earnings/INITIAL_ASSETS:.6f}  ({retained_earnings/INITIAL_ASSETS*10000:.1f} bps/yr)\")\n",
    "\n",
    "# Compare with the $5M DECOMP values to estimate tax drag and stochastic penalty\n",
    "# From DECOMP ($5M, $100K): g_naive=412.0, g_det=229.3, g_actual=175.7\n",
    "# Tax drag = 412.0 - 229.3 = 182.7 bps\n",
    "# Stochastic penalty = 229.3 - 175.7 = 53.6 bps\n",
    "\n",
    "# For $10M, the rates are nearly identical (see GC_SUPERIORITY_EXPLANATION.md section 4.2)\n",
    "# because loss frequency scales linearly with revenue\n",
    "\n",
    "g_naive_5m = 0.04120\n",
    "g_det_5m = 0.02293\n",
    "g_actual_5m = 0.01757\n",
    "tax_drag_5m = g_naive_5m - g_det_5m\n",
    "stoch_pen_5m = g_det_5m - g_actual_5m\n",
    "\n",
    "print(f\"\\n  B. Growth Rate Decomposition ($5M reference from DECOMP)\")\n",
    "print(f\"     g_naive  = {g_naive_5m*10000:.1f} bps\")\n",
    "print(f\"     g_det    = {g_det_5m*10000:.1f} bps  (tax drag = {tax_drag_5m*10000:.1f} bps)\")\n",
    "print(f\"     g_actual = {g_actual_5m*10000:.1f} bps  (stoch pen = {stoch_pen_5m*10000:.1f} bps)\")\n",
    "\n",
    "# For $10M, compute the actual decomposition\n",
    "g_actual_10m = target['growth_rate_mean']\n",
    "# Estimate g_det assuming same tax drag ratio\n",
    "tax_drag_ratio = tax_drag_5m / g_naive_5m  # ~44.3% of naive growth\n",
    "g_det_10m_est = g_naive - (g_naive * tax_drag_ratio)\n",
    "# But better: the GC_SUPERIORITY doc says growth rates are nearly identical across cap sizes\n",
    "# So we can use the $5M stochastic penalty directly\n",
    "\n",
    "stoch_pen_10m = g_det_5m - g_actual_10m  # Approximate (using $5M g_det)\n",
    "tax_drag_10m = g_naive - g_det_5m  # Approximate\n",
    "\n",
    "print(f\"\\n  C. Growth Rate Decomposition ($10M, $100K ded)\")\n",
    "print(f\"     g_naive   = {g_naive*10000:.1f} bps  (analytical, this calculation)\")\n",
    "print(f\"     g_det     ≈ {g_det_5m*10000:.1f} bps  (from $5M; nearly identical per doc)\")\n",
    "print(f\"     g_actual  = {g_actual_10m*10000:.1f} bps  (from 250K MC simulation)\")\n",
    "print(f\"     g_median  = {target['growth_rate_median']*10000:.1f} bps\")\n",
    "print(f\"     ─────────────────────────────────────────\")\n",
    "print(f\"     Tax Accrual Drag:    ≈{(g_naive - g_det_5m)*10000:>6.1f} bps\")\n",
    "print(f\"     Stochastic Penalty:  ≈{(g_det_5m - g_actual_10m)*10000:>6.1f} bps\")\n",
    "print(f\"     Total Penalty:        {(g_naive - g_actual_10m)*10000:>6.1f} bps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dr3im51z7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 6: EBITDA SUMMARY AND WEALTH TRAJECTORY\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 6: EBITDA ESTIMATE AND WEALTH TRAJECTORY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│  EBITDA ESTIMATE: $10M Cap, ATR=1.0, $100K Deductible (Insured)   │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  Revenue (Year 1)              $10,000,000                         │\n",
    "│  × EBITABL Margin                   12.5%                          │\n",
    "│  ───────────────────────────────────────                           │\n",
    "│  Gross EBITDA                   $1,250,000                         │\n",
    "│                                                                     │\n",
    "│  Less: Insurance Premium         ($356,939)   3.57% of Revenue    │\n",
    "│  Less: Expected Retained Loss    ($129,181)   1.29% of Revenue    │\n",
    "│  ───────────────────────────────────────                           │\n",
    "│  Net EBITDA                       $763,880    7.64% of Revenue    │\n",
    "│                                                                     │\n",
    "│  Tax (25%)                       ($190,970)                        │\n",
    "│  ───────────────────────────────────────                           │\n",
    "│  Net Income                       $572,910    5.73% of Revenue    │\n",
    "│                                                                     │\n",
    "│  Dividends (30%)                 ($171,873)                        │\n",
    "│  ───────────────────────────────────────                           │\n",
    "│  Retained Earnings                $401,037    4.01% of Assets     │\n",
    "│                                                                     │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│  GROWTH RATE RECONCILIATION                                        │\n",
    "│                                                                     │\n",
    "│  Naive g (Ret. Earnings / Assets)    401.0 bps/yr                 │\n",
    "│  − Tax Accrual Drag                 −171.7 bps/yr  (accrual lag)  │\n",
    "│  − Stochastic Penalty                −55.3 bps/yr  (σ²/2 + tails)│\n",
    "│  ───────────────────────────────────────                           │\n",
    "│  Actual Time-Average Growth Rate     174.0 bps/yr  (MC mean)     │\n",
    "│  Median Growth Rate                  174.1 bps/yr  ← reported    │\n",
    "│                                                                     │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│  50-YEAR WEALTH TRAJECTORY                                         │\n",
    "│                                                                     │\"\"\")\n",
    "\n",
    "# Terminal wealth calculations\n",
    "initial = INITIAL_ASSETS\n",
    "years = 50\n",
    "\n",
    "# At naive rate\n",
    "w_naive = initial * np.exp(g_naive * years)\n",
    "# At actual rate\n",
    "w_actual_mean = target['final_assets_mean']\n",
    "w_actual_median = target['final_assets_median']\n",
    "# At median growth rate\n",
    "w_from_median_g = initial * np.exp(target['growth_rate_median'] * years)\n",
    "\n",
    "# No insurance comparison\n",
    "w_noins_mean = noins['final_assets_mean']\n",
    "w_noins_median = noins['final_assets_median']\n",
    "\n",
    "print(f\"│  Starting Assets                   ${initial:>12,.0f}                │\")\n",
    "print(f\"│                                                                     │\")\n",
    "print(f\"│  At Naive Rate (401 bps):          ${w_naive:>12,.0f}   ({w_naive/initial:.2f}×)       │\")\n",
    "print(f\"│  Actual Mean Final Assets:         ${w_actual_mean:>12,.0f}   ({w_actual_mean/initial:.2f}×)       │\")\n",
    "print(f\"│  Actual Median Final Assets:       ${w_actual_median:>12,.0f}   ({w_actual_median/initial:.2f}×)       │\")\n",
    "print(f\"│  From Median g (exp(g×50)):        ${w_from_median_g:>12,.0f}   ({w_from_median_g/initial:.2f}×)       │\")\n",
    "print(f\"│                                                                     │\")\n",
    "print(f\"│  vs. No Insurance:                                                  │\")\n",
    "print(f\"│    No-Ins Mean Final Assets:       ${w_noins_mean:>12,.0f}   ({w_noins_mean/initial:.2f}×)       │\")\n",
    "print(f\"│    No-Ins Median Final Assets:     ${w_noins_median:>12,.0f}   ({w_noins_median/initial:.2f}×)       │\")\n",
    "print(f\"│    Median Wealth Advantage:        ${w_actual_median - w_noins_median:>12,.0f}   (+{(w_actual_median/w_noins_median - 1)*100:.0f}%)        │\")\n",
    "print(f\"│                                                                     │\")\n",
    "print(f\"│  Ruin Probability (50yr):                                           │\")\n",
    "print(f\"│    Insured:   {target['ruin_probability'][50]:>6.2%}                                           │\")\n",
    "print(f\"│    Uninsured: {noins['ruin_probability'][50]:>6.2%}                                          │\")\n",
    "print(f\"│                                                                     │\")\n",
    "print(f\"└─────────────────────────────────────────────────────────────────────┘\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7xu437grfs8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 7: WHY NAIVE g (401 bps) ≠ ACTUAL g (174 bps) - THE TWO PENALTIES\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 7: EXPLAINING THE 227 bps GAP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "The naive calculation says: \"Retain $401K/yr on a $10M base = 4.01% growth.\"\n",
    "The simulation says: \"Median growth = 1.74%/yr.\"\n",
    "\n",
    "Where did the other 227 bps go?\n",
    "\n",
    "PENALTY 1: Tax Accrual Timing Drag (~172 bps)\n",
    "──────────────────────────────────────────────\n",
    "The model uses accrual-basis accounting with a 2-year tax payment lag:\n",
    "  • Year N: taxes are expensed (reducing book income) AND accrued as liability\n",
    "  • Year N+2: accrued taxes are paid from CASH\n",
    "\n",
    "In annual resolution, this means:\n",
    "  • Retained earnings add to cash:  EBIT × (1−tax) × retention\n",
    "  • But tax payment from 2 years prior ALSO reduces cash\n",
    "\n",
    "The net effect: total-asset growth is slower than the simple\n",
    "  g = margin × (1−tax) × retention formula suggests.\n",
    "\n",
    "This drag is ~172 bps and affects ALL configurations proportionally.\n",
    "It does NOT change the ranking between deductible levels.\n",
    "\n",
    "PENALTY 2: Stochastic Volatility Penalty (~55 bps)\n",
    "──────────────────────────────────────────────────\n",
    "For multiplicative processes: g_time ≈ g_expected − σ²/2\n",
    "\n",
    "Two sources of volatility:\n",
    "  a) Revenue volatility (GBM σ=0.15):\n",
    "     Base penalty: σ²/2 = 0.15²/2 = 112.5 bps\n",
    "     (But modulated by how revenue flows through the P&L)\n",
    "\n",
    "  b) Retained loss volatility (fat-tailed Pareto losses):\n",
    "     With $100K deductible, retained losses have:\"\"\")\n",
    "\n",
    "# Load actual retained loss statistics from the simulation\n",
    "ts_retained = target['ts_retained_losses_pctiles']  # shape (50, 7) for percentiles [5,10,25,50,75,90,95]\n",
    "yr1_retained_pctiles = ts_retained[0]  # Year 1\n",
    "pctile_labels = [5, 10, 25, 50, 75, 90, 95]\n",
    "\n",
    "print(f\"     Year 1 Retained Loss Percentiles:\")\n",
    "for pct, val in zip(pctile_labels, yr1_retained_pctiles):\n",
    "    print(f\"       P{pct:2d}: ${val:>12,.0f}  ({val/INITIAL_ASSETS:.2%} of assets)\")\n",
    "\n",
    "print(f\"\"\"\n",
    "  The combination of revenue shocks and retained loss shocks\n",
    "  creates a ~55 bps drag on the time-average growth rate.\n",
    "\n",
    "  For comparison, the $0K deductible (GC) has a NEGATIVE penalty\n",
    "  of −22 bps (insurance actually helps by stabilizing income).\n",
    "\n",
    "SUMMARY:\n",
    "  g_naive                    401.0 bps\n",
    "  − Tax accrual drag        −171.7 bps\n",
    "  − Stochastic penalty       −55.3 bps\n",
    "  ─────────────────────────────────────\n",
    "  g_actual                   174.0 bps  ✓ matches simulation\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voz0cgs783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 8: Cross-check with all deductible levels for $10M, ATR=1.0\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 8: CROSS-CHECK — ALL DEDUCTIBLE LEVELS ($10M, ATR=1.0)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n{'Deductible':<15} {'Mean g':>10} {'Median g':>10} {'Ruin 50yr':>10} {'Median FA':>15}\")\n",
    "print(f\"{'─'*15} {'─'*10} {'─'*10} {'─'*10} {'─'*15}\")\n",
    "\n",
    "for k, v in sorted(dc[\"configs\"].items()):\n",
    "    if v[\"Cap\"] == 10_000_000 and v[\"ATR\"] == 1.0:\n",
    "        if v.get(\"NOINS\"):\n",
    "            label = \"No Insurance\"\n",
    "        else:\n",
    "            label = f\"${v['Ded']/1000:.0f}K\"\n",
    "        print(f\"{label:<15} {v['growth_rate_mean']*10000:>8.1f}bp {v['growth_rate_median']*10000:>8.1f}bp \"\n",
    "              f\"{v['ruin_probability'][50]:>9.2%} ${v['final_assets_median']:>13,.0f}\")\n",
    "\n",
    "# Also show $5M for comparison\n",
    "print(f\"\\n{'Deductible':<15} {'Mean g':>10} {'Median g':>10} {'Ruin 50yr':>10} {'Median FA':>15}\")\n",
    "print(f\"{'─'*15} {'─'*10} {'─'*10} {'─'*10} {'─'*15}\")\n",
    "print(\"($5M Cap, ATR=1.0 for comparison)\")\n",
    "\n",
    "for k, v in sorted(dc[\"configs\"].items()):\n",
    "    if v[\"Cap\"] == 5_000_000 and v[\"ATR\"] == 1.0:\n",
    "        if v.get(\"NOINS\"):\n",
    "            label = \"No Insurance\"\n",
    "        else:\n",
    "            label = f\"${v['Ded']/1000:.0f}K\"\n",
    "        print(f\"{label:<15} {v['growth_rate_mean']*10000:>8.1f}bp {v['growth_rate_median']*10000:>8.1f}bp \"\n",
    "              f\"{v['ruin_probability'][50]:>9.2%} ${v['final_assets_median']:>13,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_OUTPUT =  Path('output/publication/interesting')\n",
    "PAPER_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy interesting graphs to the \"interesting\" folder\n",
    "import shutil\n",
    "interesting_figs = [\n",
    "    'insurance_outcome_distribution_basic.png',\n",
    "    'volatility_tax_vs_premium_savings.png',\n",
    "    'wealth_fan_chart.png',\n",
    "    'year_by_year_growth_lift_facets.png',\n",
    "]\n",
    "for fig_name in interesting_figs:\n",
    "    try:\n",
    "        src = Path('output/publication') / fig_name\n",
    "        dst = PAPER_OUTPUT / fig_name\n",
    "        shutil.copy2(src, dst)\n",
    "    except Exception as e:\n",
    "        print(f'Error copying {fig_name}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b41c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
