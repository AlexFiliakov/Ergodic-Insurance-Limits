{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance Structure and Technical Visualizations\n",
    "\n",
    "This notebook demonstrates the three new technical visualization functions added for issue #67:\n",
    "- **Figure B2**: Correlation Structure\n",
    "- **Figure C4**: Premium Loading Decomposition\n",
    "- **Figure C5**: Capital Efficiency Frontier (3D)\n",
    "\n",
    "These visualizations are designed for technical appendix documentation and provide detailed insights into insurance structures, risk correlations, and capital efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, os.path.abspath('../../'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the new visualization functions\n",
    "from ergodic_insurance.visualization.technical_plots import (\n",
    "    plot_correlation_structure,\n",
    "    plot_premium_decomposition,\n",
    "    plot_capital_efficiency_frontier_3d\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure B2: Risk Correlation Structure\n",
    "\n",
    "This visualization shows the correlation structure between different risk types, including correlation matrices, copula density plots, and tail dependence analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic risk data with realistic correlation structure\n",
    "n_samples = 1000\n",
    "\n",
    "# Create correlated operational risk data\n",
    "mean_op = [0, 0, 0]\n",
    "cov_op = [[1.0, 0.6, 0.3],   # High correlation between first two\n",
    "          [0.6, 1.0, 0.4],\n",
    "          [0.3, 0.4, 1.0]]\n",
    "operational_data = np.random.multivariate_normal(mean_op, cov_op, n_samples)\n",
    "\n",
    "# Create correlated financial risk data  \n",
    "mean_fin = [0, 0, 0]\n",
    "cov_fin = [[1.0, 0.8, 0.5],   # Very high correlation - systemic risk\n",
    "           [0.8, 1.0, 0.7],\n",
    "           [0.5, 0.7, 1.0]]\n",
    "financial_data = np.random.multivariate_normal(mean_fin, cov_fin, n_samples)\n",
    "\n",
    "# Transform to positive values (loss amounts)\n",
    "operational_data = np.exp(operational_data) * 10000  # Log-normal losses\n",
    "financial_data = np.exp(financial_data) * 50000      # Larger financial losses\n",
    "\n",
    "risk_data = {\n",
    "    \"Operational\": operational_data,\n",
    "    \"Financial\": financial_data\n",
    "}\n",
    "\n",
    "print(f\"Generated {n_samples} samples for each risk type\")\n",
    "print(f\"Operational loss range: ${operational_data.min():,.0f} - ${operational_data.max():,.0f}\")\n",
    "print(f\"Financial loss range: ${financial_data.min():,.0f} - ${financial_data.max():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation structure visualization\n",
    "fig = plot_correlation_structure(\n",
    "    risk_data,\n",
    "    correlation_type=\"pearson\",\n",
    "    title=\"Risk Correlation Structure Analysis\",\n",
    "    figsize=(16, 10),\n",
    "    show_copula=True\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelation structure shows:\")\n",
    "print(\"- Heatmaps reveal the strength of linear relationships\")\n",
    "print(\"- Copula plots show dependency structure beyond linear correlation\")\n",
    "print(\"- Useful for understanding tail risk dependencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different correlation measures\n",
    "for corr_type in [\"spearman\", \"kendall\"]:\n",
    "    fig = plot_correlation_structure(\n",
    "        {\"Combined Risk\": np.column_stack([operational_data[:, 0], financial_data[:, 0]])},\n",
    "        correlation_type=corr_type,\n",
    "        title=f\"Risk Correlation - {corr_type.title()} Coefficient\",\n",
    "        figsize=(14, 8)\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure C4: Premium Loading Decomposition\n",
    "\n",
    "This visualization breaks down insurance premiums into their component parts, showing how much of the premium goes to expected losses, volatility loading, tail risk, expenses, and profit margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic premium component data for different company sizes and layers\n",
    "premium_components = {\n",
    "    \"Small Company\": {\n",
    "        \"Primary ($0-5M)\": {\n",
    "            \"expected_loss\": 250000,      # 50% of premium\n",
    "            \"volatility_load\": 75000,     # 15% - higher for small companies\n",
    "            \"tail_load\": 50000,          # 10% - catastrophic risk\n",
    "            \"expense_load\": 87500,       # 17.5% - fixed costs\n",
    "            \"profit_margin\": 37500       # 7.5% - insurer profit\n",
    "        },\n",
    "        \"Excess ($5-15M)\": {\n",
    "            \"expected_loss\": 100000,     # Lower frequency in excess layer\n",
    "            \"volatility_load\": 40000,    \n",
    "            \"tail_load\": 35000,         \n",
    "            \"expense_load\": 35000,      # Lower expense ratio\n",
    "            \"profit_margin\": 15000      \n",
    "        },\n",
    "        \"High Excess ($15-25M)\": {\n",
    "            \"expected_loss\": 30000,      # Rare events\n",
    "            \"volatility_load\": 20000,    # High uncertainty\n",
    "            \"tail_load\": 25000,         # Significant tail risk\n",
    "            \"expense_load\": 15000,      \n",
    "            \"profit_margin\": 10000      \n",
    "        }\n",
    "    },\n",
    "    \"Medium Company\": {\n",
    "        \"Primary ($0-5M)\": {\n",
    "            \"expected_loss\": 400000,     # Higher exposure\n",
    "            \"volatility_load\": 80000,    # 20% of expected\n",
    "            \"tail_load\": 60000,         \n",
    "            \"expense_load\": 100000,     \n",
    "            \"profit_margin\": 60000      \n",
    "        },\n",
    "        \"Excess ($5-15M)\": {\n",
    "            \"expected_loss\": 180000,\n",
    "            \"volatility_load\": 54000,\n",
    "            \"tail_load\": 45000,\n",
    "            \"expense_load\": 45000,\n",
    "            \"profit_margin\": 26000\n",
    "        },\n",
    "        \"High Excess ($15-25M)\": {\n",
    "            \"expected_loss\": 60000,\n",
    "            \"volatility_load\": 30000,\n",
    "            \"tail_load\": 35000,\n",
    "            \"expense_load\": 20000,\n",
    "            \"profit_margin\": 15000\n",
    "        }\n",
    "    },\n",
    "    \"Large Company\": {\n",
    "        \"Primary ($0-10M)\": {\n",
    "            \"expected_loss\": 800000,     # Much higher exposure\n",
    "            \"volatility_load\": 120000,   # Lower relative volatility\n",
    "            \"tail_load\": 100000,\n",
    "            \"expense_load\": 150000,\n",
    "            \"profit_margin\": 80000\n",
    "        },\n",
    "        \"Excess ($10-25M)\": {\n",
    "            \"expected_loss\": 300000,\n",
    "            \"volatility_load\": 75000,\n",
    "            \"tail_load\": 75000,\n",
    "            \"expense_load\": 60000,\n",
    "            \"profit_margin\": 40000\n",
    "        },\n",
    "        \"High Excess ($25-50M)\": {\n",
    "            \"expected_loss\": 100000,\n",
    "            \"volatility_load\": 50000,\n",
    "            \"tail_load\": 60000,\n",
    "            \"expense_load\": 30000,\n",
    "            \"profit_margin\": 20000\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Calculate total premiums\n",
    "for company_size, layers in premium_components.items():\n",
    "    print(f\"\\n{company_size}:\")\n",
    "    for layer, components in layers.items():\n",
    "        total = sum(components.values())\n",
    "        print(f\"  {layer}: Total Premium = ${total:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create premium decomposition visualization\n",
    "fig = plot_premium_decomposition(\n",
    "    premium_components,\n",
    "    title=\"Insurance Premium Loading Decomposition by Company Size and Layer\",\n",
    "    figsize=(16, 10),\n",
    "    show_percentages=True\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insights from premium decomposition:\")\n",
    "print(\"- Expected loss typically represents 40-60% of premium\")\n",
    "print(\"- Volatility and tail loads increase for higher layers\")\n",
    "print(\"- Expense ratios decrease with company size (economies of scale)\")\n",
    "print(\"- Profit margins are generally 5-10% of total premium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a focused view for just small companies with custom colors\n",
    "small_only = {\"Small Company\": premium_components[\"Small Company\"]}\n",
    "\n",
    "custom_colors = {\n",
    "    \"expected_loss\": \"#2E86AB\",     # Blue - base cost\n",
    "    \"volatility_load\": \"#F24236\",   # Red - risk charge\n",
    "    \"tail_load\": \"#F6AE2D\",        # Orange - extreme risk\n",
    "    \"expense_load\": \"#2F4858\",     # Dark gray - operations\n",
    "    \"profit_margin\": \"#86BA90\"      # Green - profit\n",
    "}\n",
    "\n",
    "fig = plot_premium_decomposition(\n",
    "    small_only,\n",
    "    title=\"Small Company Premium Structure Analysis\",\n",
    "    figsize=(12, 8),\n",
    "    show_percentages=True,\n",
    "    color_scheme=custom_colors\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure C5: Capital Efficiency Frontier (3D)\n",
    "\n",
    "This 3D visualization shows the relationship between ROE, ruin probability, and insurance spend, helping identify the optimal insurance strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate efficiency frontier data\n",
    "def generate_efficiency_surface(n_ruin=25, n_spend=30, company_type=\"Small\"):\n",
    "    \"\"\"Generate realistic efficiency surface data.\"\"\"\n",
    "    \n",
    "    # Define ranges based on company size\n",
    "    if company_type == \"Small\":\n",
    "        ruin_range = (0.001, 0.15)  # 0.1% to 15% ruin probability\n",
    "        spend_range = (0, 1.5e6)     # $0 to $1.5M insurance spend\n",
    "        base_roe = 0.12              # 12% base ROE\n",
    "    elif company_type == \"Medium\":\n",
    "        ruin_range = (0.001, 0.10)\n",
    "        spend_range = (0, 3e6)\n",
    "        base_roe = 0.15\n",
    "    else:  # Large\n",
    "        ruin_range = (0.001, 0.05)\n",
    "        spend_range = (0, 6e6)\n",
    "        base_roe = 0.18\n",
    "    \n",
    "    ruin_probs = np.linspace(ruin_range[0], ruin_range[1], n_ruin)\n",
    "    insurance_spends = np.linspace(spend_range[0], spend_range[1], n_spend)\n",
    "    \n",
    "    # Create ROE surface - higher insurance reduces ruin but costs premium\n",
    "    roe_surface = np.zeros((n_ruin, n_spend))\n",
    "    \n",
    "    for i, ruin in enumerate(ruin_probs):\n",
    "        for j, spend in enumerate(insurance_spends):\n",
    "            # Base ROE adjusted for ruin probability\n",
    "            roe = base_roe * (1 - ruin * 2)  # Ruin reduces effective ROE\n",
    "            \n",
    "            # Insurance cost reduces ROE but improves stability\n",
    "            insurance_drag = spend / 10e6  # Normalize spending impact\n",
    "            roe -= insurance_drag * 0.5\n",
    "            \n",
    "            # But insurance reduces volatility, improving risk-adjusted returns\n",
    "            stability_bonus = min(spend / spend_range[1], 1) * 0.08 * (1 - ruin)\n",
    "            roe += stability_bonus\n",
    "            \n",
    "            # Add some noise for realism\n",
    "            roe += np.random.normal(0, 0.005)\n",
    "            \n",
    "            roe_surface[i, j] = max(roe, 0)  # ROE can't be negative\n",
    "    \n",
    "    return {\n",
    "        \"roe\": roe_surface,\n",
    "        \"ruin_prob\": ruin_probs,\n",
    "        \"insurance_spend\": insurance_spends\n",
    "    }\n",
    "\n",
    "# Generate data for three company sizes\n",
    "efficiency_data = {\n",
    "    \"Small\": generate_efficiency_surface(company_type=\"Small\"),\n",
    "    \"Medium\": generate_efficiency_surface(company_type=\"Medium\"),\n",
    "    \"Large\": generate_efficiency_surface(company_type=\"Large\")\n",
    "}\n",
    "\n",
    "print(\"Generated efficiency surfaces for Small, Medium, and Large companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate optimal paths (simplified - in reality would be from optimization)\n",
    "def generate_optimal_path(company_type, n_points=20):\n",
    "    \"\"\"Generate a plausible optimal insurance path.\"\"\"\n",
    "    \n",
    "    if company_type == \"Small\":\n",
    "        # Small company: gradually increase insurance to reduce ruin\n",
    "        ruin_path = np.linspace(0.10, 0.01, n_points)\n",
    "        spend_path = np.linspace(0.2e6, 1.0e6, n_points)\n",
    "        roe_path = np.linspace(0.08, 0.11, n_points)  # ROE improves with stability\n",
    "    elif company_type == \"Medium\":\n",
    "        ruin_path = np.linspace(0.07, 0.005, n_points)\n",
    "        spend_path = np.linspace(0.5e6, 2.0e6, n_points)\n",
    "        roe_path = np.linspace(0.11, 0.14, n_points)\n",
    "    else:\n",
    "        ruin_path = np.linspace(0.04, 0.002, n_points)\n",
    "        spend_path = np.linspace(1.0e6, 3.5e6, n_points)\n",
    "        roe_path = np.linspace(0.14, 0.16, n_points)\n",
    "    \n",
    "    # Add some curvature for realism\n",
    "    t = np.linspace(0, 1, n_points)\n",
    "    curvature = 0.02 * np.sin(np.pi * t)\n",
    "    roe_path += curvature\n",
    "    \n",
    "    return np.column_stack([ruin_path, spend_path, roe_path])\n",
    "\n",
    "optimal_paths = {\n",
    "    \"Small\": generate_optimal_path(\"Small\"),\n",
    "    \"Medium\": generate_optimal_path(\"Medium\"),\n",
    "    \"Large\": generate_optimal_path(\"Large\")\n",
    "}\n",
    "\n",
    "print(\"Generated optimal insurance paths for each company size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 3D capital efficiency frontier visualization\n",
    "fig = plot_capital_efficiency_frontier_3d(\n",
    "    efficiency_data,\n",
    "    optimal_paths=optimal_paths,\n",
    "    title=\"Capital Efficiency Frontier: ROE vs Ruin vs Insurance Spend\",\n",
    "    figsize=(14, 10),\n",
    "    view_angles=(25, 45)  # Elevation, azimuth\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insights from 3D efficiency frontier:\")\n",
    "print(\"- Optimal paths show trade-off between insurance cost and risk reduction\")\n",
    "print(\"- Larger companies achieve higher ROE with lower ruin probability\")\n",
    "print(\"- Surface curvature reveals non-linear relationships\")\n",
    "print(\"- Sweet spot exists where insurance maximizes risk-adjusted returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple viewing angles for comprehensive analysis\n",
    "figures = plot_capital_efficiency_frontier_3d(\n",
    "    {\"Small\": efficiency_data[\"Small\"]},  # Focus on small company\n",
    "    optimal_paths={\"Small\": optimal_paths[\"Small\"]},\n",
    "    title=\"Small Company Efficiency Analysis\",\n",
    "    figsize=(12, 8),\n",
    "    export_views=True  # Generate multiple viewing angles\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(figures)} different viewing angles\")\n",
    "\n",
    "# Display first two views\n",
    "for i, fig in enumerate(figures[:2]):\n",
    "    print(f\"\\nView {i+1}:\")\n",
    "    plt.show()\n",
    "    \n",
    "# Close remaining figures to save memory\n",
    "for fig in figures[2:]:\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison view with different angles\n",
    "angles = [(20, 45), (30, 135), (10, 225), (45, 315)]\n",
    "angle_names = [\"Default\", \"Side View\", \"Back View\", \"Top View\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12), subplot_kw={'projection': '3d'})\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (ax, (elev, azim), name) in enumerate(zip(axes, angles, angle_names)):\n",
    "    # Plot surface for small company\n",
    "    data = efficiency_data[\"Small\"]\n",
    "    X, Y = np.meshgrid(data[\"ruin_prob\"], data[\"insurance_spend\"])\n",
    "    Z = data[\"roe\"].T\n",
    "    \n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7)\n",
    "    \n",
    "    # Add optimal path\n",
    "    path = optimal_paths[\"Small\"]\n",
    "    ax.plot(path[:, 0], path[:, 1], path[:, 2], \n",
    "            color='red', linewidth=3, label='Optimal Path')\n",
    "    \n",
    "    ax.set_xlabel('Ruin Probability', fontsize=9)\n",
    "    ax.set_ylabel('Insurance Spend ($)', fontsize=9)\n",
    "    ax.set_zlabel('ROE', fontsize=9)\n",
    "    ax.set_title(f'{name} (elev={elev}°, azim={azim}°)', fontsize=11)\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "plt.suptitle('Capital Efficiency Frontier - Multiple Perspectives', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "These three technical visualizations provide comprehensive insights into insurance structures:\n",
    "\n",
    "1. **Correlation Structure (Figure B2)**:\n",
    "   - Reveals dependencies between risk types\n",
    "   - Copula analysis shows tail dependencies beyond linear correlation\n",
    "   - Critical for understanding systemic risk\n",
    "\n",
    "2. **Premium Decomposition (Figure C4)**:\n",
    "   - Transparently shows premium components\n",
    "   - Highlights how costs vary by company size and layer\n",
    "   - Useful for insurance buying decisions\n",
    "\n",
    "3. **Capital Efficiency Frontier (Figure C5)**:\n",
    "   - 3D visualization reveals complex trade-offs\n",
    "   - Optimal paths guide insurance strategy\n",
    "   - Shows that more insurance can actually improve ROE when risk-adjusted\n",
    "\n",
    "These visualizations are suitable for:\n",
    "- Technical appendices in research papers\n",
    "- Actuarial presentations\n",
    "- Risk committee discussions\n",
    "- Insurance program design documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
